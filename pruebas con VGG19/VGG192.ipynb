{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pruebas de CNN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.8.6 64-bit",
      "metadata": {
        "interpreter": {
          "hash": "8536e2ca952f32a5bec726450a2478a8882e5b0c7830bd7510f01b501b083f0b"
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sbc9OwzSc0pv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54bdb70a-5c68-42f0-b0bf-375b0d2f577d"
      },
      "source": [
        "import sys\n",
        "\n",
        "sys.path.append(\"../\")\n",
        "from tensorflow.keras.applications.VGG19 import VGG19\n",
        "from funciones import *"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Modulo importado con exito.... :)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PvI4hYBxd9k8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60204881-7d7d-45b7-abe4-fa154b40b983"
      },
      "source": [
        "K.clear_session() #limpiamos todos en caso de nuevo entrenamiento\n",
        "img_width=224\n",
        "img_height=224\n",
        "INIT_LR = 1e-3\n",
        "batch_size=50\n",
        "epochs=100\n",
        "\n",
        "#CARGANDO LOS DATASETS\n",
        "path_root='../../Dataset Real Bananos MRefinados/'\n",
        "path_train=path_root+'train'\n",
        "path_validation=path_root+'validation'\n",
        "\n",
        "train_gen=ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    shear_range=0.3,\n",
        "    zoom_range=0.3,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "\n",
        "validation_gen= ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "image_train=train_gen.flow_from_directory(\n",
        "    path_train,\n",
        "    target_size=(img_width,img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        ")\n",
        "\n",
        "image_validation=validation_gen.flow_from_directory(\n",
        "    path_validation,\n",
        "    target_size=(img_width,img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "nClasses=len(image_train.class_indices)\n",
        "print(image_train.class_indices)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2384 images belonging to 4 classes.\n",
            "Found 795 images belonging to 4 classes.\n",
            "{'Class A': 0, 'Class B': 1, 'Class C': 2, 'Class D': 3}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cd-uNvKYfKG6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a90d1a61-eb34-46f8-cb34-ee87804ea5b4",
        "tags": []
      },
      "source": [
        "#Construccion del modelo\n",
        "\n",
        "vgg19_arch=VGG19(input_shape=(img_width,img_height,3),\n",
        "                                 weights=None, #aqui se puede aplicarTransfer Learning\n",
        "                                 include_top=False)\n",
        "vgg19_arch.summary()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"inception_resnet_v2\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 111, 111, 32) 864         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 111, 111, 32) 96          conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 111, 111, 32) 0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 109, 109, 32) 9216        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 109, 109, 32) 96          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 109, 109, 32) 0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 109, 109, 64) 18432       activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 109, 109, 64) 192         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 109, 109, 64) 0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 54, 54, 64)   0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 54, 54, 80)   5120        max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 54, 54, 80)   240         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 54, 54, 80)   0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 52, 52, 192)  138240      activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 52, 52, 192)  576         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 52, 52, 192)  0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 25, 25, 192)  0           activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 25, 25, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 25, 25, 64)   192         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 25, 25, 64)   0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 25, 25, 48)   9216        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 25, 25, 96)   55296       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 25, 25, 48)   144         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 25, 25, 96)   288         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 25, 25, 48)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 25, 25, 96)   0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 25, 25, 192)  0           max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 25, 25, 96)   18432       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 25, 25, 64)   76800       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 25, 25, 96)   82944       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 25, 25, 64)   12288       average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 25, 25, 96)   288         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 25, 25, 64)   192         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 25, 25, 96)   288         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 25, 25, 64)   192         conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 25, 25, 96)   0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 25, 25, 64)   0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 25, 25, 96)   0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 25, 25, 64)   0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed_5b (Concatenate)          (None, 25, 25, 320)  0           activation_5[0][0]               \n",
            "                                                                 activation_7[0][0]               \n",
            "                                                                 activation_10[0][0]              \n",
            "                                                                 activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 25, 25, 32)   10240       mixed_5b[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 25, 25, 32)   96          conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 25, 25, 32)   0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 25, 25, 32)   10240       mixed_5b[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 25, 25, 48)   13824       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 25, 25, 32)   96          conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 25, 25, 48)   144         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 25, 25, 32)   0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 25, 25, 48)   0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 25, 25, 32)   10240       mixed_5b[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 25, 25, 32)   9216        activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 25, 25, 64)   27648       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 25, 25, 32)   96          conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 25, 25, 32)   96          conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 25, 25, 64)   192         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 25, 25, 32)   0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 25, 25, 32)   0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 25, 25, 64)   0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "block35_1_mixed (Concatenate)   (None, 25, 25, 128)  0           activation_12[0][0]              \n",
            "                                                                 activation_14[0][0]              \n",
            "                                                                 activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block35_1_conv (Conv2D)         (None, 25, 25, 320)  41280       block35_1_mixed[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block35_1 (Lambda)              (None, 25, 25, 320)  0           mixed_5b[0][0]                   \n",
            "                                                                 block35_1_conv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block35_1_ac (Activation)       (None, 25, 25, 320)  0           block35_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 25, 25, 32)   10240       block35_1_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 25, 25, 32)   96          conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 25, 25, 32)   0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 25, 25, 32)   10240       block35_1_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 25, 25, 48)   13824       activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 25, 25, 32)   96          conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 25, 25, 48)   144         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 25, 25, 32)   0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 25, 25, 48)   0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 25, 25, 32)   10240       block35_1_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 25, 25, 32)   9216        activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 25, 25, 64)   27648       activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 25, 25, 32)   96          conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 25, 25, 32)   96          conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 25, 25, 64)   192         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 25, 25, 32)   0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 25, 25, 32)   0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 25, 25, 64)   0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "block35_2_mixed (Concatenate)   (None, 25, 25, 128)  0           activation_18[0][0]              \n",
            "                                                                 activation_20[0][0]              \n",
            "                                                                 activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block35_2_conv (Conv2D)         (None, 25, 25, 320)  41280       block35_2_mixed[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block35_2 (Lambda)              (None, 25, 25, 320)  0           block35_1_ac[0][0]               \n",
            "                                                                 block35_2_conv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block35_2_ac (Activation)       (None, 25, 25, 320)  0           block35_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 25, 25, 32)   10240       block35_2_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 25, 25, 32)   96          conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 25, 25, 32)   0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 25, 25, 32)   10240       block35_2_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 25, 25, 48)   13824       activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 25, 25, 32)   96          conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 25, 25, 48)   144         conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 25, 25, 32)   0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 25, 25, 48)   0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 25, 25, 32)   10240       block35_2_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 25, 25, 32)   9216        activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 25, 25, 64)   27648       activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 25, 25, 32)   96          conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 25, 25, 32)   96          conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 25, 25, 64)   192         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 25, 25, 32)   0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 25, 25, 32)   0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 25, 25, 64)   0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "block35_3_mixed (Concatenate)   (None, 25, 25, 128)  0           activation_24[0][0]              \n",
            "                                                                 activation_26[0][0]              \n",
            "                                                                 activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block35_3_conv (Conv2D)         (None, 25, 25, 320)  41280       block35_3_mixed[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block35_3 (Lambda)              (None, 25, 25, 320)  0           block35_2_ac[0][0]               \n",
            "                                                                 block35_3_conv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block35_3_ac (Activation)       (None, 25, 25, 320)  0           block35_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 25, 25, 32)   10240       block35_3_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 25, 25, 32)   96          conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 25, 25, 32)   0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 25, 25, 32)   10240       block35_3_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 25, 25, 48)   13824       activation_33[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 25, 25, 32)   96          conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 25, 25, 48)   144         conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 25, 25, 32)   0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 25, 25, 48)   0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 25, 25, 32)   10240       block35_3_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 25, 25, 32)   9216        activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 25, 25, 64)   27648       activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 25, 25, 32)   96          conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 25, 25, 32)   96          conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 25, 25, 64)   192         conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 25, 25, 32)   0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 25, 25, 32)   0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 25, 25, 64)   0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "block35_4_mixed (Concatenate)   (None, 25, 25, 128)  0           activation_30[0][0]              \n",
            "                                                                 activation_32[0][0]              \n",
            "                                                                 activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block35_4_conv (Conv2D)         (None, 25, 25, 320)  41280       block35_4_mixed[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block35_4 (Lambda)              (None, 25, 25, 320)  0           block35_3_ac[0][0]               \n",
            "                                                                 block35_4_conv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block35_4_ac (Activation)       (None, 25, 25, 320)  0           block35_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 25, 25, 32)   10240       block35_4_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 25, 25, 32)   96          conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 25, 25, 32)   0           batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 25, 25, 32)   10240       block35_4_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 25, 25, 48)   13824       activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 25, 25, 32)   96          conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 25, 25, 48)   144         conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 25, 25, 32)   0           batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 25, 25, 48)   0           batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 25, 25, 32)   10240       block35_4_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 25, 25, 32)   9216        activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 25, 25, 64)   27648       activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 25, 25, 32)   96          conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 25, 25, 32)   96          conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 25, 25, 64)   192         conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 25, 25, 32)   0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 25, 25, 32)   0           batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 25, 25, 64)   0           batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "block35_5_mixed (Concatenate)   (None, 25, 25, 128)  0           activation_36[0][0]              \n",
            "                                                                 activation_38[0][0]              \n",
            "                                                                 activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block35_5_conv (Conv2D)         (None, 25, 25, 320)  41280       block35_5_mixed[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block35_5 (Lambda)              (None, 25, 25, 320)  0           block35_4_ac[0][0]               \n",
            "                                                                 block35_5_conv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block35_5_ac (Activation)       (None, 25, 25, 320)  0           block35_5[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 25, 25, 32)   10240       block35_5_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, 25, 25, 32)   96          conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 25, 25, 32)   0           batch_normalization_45[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 25, 25, 32)   10240       block35_5_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 25, 25, 48)   13824       activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, 25, 25, 32)   96          conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, 25, 25, 48)   144         conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 25, 25, 32)   0           batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 25, 25, 48)   0           batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 25, 25, 32)   10240       block35_5_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 25, 25, 32)   9216        activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 25, 25, 64)   27648       activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 25, 25, 32)   96          conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, 25, 25, 32)   96          conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, 25, 25, 64)   192         conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 25, 25, 32)   0           batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 25, 25, 32)   0           batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 25, 25, 64)   0           batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "block35_6_mixed (Concatenate)   (None, 25, 25, 128)  0           activation_42[0][0]              \n",
            "                                                                 activation_44[0][0]              \n",
            "                                                                 activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block35_6_conv (Conv2D)         (None, 25, 25, 320)  41280       block35_6_mixed[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block35_6 (Lambda)              (None, 25, 25, 320)  0           block35_5_ac[0][0]               \n",
            "                                                                 block35_6_conv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block35_6_ac (Activation)       (None, 25, 25, 320)  0           block35_6[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 25, 25, 32)   10240       block35_6_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, 25, 25, 32)   96          conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 25, 25, 32)   0           batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 25, 25, 32)   10240       block35_6_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 25, 25, 48)   13824       activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, 25, 25, 32)   96          conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, 25, 25, 48)   144         conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 25, 25, 32)   0           batch_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 25, 25, 48)   0           batch_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 25, 25, 32)   10240       block35_6_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 25, 25, 32)   9216        activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 25, 25, 64)   27648       activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, 25, 25, 32)   96          conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, 25, 25, 32)   96          conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_53 (BatchNo (None, 25, 25, 64)   192         conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 25, 25, 32)   0           batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 25, 25, 32)   0           batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 25, 25, 64)   0           batch_normalization_53[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "block35_7_mixed (Concatenate)   (None, 25, 25, 128)  0           activation_48[0][0]              \n",
            "                                                                 activation_50[0][0]              \n",
            "                                                                 activation_53[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block35_7_conv (Conv2D)         (None, 25, 25, 320)  41280       block35_7_mixed[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block35_7 (Lambda)              (None, 25, 25, 320)  0           block35_6_ac[0][0]               \n",
            "                                                                 block35_7_conv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block35_7_ac (Activation)       (None, 25, 25, 320)  0           block35_7[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 25, 25, 32)   10240       block35_7_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_57 (BatchNo (None, 25, 25, 32)   96          conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 25, 25, 32)   0           batch_normalization_57[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 25, 25, 32)   10240       block35_7_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 25, 25, 48)   13824       activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_55 (BatchNo (None, 25, 25, 32)   96          conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_58 (BatchNo (None, 25, 25, 48)   144         conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 25, 25, 32)   0           batch_normalization_55[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 25, 25, 48)   0           batch_normalization_58[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 25, 25, 32)   10240       block35_7_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 25, 25, 32)   9216        activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 25, 25, 64)   27648       activation_58[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_54 (BatchNo (None, 25, 25, 32)   96          conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_56 (BatchNo (None, 25, 25, 32)   96          conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_59 (BatchNo (None, 25, 25, 64)   192         conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 25, 25, 32)   0           batch_normalization_54[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 25, 25, 32)   0           batch_normalization_56[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 25, 25, 64)   0           batch_normalization_59[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "block35_8_mixed (Concatenate)   (None, 25, 25, 128)  0           activation_54[0][0]              \n",
            "                                                                 activation_56[0][0]              \n",
            "                                                                 activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block35_8_conv (Conv2D)         (None, 25, 25, 320)  41280       block35_8_mixed[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block35_8 (Lambda)              (None, 25, 25, 320)  0           block35_7_ac[0][0]               \n",
            "                                                                 block35_8_conv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block35_8_ac (Activation)       (None, 25, 25, 320)  0           block35_8[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 25, 25, 32)   10240       block35_8_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_63 (BatchNo (None, 25, 25, 32)   96          conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 25, 25, 32)   0           batch_normalization_63[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 25, 25, 32)   10240       block35_8_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 25, 25, 48)   13824       activation_63[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_61 (BatchNo (None, 25, 25, 32)   96          conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_64 (BatchNo (None, 25, 25, 48)   144         conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 25, 25, 32)   0           batch_normalization_61[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 25, 25, 48)   0           batch_normalization_64[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 25, 25, 32)   10240       block35_8_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 25, 25, 32)   9216        activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 25, 25, 64)   27648       activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_60 (BatchNo (None, 25, 25, 32)   96          conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_62 (BatchNo (None, 25, 25, 32)   96          conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_65 (BatchNo (None, 25, 25, 64)   192         conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 25, 25, 32)   0           batch_normalization_60[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 25, 25, 32)   0           batch_normalization_62[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 25, 25, 64)   0           batch_normalization_65[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "block35_9_mixed (Concatenate)   (None, 25, 25, 128)  0           activation_60[0][0]              \n",
            "                                                                 activation_62[0][0]              \n",
            "                                                                 activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block35_9_conv (Conv2D)         (None, 25, 25, 320)  41280       block35_9_mixed[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block35_9 (Lambda)              (None, 25, 25, 320)  0           block35_8_ac[0][0]               \n",
            "                                                                 block35_9_conv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block35_9_ac (Activation)       (None, 25, 25, 320)  0           block35_9[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 25, 25, 32)   10240       block35_9_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_69 (BatchNo (None, 25, 25, 32)   96          conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 25, 25, 32)   0           batch_normalization_69[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 25, 25, 32)   10240       block35_9_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_70 (Conv2D)              (None, 25, 25, 48)   13824       activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_67 (BatchNo (None, 25, 25, 32)   96          conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_70 (BatchNo (None, 25, 25, 48)   144         conv2d_70[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 25, 25, 32)   0           batch_normalization_67[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_70 (Activation)      (None, 25, 25, 48)   0           batch_normalization_70[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 25, 25, 32)   10240       block35_9_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 25, 25, 32)   9216        activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_71 (Conv2D)              (None, 25, 25, 64)   27648       activation_70[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_66 (BatchNo (None, 25, 25, 32)   96          conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_68 (BatchNo (None, 25, 25, 32)   96          conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_71 (BatchNo (None, 25, 25, 64)   192         conv2d_71[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 25, 25, 32)   0           batch_normalization_66[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 25, 25, 32)   0           batch_normalization_68[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_71 (Activation)      (None, 25, 25, 64)   0           batch_normalization_71[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "block35_10_mixed (Concatenate)  (None, 25, 25, 128)  0           activation_66[0][0]              \n",
            "                                                                 activation_68[0][0]              \n",
            "                                                                 activation_71[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block35_10_conv (Conv2D)        (None, 25, 25, 320)  41280       block35_10_mixed[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block35_10 (Lambda)             (None, 25, 25, 320)  0           block35_9_ac[0][0]               \n",
            "                                                                 block35_10_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block35_10_ac (Activation)      (None, 25, 25, 320)  0           block35_10[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_73 (Conv2D)              (None, 25, 25, 256)  81920       block35_10_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_73 (BatchNo (None, 25, 25, 256)  768         conv2d_73[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_73 (Activation)      (None, 25, 25, 256)  0           batch_normalization_73[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_74 (Conv2D)              (None, 25, 25, 256)  589824      activation_73[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_74 (BatchNo (None, 25, 25, 256)  768         conv2d_74[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_74 (Activation)      (None, 25, 25, 256)  0           batch_normalization_74[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_72 (Conv2D)              (None, 12, 12, 384)  1105920     block35_10_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_75 (Conv2D)              (None, 12, 12, 384)  884736      activation_74[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_72 (BatchNo (None, 12, 12, 384)  1152        conv2d_72[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_75 (BatchNo (None, 12, 12, 384)  1152        conv2d_75[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_72 (Activation)      (None, 12, 12, 384)  0           batch_normalization_72[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_75 (Activation)      (None, 12, 12, 384)  0           batch_normalization_75[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 12, 12, 320)  0           block35_10_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed_6a (Concatenate)          (None, 12, 12, 1088) 0           activation_72[0][0]              \n",
            "                                                                 activation_75[0][0]              \n",
            "                                                                 max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_77 (Conv2D)              (None, 12, 12, 128)  139264      mixed_6a[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_77 (BatchNo (None, 12, 12, 128)  384         conv2d_77[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_77 (Activation)      (None, 12, 12, 128)  0           batch_normalization_77[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_78 (Conv2D)              (None, 12, 12, 160)  143360      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_78 (BatchNo (None, 12, 12, 160)  480         conv2d_78[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_78 (Activation)      (None, 12, 12, 160)  0           batch_normalization_78[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_76 (Conv2D)              (None, 12, 12, 192)  208896      mixed_6a[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_79 (Conv2D)              (None, 12, 12, 192)  215040      activation_78[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_76 (BatchNo (None, 12, 12, 192)  576         conv2d_76[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_79 (BatchNo (None, 12, 12, 192)  576         conv2d_79[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_76 (Activation)      (None, 12, 12, 192)  0           batch_normalization_76[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_79 (Activation)      (None, 12, 12, 192)  0           batch_normalization_79[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "block17_1_mixed (Concatenate)   (None, 12, 12, 384)  0           activation_76[0][0]              \n",
            "                                                                 activation_79[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block17_1_conv (Conv2D)         (None, 12, 12, 1088) 418880      block17_1_mixed[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_1 (Lambda)              (None, 12, 12, 1088) 0           mixed_6a[0][0]                   \n",
            "                                                                 block17_1_conv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_1_ac (Activation)       (None, 12, 12, 1088) 0           block17_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_81 (Conv2D)              (None, 12, 12, 128)  139264      block17_1_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_81 (BatchNo (None, 12, 12, 128)  384         conv2d_81[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_81 (Activation)      (None, 12, 12, 128)  0           batch_normalization_81[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_82 (Conv2D)              (None, 12, 12, 160)  143360      activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_82 (BatchNo (None, 12, 12, 160)  480         conv2d_82[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_82 (Activation)      (None, 12, 12, 160)  0           batch_normalization_82[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_80 (Conv2D)              (None, 12, 12, 192)  208896      block17_1_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_83 (Conv2D)              (None, 12, 12, 192)  215040      activation_82[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_80 (BatchNo (None, 12, 12, 192)  576         conv2d_80[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_83 (BatchNo (None, 12, 12, 192)  576         conv2d_83[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_80 (Activation)      (None, 12, 12, 192)  0           batch_normalization_80[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_83 (Activation)      (None, 12, 12, 192)  0           batch_normalization_83[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "block17_2_mixed (Concatenate)   (None, 12, 12, 384)  0           activation_80[0][0]              \n",
            "                                                                 activation_83[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block17_2_conv (Conv2D)         (None, 12, 12, 1088) 418880      block17_2_mixed[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_2 (Lambda)              (None, 12, 12, 1088) 0           block17_1_ac[0][0]               \n",
            "                                                                 block17_2_conv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_2_ac (Activation)       (None, 12, 12, 1088) 0           block17_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_85 (Conv2D)              (None, 12, 12, 128)  139264      block17_2_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_85 (BatchNo (None, 12, 12, 128)  384         conv2d_85[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_85 (Activation)      (None, 12, 12, 128)  0           batch_normalization_85[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_86 (Conv2D)              (None, 12, 12, 160)  143360      activation_85[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_86 (BatchNo (None, 12, 12, 160)  480         conv2d_86[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_86 (Activation)      (None, 12, 12, 160)  0           batch_normalization_86[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_84 (Conv2D)              (None, 12, 12, 192)  208896      block17_2_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_87 (Conv2D)              (None, 12, 12, 192)  215040      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_84 (BatchNo (None, 12, 12, 192)  576         conv2d_84[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_87 (BatchNo (None, 12, 12, 192)  576         conv2d_87[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_84 (Activation)      (None, 12, 12, 192)  0           batch_normalization_84[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_87 (Activation)      (None, 12, 12, 192)  0           batch_normalization_87[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "block17_3_mixed (Concatenate)   (None, 12, 12, 384)  0           activation_84[0][0]              \n",
            "                                                                 activation_87[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block17_3_conv (Conv2D)         (None, 12, 12, 1088) 418880      block17_3_mixed[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_3 (Lambda)              (None, 12, 12, 1088) 0           block17_2_ac[0][0]               \n",
            "                                                                 block17_3_conv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_3_ac (Activation)       (None, 12, 12, 1088) 0           block17_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_89 (Conv2D)              (None, 12, 12, 128)  139264      block17_3_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_89 (BatchNo (None, 12, 12, 128)  384         conv2d_89[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_89 (Activation)      (None, 12, 12, 128)  0           batch_normalization_89[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_90 (Conv2D)              (None, 12, 12, 160)  143360      activation_89[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_90 (BatchNo (None, 12, 12, 160)  480         conv2d_90[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_90 (Activation)      (None, 12, 12, 160)  0           batch_normalization_90[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_88 (Conv2D)              (None, 12, 12, 192)  208896      block17_3_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_91 (Conv2D)              (None, 12, 12, 192)  215040      activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_88 (BatchNo (None, 12, 12, 192)  576         conv2d_88[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_91 (BatchNo (None, 12, 12, 192)  576         conv2d_91[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_88 (Activation)      (None, 12, 12, 192)  0           batch_normalization_88[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_91 (Activation)      (None, 12, 12, 192)  0           batch_normalization_91[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "block17_4_mixed (Concatenate)   (None, 12, 12, 384)  0           activation_88[0][0]              \n",
            "                                                                 activation_91[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block17_4_conv (Conv2D)         (None, 12, 12, 1088) 418880      block17_4_mixed[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_4 (Lambda)              (None, 12, 12, 1088) 0           block17_3_ac[0][0]               \n",
            "                                                                 block17_4_conv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_4_ac (Activation)       (None, 12, 12, 1088) 0           block17_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_93 (Conv2D)              (None, 12, 12, 128)  139264      block17_4_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_93 (BatchNo (None, 12, 12, 128)  384         conv2d_93[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_93 (Activation)      (None, 12, 12, 128)  0           batch_normalization_93[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_94 (Conv2D)              (None, 12, 12, 160)  143360      activation_93[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_94 (BatchNo (None, 12, 12, 160)  480         conv2d_94[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_94 (Activation)      (None, 12, 12, 160)  0           batch_normalization_94[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_92 (Conv2D)              (None, 12, 12, 192)  208896      block17_4_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_95 (Conv2D)              (None, 12, 12, 192)  215040      activation_94[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_92 (BatchNo (None, 12, 12, 192)  576         conv2d_92[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_95 (BatchNo (None, 12, 12, 192)  576         conv2d_95[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_92 (Activation)      (None, 12, 12, 192)  0           batch_normalization_92[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_95 (Activation)      (None, 12, 12, 192)  0           batch_normalization_95[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "block17_5_mixed (Concatenate)   (None, 12, 12, 384)  0           activation_92[0][0]              \n",
            "                                                                 activation_95[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block17_5_conv (Conv2D)         (None, 12, 12, 1088) 418880      block17_5_mixed[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_5 (Lambda)              (None, 12, 12, 1088) 0           block17_4_ac[0][0]               \n",
            "                                                                 block17_5_conv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_5_ac (Activation)       (None, 12, 12, 1088) 0           block17_5[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_97 (Conv2D)              (None, 12, 12, 128)  139264      block17_5_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_97 (BatchNo (None, 12, 12, 128)  384         conv2d_97[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_97 (Activation)      (None, 12, 12, 128)  0           batch_normalization_97[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_98 (Conv2D)              (None, 12, 12, 160)  143360      activation_97[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_98 (BatchNo (None, 12, 12, 160)  480         conv2d_98[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_98 (Activation)      (None, 12, 12, 160)  0           batch_normalization_98[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_96 (Conv2D)              (None, 12, 12, 192)  208896      block17_5_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_99 (Conv2D)              (None, 12, 12, 192)  215040      activation_98[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_96 (BatchNo (None, 12, 12, 192)  576         conv2d_96[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_99 (BatchNo (None, 12, 12, 192)  576         conv2d_99[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_96 (Activation)      (None, 12, 12, 192)  0           batch_normalization_96[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_99 (Activation)      (None, 12, 12, 192)  0           batch_normalization_99[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "block17_6_mixed (Concatenate)   (None, 12, 12, 384)  0           activation_96[0][0]              \n",
            "                                                                 activation_99[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block17_6_conv (Conv2D)         (None, 12, 12, 1088) 418880      block17_6_mixed[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_6 (Lambda)              (None, 12, 12, 1088) 0           block17_5_ac[0][0]               \n",
            "                                                                 block17_6_conv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_6_ac (Activation)       (None, 12, 12, 1088) 0           block17_6[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_101 (Conv2D)             (None, 12, 12, 128)  139264      block17_6_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_101 (BatchN (None, 12, 12, 128)  384         conv2d_101[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_101 (Activation)     (None, 12, 12, 128)  0           batch_normalization_101[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_102 (Conv2D)             (None, 12, 12, 160)  143360      activation_101[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_102 (BatchN (None, 12, 12, 160)  480         conv2d_102[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_102 (Activation)     (None, 12, 12, 160)  0           batch_normalization_102[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_100 (Conv2D)             (None, 12, 12, 192)  208896      block17_6_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_103 (Conv2D)             (None, 12, 12, 192)  215040      activation_102[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_100 (BatchN (None, 12, 12, 192)  576         conv2d_100[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_103 (BatchN (None, 12, 12, 192)  576         conv2d_103[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_100 (Activation)     (None, 12, 12, 192)  0           batch_normalization_100[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_103 (Activation)     (None, 12, 12, 192)  0           batch_normalization_103[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block17_7_mixed (Concatenate)   (None, 12, 12, 384)  0           activation_100[0][0]             \n",
            "                                                                 activation_103[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_7_conv (Conv2D)         (None, 12, 12, 1088) 418880      block17_7_mixed[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_7 (Lambda)              (None, 12, 12, 1088) 0           block17_6_ac[0][0]               \n",
            "                                                                 block17_7_conv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_7_ac (Activation)       (None, 12, 12, 1088) 0           block17_7[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_105 (Conv2D)             (None, 12, 12, 128)  139264      block17_7_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_105 (BatchN (None, 12, 12, 128)  384         conv2d_105[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_105 (Activation)     (None, 12, 12, 128)  0           batch_normalization_105[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_106 (Conv2D)             (None, 12, 12, 160)  143360      activation_105[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_106 (BatchN (None, 12, 12, 160)  480         conv2d_106[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_106 (Activation)     (None, 12, 12, 160)  0           batch_normalization_106[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_104 (Conv2D)             (None, 12, 12, 192)  208896      block17_7_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_107 (Conv2D)             (None, 12, 12, 192)  215040      activation_106[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_104 (BatchN (None, 12, 12, 192)  576         conv2d_104[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_107 (BatchN (None, 12, 12, 192)  576         conv2d_107[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_104 (Activation)     (None, 12, 12, 192)  0           batch_normalization_104[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_107 (Activation)     (None, 12, 12, 192)  0           batch_normalization_107[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block17_8_mixed (Concatenate)   (None, 12, 12, 384)  0           activation_104[0][0]             \n",
            "                                                                 activation_107[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_8_conv (Conv2D)         (None, 12, 12, 1088) 418880      block17_8_mixed[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_8 (Lambda)              (None, 12, 12, 1088) 0           block17_7_ac[0][0]               \n",
            "                                                                 block17_8_conv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_8_ac (Activation)       (None, 12, 12, 1088) 0           block17_8[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_109 (Conv2D)             (None, 12, 12, 128)  139264      block17_8_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_109 (BatchN (None, 12, 12, 128)  384         conv2d_109[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_109 (Activation)     (None, 12, 12, 128)  0           batch_normalization_109[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_110 (Conv2D)             (None, 12, 12, 160)  143360      activation_109[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_110 (BatchN (None, 12, 12, 160)  480         conv2d_110[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_110 (Activation)     (None, 12, 12, 160)  0           batch_normalization_110[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_108 (Conv2D)             (None, 12, 12, 192)  208896      block17_8_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_111 (Conv2D)             (None, 12, 12, 192)  215040      activation_110[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_108 (BatchN (None, 12, 12, 192)  576         conv2d_108[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_111 (BatchN (None, 12, 12, 192)  576         conv2d_111[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_108 (Activation)     (None, 12, 12, 192)  0           batch_normalization_108[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_111 (Activation)     (None, 12, 12, 192)  0           batch_normalization_111[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block17_9_mixed (Concatenate)   (None, 12, 12, 384)  0           activation_108[0][0]             \n",
            "                                                                 activation_111[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_9_conv (Conv2D)         (None, 12, 12, 1088) 418880      block17_9_mixed[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_9 (Lambda)              (None, 12, 12, 1088) 0           block17_8_ac[0][0]               \n",
            "                                                                 block17_9_conv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_9_ac (Activation)       (None, 12, 12, 1088) 0           block17_9[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_113 (Conv2D)             (None, 12, 12, 128)  139264      block17_9_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_113 (BatchN (None, 12, 12, 128)  384         conv2d_113[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_113 (Activation)     (None, 12, 12, 128)  0           batch_normalization_113[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_114 (Conv2D)             (None, 12, 12, 160)  143360      activation_113[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_114 (BatchN (None, 12, 12, 160)  480         conv2d_114[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_114 (Activation)     (None, 12, 12, 160)  0           batch_normalization_114[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_112 (Conv2D)             (None, 12, 12, 192)  208896      block17_9_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_115 (Conv2D)             (None, 12, 12, 192)  215040      activation_114[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_112 (BatchN (None, 12, 12, 192)  576         conv2d_112[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_115 (BatchN (None, 12, 12, 192)  576         conv2d_115[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_112 (Activation)     (None, 12, 12, 192)  0           batch_normalization_112[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_115 (Activation)     (None, 12, 12, 192)  0           batch_normalization_115[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block17_10_mixed (Concatenate)  (None, 12, 12, 384)  0           activation_112[0][0]             \n",
            "                                                                 activation_115[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_10_conv (Conv2D)        (None, 12, 12, 1088) 418880      block17_10_mixed[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block17_10 (Lambda)             (None, 12, 12, 1088) 0           block17_9_ac[0][0]               \n",
            "                                                                 block17_10_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_10_ac (Activation)      (None, 12, 12, 1088) 0           block17_10[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_117 (Conv2D)             (None, 12, 12, 128)  139264      block17_10_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_117 (BatchN (None, 12, 12, 128)  384         conv2d_117[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_117 (Activation)     (None, 12, 12, 128)  0           batch_normalization_117[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_118 (Conv2D)             (None, 12, 12, 160)  143360      activation_117[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_118 (BatchN (None, 12, 12, 160)  480         conv2d_118[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_118 (Activation)     (None, 12, 12, 160)  0           batch_normalization_118[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_116 (Conv2D)             (None, 12, 12, 192)  208896      block17_10_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_119 (Conv2D)             (None, 12, 12, 192)  215040      activation_118[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_116 (BatchN (None, 12, 12, 192)  576         conv2d_116[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_119 (BatchN (None, 12, 12, 192)  576         conv2d_119[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_116 (Activation)     (None, 12, 12, 192)  0           batch_normalization_116[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_119 (Activation)     (None, 12, 12, 192)  0           batch_normalization_119[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block17_11_mixed (Concatenate)  (None, 12, 12, 384)  0           activation_116[0][0]             \n",
            "                                                                 activation_119[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_11_conv (Conv2D)        (None, 12, 12, 1088) 418880      block17_11_mixed[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block17_11 (Lambda)             (None, 12, 12, 1088) 0           block17_10_ac[0][0]              \n",
            "                                                                 block17_11_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_11_ac (Activation)      (None, 12, 12, 1088) 0           block17_11[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_121 (Conv2D)             (None, 12, 12, 128)  139264      block17_11_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_121 (BatchN (None, 12, 12, 128)  384         conv2d_121[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_121 (Activation)     (None, 12, 12, 128)  0           batch_normalization_121[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_122 (Conv2D)             (None, 12, 12, 160)  143360      activation_121[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_122 (BatchN (None, 12, 12, 160)  480         conv2d_122[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_122 (Activation)     (None, 12, 12, 160)  0           batch_normalization_122[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_120 (Conv2D)             (None, 12, 12, 192)  208896      block17_11_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_123 (Conv2D)             (None, 12, 12, 192)  215040      activation_122[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_120 (BatchN (None, 12, 12, 192)  576         conv2d_120[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_123 (BatchN (None, 12, 12, 192)  576         conv2d_123[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_120 (Activation)     (None, 12, 12, 192)  0           batch_normalization_120[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_123 (Activation)     (None, 12, 12, 192)  0           batch_normalization_123[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block17_12_mixed (Concatenate)  (None, 12, 12, 384)  0           activation_120[0][0]             \n",
            "                                                                 activation_123[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_12_conv (Conv2D)        (None, 12, 12, 1088) 418880      block17_12_mixed[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block17_12 (Lambda)             (None, 12, 12, 1088) 0           block17_11_ac[0][0]              \n",
            "                                                                 block17_12_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_12_ac (Activation)      (None, 12, 12, 1088) 0           block17_12[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_125 (Conv2D)             (None, 12, 12, 128)  139264      block17_12_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_125 (BatchN (None, 12, 12, 128)  384         conv2d_125[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_125 (Activation)     (None, 12, 12, 128)  0           batch_normalization_125[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_126 (Conv2D)             (None, 12, 12, 160)  143360      activation_125[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_126 (BatchN (None, 12, 12, 160)  480         conv2d_126[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_126 (Activation)     (None, 12, 12, 160)  0           batch_normalization_126[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_124 (Conv2D)             (None, 12, 12, 192)  208896      block17_12_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_127 (Conv2D)             (None, 12, 12, 192)  215040      activation_126[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_124 (BatchN (None, 12, 12, 192)  576         conv2d_124[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_127 (BatchN (None, 12, 12, 192)  576         conv2d_127[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_124 (Activation)     (None, 12, 12, 192)  0           batch_normalization_124[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_127 (Activation)     (None, 12, 12, 192)  0           batch_normalization_127[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block17_13_mixed (Concatenate)  (None, 12, 12, 384)  0           activation_124[0][0]             \n",
            "                                                                 activation_127[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_13_conv (Conv2D)        (None, 12, 12, 1088) 418880      block17_13_mixed[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block17_13 (Lambda)             (None, 12, 12, 1088) 0           block17_12_ac[0][0]              \n",
            "                                                                 block17_13_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_13_ac (Activation)      (None, 12, 12, 1088) 0           block17_13[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_129 (Conv2D)             (None, 12, 12, 128)  139264      block17_13_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_129 (BatchN (None, 12, 12, 128)  384         conv2d_129[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_129 (Activation)     (None, 12, 12, 128)  0           batch_normalization_129[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_130 (Conv2D)             (None, 12, 12, 160)  143360      activation_129[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_130 (BatchN (None, 12, 12, 160)  480         conv2d_130[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_130 (Activation)     (None, 12, 12, 160)  0           batch_normalization_130[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_128 (Conv2D)             (None, 12, 12, 192)  208896      block17_13_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_131 (Conv2D)             (None, 12, 12, 192)  215040      activation_130[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_128 (BatchN (None, 12, 12, 192)  576         conv2d_128[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_131 (BatchN (None, 12, 12, 192)  576         conv2d_131[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_128 (Activation)     (None, 12, 12, 192)  0           batch_normalization_128[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_131 (Activation)     (None, 12, 12, 192)  0           batch_normalization_131[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block17_14_mixed (Concatenate)  (None, 12, 12, 384)  0           activation_128[0][0]             \n",
            "                                                                 activation_131[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_14_conv (Conv2D)        (None, 12, 12, 1088) 418880      block17_14_mixed[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block17_14 (Lambda)             (None, 12, 12, 1088) 0           block17_13_ac[0][0]              \n",
            "                                                                 block17_14_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_14_ac (Activation)      (None, 12, 12, 1088) 0           block17_14[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_133 (Conv2D)             (None, 12, 12, 128)  139264      block17_14_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_133 (BatchN (None, 12, 12, 128)  384         conv2d_133[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_133 (Activation)     (None, 12, 12, 128)  0           batch_normalization_133[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_134 (Conv2D)             (None, 12, 12, 160)  143360      activation_133[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_134 (BatchN (None, 12, 12, 160)  480         conv2d_134[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_134 (Activation)     (None, 12, 12, 160)  0           batch_normalization_134[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_132 (Conv2D)             (None, 12, 12, 192)  208896      block17_14_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_135 (Conv2D)             (None, 12, 12, 192)  215040      activation_134[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_132 (BatchN (None, 12, 12, 192)  576         conv2d_132[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_135 (BatchN (None, 12, 12, 192)  576         conv2d_135[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_132 (Activation)     (None, 12, 12, 192)  0           batch_normalization_132[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_135 (Activation)     (None, 12, 12, 192)  0           batch_normalization_135[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block17_15_mixed (Concatenate)  (None, 12, 12, 384)  0           activation_132[0][0]             \n",
            "                                                                 activation_135[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_15_conv (Conv2D)        (None, 12, 12, 1088) 418880      block17_15_mixed[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block17_15 (Lambda)             (None, 12, 12, 1088) 0           block17_14_ac[0][0]              \n",
            "                                                                 block17_15_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_15_ac (Activation)      (None, 12, 12, 1088) 0           block17_15[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_137 (Conv2D)             (None, 12, 12, 128)  139264      block17_15_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_137 (BatchN (None, 12, 12, 128)  384         conv2d_137[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_137 (Activation)     (None, 12, 12, 128)  0           batch_normalization_137[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_138 (Conv2D)             (None, 12, 12, 160)  143360      activation_137[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_138 (BatchN (None, 12, 12, 160)  480         conv2d_138[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_138 (Activation)     (None, 12, 12, 160)  0           batch_normalization_138[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_136 (Conv2D)             (None, 12, 12, 192)  208896      block17_15_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_139 (Conv2D)             (None, 12, 12, 192)  215040      activation_138[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_136 (BatchN (None, 12, 12, 192)  576         conv2d_136[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_139 (BatchN (None, 12, 12, 192)  576         conv2d_139[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_136 (Activation)     (None, 12, 12, 192)  0           batch_normalization_136[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_139 (Activation)     (None, 12, 12, 192)  0           batch_normalization_139[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block17_16_mixed (Concatenate)  (None, 12, 12, 384)  0           activation_136[0][0]             \n",
            "                                                                 activation_139[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_16_conv (Conv2D)        (None, 12, 12, 1088) 418880      block17_16_mixed[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block17_16 (Lambda)             (None, 12, 12, 1088) 0           block17_15_ac[0][0]              \n",
            "                                                                 block17_16_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_16_ac (Activation)      (None, 12, 12, 1088) 0           block17_16[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_141 (Conv2D)             (None, 12, 12, 128)  139264      block17_16_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_141 (BatchN (None, 12, 12, 128)  384         conv2d_141[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_141 (Activation)     (None, 12, 12, 128)  0           batch_normalization_141[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_142 (Conv2D)             (None, 12, 12, 160)  143360      activation_141[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_142 (BatchN (None, 12, 12, 160)  480         conv2d_142[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_142 (Activation)     (None, 12, 12, 160)  0           batch_normalization_142[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_140 (Conv2D)             (None, 12, 12, 192)  208896      block17_16_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_143 (Conv2D)             (None, 12, 12, 192)  215040      activation_142[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_140 (BatchN (None, 12, 12, 192)  576         conv2d_140[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_143 (BatchN (None, 12, 12, 192)  576         conv2d_143[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_140 (Activation)     (None, 12, 12, 192)  0           batch_normalization_140[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_143 (Activation)     (None, 12, 12, 192)  0           batch_normalization_143[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block17_17_mixed (Concatenate)  (None, 12, 12, 384)  0           activation_140[0][0]             \n",
            "                                                                 activation_143[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_17_conv (Conv2D)        (None, 12, 12, 1088) 418880      block17_17_mixed[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block17_17 (Lambda)             (None, 12, 12, 1088) 0           block17_16_ac[0][0]              \n",
            "                                                                 block17_17_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_17_ac (Activation)      (None, 12, 12, 1088) 0           block17_17[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_145 (Conv2D)             (None, 12, 12, 128)  139264      block17_17_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_145 (BatchN (None, 12, 12, 128)  384         conv2d_145[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_145 (Activation)     (None, 12, 12, 128)  0           batch_normalization_145[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_146 (Conv2D)             (None, 12, 12, 160)  143360      activation_145[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_146 (BatchN (None, 12, 12, 160)  480         conv2d_146[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_146 (Activation)     (None, 12, 12, 160)  0           batch_normalization_146[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_144 (Conv2D)             (None, 12, 12, 192)  208896      block17_17_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_147 (Conv2D)             (None, 12, 12, 192)  215040      activation_146[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_144 (BatchN (None, 12, 12, 192)  576         conv2d_144[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_147 (BatchN (None, 12, 12, 192)  576         conv2d_147[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_144 (Activation)     (None, 12, 12, 192)  0           batch_normalization_144[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_147 (Activation)     (None, 12, 12, 192)  0           batch_normalization_147[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block17_18_mixed (Concatenate)  (None, 12, 12, 384)  0           activation_144[0][0]             \n",
            "                                                                 activation_147[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_18_conv (Conv2D)        (None, 12, 12, 1088) 418880      block17_18_mixed[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block17_18 (Lambda)             (None, 12, 12, 1088) 0           block17_17_ac[0][0]              \n",
            "                                                                 block17_18_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_18_ac (Activation)      (None, 12, 12, 1088) 0           block17_18[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_149 (Conv2D)             (None, 12, 12, 128)  139264      block17_18_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_149 (BatchN (None, 12, 12, 128)  384         conv2d_149[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_149 (Activation)     (None, 12, 12, 128)  0           batch_normalization_149[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_150 (Conv2D)             (None, 12, 12, 160)  143360      activation_149[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_150 (BatchN (None, 12, 12, 160)  480         conv2d_150[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_150 (Activation)     (None, 12, 12, 160)  0           batch_normalization_150[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_148 (Conv2D)             (None, 12, 12, 192)  208896      block17_18_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_151 (Conv2D)             (None, 12, 12, 192)  215040      activation_150[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_148 (BatchN (None, 12, 12, 192)  576         conv2d_148[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_151 (BatchN (None, 12, 12, 192)  576         conv2d_151[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_148 (Activation)     (None, 12, 12, 192)  0           batch_normalization_148[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_151 (Activation)     (None, 12, 12, 192)  0           batch_normalization_151[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block17_19_mixed (Concatenate)  (None, 12, 12, 384)  0           activation_148[0][0]             \n",
            "                                                                 activation_151[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_19_conv (Conv2D)        (None, 12, 12, 1088) 418880      block17_19_mixed[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block17_19 (Lambda)             (None, 12, 12, 1088) 0           block17_18_ac[0][0]              \n",
            "                                                                 block17_19_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_19_ac (Activation)      (None, 12, 12, 1088) 0           block17_19[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_153 (Conv2D)             (None, 12, 12, 128)  139264      block17_19_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_153 (BatchN (None, 12, 12, 128)  384         conv2d_153[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_153 (Activation)     (None, 12, 12, 128)  0           batch_normalization_153[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_154 (Conv2D)             (None, 12, 12, 160)  143360      activation_153[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_154 (BatchN (None, 12, 12, 160)  480         conv2d_154[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_154 (Activation)     (None, 12, 12, 160)  0           batch_normalization_154[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_152 (Conv2D)             (None, 12, 12, 192)  208896      block17_19_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_155 (Conv2D)             (None, 12, 12, 192)  215040      activation_154[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_152 (BatchN (None, 12, 12, 192)  576         conv2d_152[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_155 (BatchN (None, 12, 12, 192)  576         conv2d_155[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_152 (Activation)     (None, 12, 12, 192)  0           batch_normalization_152[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_155 (Activation)     (None, 12, 12, 192)  0           batch_normalization_155[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block17_20_mixed (Concatenate)  (None, 12, 12, 384)  0           activation_152[0][0]             \n",
            "                                                                 activation_155[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_20_conv (Conv2D)        (None, 12, 12, 1088) 418880      block17_20_mixed[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block17_20 (Lambda)             (None, 12, 12, 1088) 0           block17_19_ac[0][0]              \n",
            "                                                                 block17_20_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_20_ac (Activation)      (None, 12, 12, 1088) 0           block17_20[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_160 (Conv2D)             (None, 12, 12, 256)  278528      block17_20_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_160 (BatchN (None, 12, 12, 256)  768         conv2d_160[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_160 (Activation)     (None, 12, 12, 256)  0           batch_normalization_160[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_156 (Conv2D)             (None, 12, 12, 256)  278528      block17_20_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_158 (Conv2D)             (None, 12, 12, 256)  278528      block17_20_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_161 (Conv2D)             (None, 12, 12, 288)  663552      activation_160[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_156 (BatchN (None, 12, 12, 256)  768         conv2d_156[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_158 (BatchN (None, 12, 12, 256)  768         conv2d_158[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_161 (BatchN (None, 12, 12, 288)  864         conv2d_161[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_156 (Activation)     (None, 12, 12, 256)  0           batch_normalization_156[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_158 (Activation)     (None, 12, 12, 256)  0           batch_normalization_158[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_161 (Activation)     (None, 12, 12, 288)  0           batch_normalization_161[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_157 (Conv2D)             (None, 5, 5, 384)    884736      activation_156[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_159 (Conv2D)             (None, 5, 5, 288)    663552      activation_158[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_162 (Conv2D)             (None, 5, 5, 320)    829440      activation_161[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_157 (BatchN (None, 5, 5, 384)    1152        conv2d_157[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_159 (BatchN (None, 5, 5, 288)    864         conv2d_159[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_162 (BatchN (None, 5, 5, 320)    960         conv2d_162[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_157 (Activation)     (None, 5, 5, 384)    0           batch_normalization_157[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_159 (Activation)     (None, 5, 5, 288)    0           batch_normalization_159[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_162 (Activation)     (None, 5, 5, 320)    0           batch_normalization_162[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 5, 5, 1088)   0           block17_20_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed_7a (Concatenate)          (None, 5, 5, 2080)   0           activation_157[0][0]             \n",
            "                                                                 activation_159[0][0]             \n",
            "                                                                 activation_162[0][0]             \n",
            "                                                                 max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_164 (Conv2D)             (None, 5, 5, 192)    399360      mixed_7a[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_164 (BatchN (None, 5, 5, 192)    576         conv2d_164[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_164 (Activation)     (None, 5, 5, 192)    0           batch_normalization_164[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_165 (Conv2D)             (None, 5, 5, 224)    129024      activation_164[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_165 (BatchN (None, 5, 5, 224)    672         conv2d_165[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_165 (Activation)     (None, 5, 5, 224)    0           batch_normalization_165[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_163 (Conv2D)             (None, 5, 5, 192)    399360      mixed_7a[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_166 (Conv2D)             (None, 5, 5, 256)    172032      activation_165[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_163 (BatchN (None, 5, 5, 192)    576         conv2d_163[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_166 (BatchN (None, 5, 5, 256)    768         conv2d_166[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_163 (Activation)     (None, 5, 5, 192)    0           batch_normalization_163[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_166 (Activation)     (None, 5, 5, 256)    0           batch_normalization_166[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block8_1_mixed (Concatenate)    (None, 5, 5, 448)    0           activation_163[0][0]             \n",
            "                                                                 activation_166[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_1_conv (Conv2D)          (None, 5, 5, 2080)   933920      block8_1_mixed[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_1 (Lambda)               (None, 5, 5, 2080)   0           mixed_7a[0][0]                   \n",
            "                                                                 block8_1_conv[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block8_1_ac (Activation)        (None, 5, 5, 2080)   0           block8_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_168 (Conv2D)             (None, 5, 5, 192)    399360      block8_1_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_168 (BatchN (None, 5, 5, 192)    576         conv2d_168[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_168 (Activation)     (None, 5, 5, 192)    0           batch_normalization_168[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_169 (Conv2D)             (None, 5, 5, 224)    129024      activation_168[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_169 (BatchN (None, 5, 5, 224)    672         conv2d_169[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_169 (Activation)     (None, 5, 5, 224)    0           batch_normalization_169[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_167 (Conv2D)             (None, 5, 5, 192)    399360      block8_1_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_170 (Conv2D)             (None, 5, 5, 256)    172032      activation_169[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_167 (BatchN (None, 5, 5, 192)    576         conv2d_167[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_170 (BatchN (None, 5, 5, 256)    768         conv2d_170[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_167 (Activation)     (None, 5, 5, 192)    0           batch_normalization_167[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_170 (Activation)     (None, 5, 5, 256)    0           batch_normalization_170[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block8_2_mixed (Concatenate)    (None, 5, 5, 448)    0           activation_167[0][0]             \n",
            "                                                                 activation_170[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_2_conv (Conv2D)          (None, 5, 5, 2080)   933920      block8_2_mixed[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_2 (Lambda)               (None, 5, 5, 2080)   0           block8_1_ac[0][0]                \n",
            "                                                                 block8_2_conv[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block8_2_ac (Activation)        (None, 5, 5, 2080)   0           block8_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_172 (Conv2D)             (None, 5, 5, 192)    399360      block8_2_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_172 (BatchN (None, 5, 5, 192)    576         conv2d_172[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_172 (Activation)     (None, 5, 5, 192)    0           batch_normalization_172[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_173 (Conv2D)             (None, 5, 5, 224)    129024      activation_172[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_173 (BatchN (None, 5, 5, 224)    672         conv2d_173[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_173 (Activation)     (None, 5, 5, 224)    0           batch_normalization_173[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_171 (Conv2D)             (None, 5, 5, 192)    399360      block8_2_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_174 (Conv2D)             (None, 5, 5, 256)    172032      activation_173[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_171 (BatchN (None, 5, 5, 192)    576         conv2d_171[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_174 (BatchN (None, 5, 5, 256)    768         conv2d_174[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_171 (Activation)     (None, 5, 5, 192)    0           batch_normalization_171[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_174 (Activation)     (None, 5, 5, 256)    0           batch_normalization_174[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block8_3_mixed (Concatenate)    (None, 5, 5, 448)    0           activation_171[0][0]             \n",
            "                                                                 activation_174[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_3_conv (Conv2D)          (None, 5, 5, 2080)   933920      block8_3_mixed[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_3 (Lambda)               (None, 5, 5, 2080)   0           block8_2_ac[0][0]                \n",
            "                                                                 block8_3_conv[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block8_3_ac (Activation)        (None, 5, 5, 2080)   0           block8_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_176 (Conv2D)             (None, 5, 5, 192)    399360      block8_3_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_176 (BatchN (None, 5, 5, 192)    576         conv2d_176[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_176 (Activation)     (None, 5, 5, 192)    0           batch_normalization_176[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_177 (Conv2D)             (None, 5, 5, 224)    129024      activation_176[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_177 (BatchN (None, 5, 5, 224)    672         conv2d_177[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_177 (Activation)     (None, 5, 5, 224)    0           batch_normalization_177[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_175 (Conv2D)             (None, 5, 5, 192)    399360      block8_3_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_178 (Conv2D)             (None, 5, 5, 256)    172032      activation_177[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_175 (BatchN (None, 5, 5, 192)    576         conv2d_175[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_178 (BatchN (None, 5, 5, 256)    768         conv2d_178[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_175 (Activation)     (None, 5, 5, 192)    0           batch_normalization_175[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_178 (Activation)     (None, 5, 5, 256)    0           batch_normalization_178[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block8_4_mixed (Concatenate)    (None, 5, 5, 448)    0           activation_175[0][0]             \n",
            "                                                                 activation_178[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_4_conv (Conv2D)          (None, 5, 5, 2080)   933920      block8_4_mixed[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_4 (Lambda)               (None, 5, 5, 2080)   0           block8_3_ac[0][0]                \n",
            "                                                                 block8_4_conv[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block8_4_ac (Activation)        (None, 5, 5, 2080)   0           block8_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_180 (Conv2D)             (None, 5, 5, 192)    399360      block8_4_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_180 (BatchN (None, 5, 5, 192)    576         conv2d_180[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_180 (Activation)     (None, 5, 5, 192)    0           batch_normalization_180[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_181 (Conv2D)             (None, 5, 5, 224)    129024      activation_180[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_181 (BatchN (None, 5, 5, 224)    672         conv2d_181[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_181 (Activation)     (None, 5, 5, 224)    0           batch_normalization_181[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_179 (Conv2D)             (None, 5, 5, 192)    399360      block8_4_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_182 (Conv2D)             (None, 5, 5, 256)    172032      activation_181[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_179 (BatchN (None, 5, 5, 192)    576         conv2d_179[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_182 (BatchN (None, 5, 5, 256)    768         conv2d_182[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_179 (Activation)     (None, 5, 5, 192)    0           batch_normalization_179[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_182 (Activation)     (None, 5, 5, 256)    0           batch_normalization_182[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block8_5_mixed (Concatenate)    (None, 5, 5, 448)    0           activation_179[0][0]             \n",
            "                                                                 activation_182[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_5_conv (Conv2D)          (None, 5, 5, 2080)   933920      block8_5_mixed[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_5 (Lambda)               (None, 5, 5, 2080)   0           block8_4_ac[0][0]                \n",
            "                                                                 block8_5_conv[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block8_5_ac (Activation)        (None, 5, 5, 2080)   0           block8_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_184 (Conv2D)             (None, 5, 5, 192)    399360      block8_5_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_184 (BatchN (None, 5, 5, 192)    576         conv2d_184[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_184 (Activation)     (None, 5, 5, 192)    0           batch_normalization_184[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_185 (Conv2D)             (None, 5, 5, 224)    129024      activation_184[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_185 (BatchN (None, 5, 5, 224)    672         conv2d_185[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_185 (Activation)     (None, 5, 5, 224)    0           batch_normalization_185[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_183 (Conv2D)             (None, 5, 5, 192)    399360      block8_5_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_186 (Conv2D)             (None, 5, 5, 256)    172032      activation_185[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_183 (BatchN (None, 5, 5, 192)    576         conv2d_183[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_186 (BatchN (None, 5, 5, 256)    768         conv2d_186[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_183 (Activation)     (None, 5, 5, 192)    0           batch_normalization_183[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_186 (Activation)     (None, 5, 5, 256)    0           batch_normalization_186[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block8_6_mixed (Concatenate)    (None, 5, 5, 448)    0           activation_183[0][0]             \n",
            "                                                                 activation_186[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_6_conv (Conv2D)          (None, 5, 5, 2080)   933920      block8_6_mixed[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_6 (Lambda)               (None, 5, 5, 2080)   0           block8_5_ac[0][0]                \n",
            "                                                                 block8_6_conv[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block8_6_ac (Activation)        (None, 5, 5, 2080)   0           block8_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_188 (Conv2D)             (None, 5, 5, 192)    399360      block8_6_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_188 (BatchN (None, 5, 5, 192)    576         conv2d_188[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_188 (Activation)     (None, 5, 5, 192)    0           batch_normalization_188[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_189 (Conv2D)             (None, 5, 5, 224)    129024      activation_188[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_189 (BatchN (None, 5, 5, 224)    672         conv2d_189[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_189 (Activation)     (None, 5, 5, 224)    0           batch_normalization_189[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_187 (Conv2D)             (None, 5, 5, 192)    399360      block8_6_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_190 (Conv2D)             (None, 5, 5, 256)    172032      activation_189[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_187 (BatchN (None, 5, 5, 192)    576         conv2d_187[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_190 (BatchN (None, 5, 5, 256)    768         conv2d_190[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_187 (Activation)     (None, 5, 5, 192)    0           batch_normalization_187[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_190 (Activation)     (None, 5, 5, 256)    0           batch_normalization_190[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block8_7_mixed (Concatenate)    (None, 5, 5, 448)    0           activation_187[0][0]             \n",
            "                                                                 activation_190[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_7_conv (Conv2D)          (None, 5, 5, 2080)   933920      block8_7_mixed[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_7 (Lambda)               (None, 5, 5, 2080)   0           block8_6_ac[0][0]                \n",
            "                                                                 block8_7_conv[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block8_7_ac (Activation)        (None, 5, 5, 2080)   0           block8_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_192 (Conv2D)             (None, 5, 5, 192)    399360      block8_7_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_192 (BatchN (None, 5, 5, 192)    576         conv2d_192[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_192 (Activation)     (None, 5, 5, 192)    0           batch_normalization_192[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_193 (Conv2D)             (None, 5, 5, 224)    129024      activation_192[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_193 (BatchN (None, 5, 5, 224)    672         conv2d_193[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_193 (Activation)     (None, 5, 5, 224)    0           batch_normalization_193[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_191 (Conv2D)             (None, 5, 5, 192)    399360      block8_7_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_194 (Conv2D)             (None, 5, 5, 256)    172032      activation_193[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_191 (BatchN (None, 5, 5, 192)    576         conv2d_191[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_194 (BatchN (None, 5, 5, 256)    768         conv2d_194[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_191 (Activation)     (None, 5, 5, 192)    0           batch_normalization_191[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_194 (Activation)     (None, 5, 5, 256)    0           batch_normalization_194[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block8_8_mixed (Concatenate)    (None, 5, 5, 448)    0           activation_191[0][0]             \n",
            "                                                                 activation_194[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_8_conv (Conv2D)          (None, 5, 5, 2080)   933920      block8_8_mixed[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_8 (Lambda)               (None, 5, 5, 2080)   0           block8_7_ac[0][0]                \n",
            "                                                                 block8_8_conv[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block8_8_ac (Activation)        (None, 5, 5, 2080)   0           block8_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_196 (Conv2D)             (None, 5, 5, 192)    399360      block8_8_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_196 (BatchN (None, 5, 5, 192)    576         conv2d_196[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_196 (Activation)     (None, 5, 5, 192)    0           batch_normalization_196[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_197 (Conv2D)             (None, 5, 5, 224)    129024      activation_196[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_197 (BatchN (None, 5, 5, 224)    672         conv2d_197[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_197 (Activation)     (None, 5, 5, 224)    0           batch_normalization_197[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_195 (Conv2D)             (None, 5, 5, 192)    399360      block8_8_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_198 (Conv2D)             (None, 5, 5, 256)    172032      activation_197[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_195 (BatchN (None, 5, 5, 192)    576         conv2d_195[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_198 (BatchN (None, 5, 5, 256)    768         conv2d_198[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_195 (Activation)     (None, 5, 5, 192)    0           batch_normalization_195[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_198 (Activation)     (None, 5, 5, 256)    0           batch_normalization_198[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block8_9_mixed (Concatenate)    (None, 5, 5, 448)    0           activation_195[0][0]             \n",
            "                                                                 activation_198[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_9_conv (Conv2D)          (None, 5, 5, 2080)   933920      block8_9_mixed[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_9 (Lambda)               (None, 5, 5, 2080)   0           block8_8_ac[0][0]                \n",
            "                                                                 block8_9_conv[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block8_9_ac (Activation)        (None, 5, 5, 2080)   0           block8_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_200 (Conv2D)             (None, 5, 5, 192)    399360      block8_9_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_200 (BatchN (None, 5, 5, 192)    576         conv2d_200[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_200 (Activation)     (None, 5, 5, 192)    0           batch_normalization_200[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_201 (Conv2D)             (None, 5, 5, 224)    129024      activation_200[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_201 (BatchN (None, 5, 5, 224)    672         conv2d_201[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_201 (Activation)     (None, 5, 5, 224)    0           batch_normalization_201[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_199 (Conv2D)             (None, 5, 5, 192)    399360      block8_9_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_202 (Conv2D)             (None, 5, 5, 256)    172032      activation_201[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_199 (BatchN (None, 5, 5, 192)    576         conv2d_199[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_202 (BatchN (None, 5, 5, 256)    768         conv2d_202[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_199 (Activation)     (None, 5, 5, 192)    0           batch_normalization_199[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_202 (Activation)     (None, 5, 5, 256)    0           batch_normalization_202[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block8_10_mixed (Concatenate)   (None, 5, 5, 448)    0           activation_199[0][0]             \n",
            "                                                                 activation_202[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_10_conv (Conv2D)         (None, 5, 5, 2080)   933920      block8_10_mixed[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block8_10 (Lambda)              (None, 5, 5, 2080)   0           block8_9_ac[0][0]                \n",
            "                                                                 block8_10_conv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv_7b (Conv2D)                (None, 5, 5, 1536)   3194880     block8_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv_7b_bn (BatchNormalization) (None, 5, 5, 1536)   4608        conv_7b[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv_7b_ac (Activation)         (None, 5, 5, 1536)   0           conv_7b_bn[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 54,336,736\n",
            "Trainable params: 54,276,192\n",
            "Non-trainable params: 60,544\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninception_resnet_v2 (Functio (None, 5, 5, 1536)        54336736  \n_________________________________________________________________\nflatten (Flatten)            (None, 38400)             0         \n_________________________________________________________________\ndropout (Dropout)            (None, 38400)             0         \n_________________________________________________________________\ndense (Dense)                (None, 1024)              39322624  \n_________________________________________________________________\ndropout_1 (Dropout)          (None, 1024)              0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 512)               524800    \n_________________________________________________________________\ndropout_2 (Dropout)          (None, 512)               0         \n_________________________________________________________________\ndense_2 (Dense)              (None, 4)                 2052      \n=================================================================\nTotal params: 94,186,212\nTrainable params: 94,125,668\nNon-trainable params: 60,544\n_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = Sequential()\n",
        "model.add(vgg19_arch)\n",
        "model.add(Flatten())\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(1024, activation='relu', kernel_constraint=maxnorm(3)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(512, activation='relu', kernel_constraint=maxnorm(3)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(nClasses, activation='softmax'))\n",
        "\n",
        "model.compile(loss=keras.losses.categorical_crossentropy, \n",
        "    optimizer=keras.optimizers.Adagrad(lr=INIT_LR, decay=INIT_LR / 100),\n",
        "    metrics=['accuracy'])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygORJ3K7eh_q"
      },
      "source": [
        "step_train=image_train.n//image_train.batch_size\n",
        "step_validation=image_validation.n//image_validation.batch_size"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mq88uIhnfP4V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c151abb-f46d-444c-df1f-537453f6bbfd"
      },
      "source": [
        "#EMPEZANDO EL ENTRENAMIENTO\n",
        "history=model.fit_generator(image_train,\n",
        "                  steps_per_epoch=step_train,\n",
        "                  epochs=epochs,\n",
        "                  #callbacks=[early_stop, tfdocs.modeling.EpochDots()],\n",
        "                  verbose=1,\n",
        "                  validation_data=image_validation,\n",
        "                  validation_steps=step_validation\n",
        "                  )\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From <ipython-input-6-504f4b3edfa2>:2: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use Model.fit, which supports generators.\n",
            "Epoch 1/100\n",
            "47/47 [==============================] - 27s 579ms/step - loss: 1.1961 - accuracy: 0.4820 - val_loss: 1.4836 - val_accuracy: 0.2547\n",
            "Epoch 2/100\n",
            "47/47 [==============================] - 23s 497ms/step - loss: 0.8373 - accuracy: 0.6392 - val_loss: 1.8860 - val_accuracy: 0.2307\n",
            "Epoch 3/100\n",
            "47/47 [==============================] - 24s 501ms/step - loss: 0.6758 - accuracy: 0.7185 - val_loss: 2.4320 - val_accuracy: 0.2280\n",
            "Epoch 4/100\n",
            "47/47 [==============================] - 23s 492ms/step - loss: 0.6002 - accuracy: 0.7515 - val_loss: 2.5281 - val_accuracy: 0.2240\n",
            "Epoch 5/100\n",
            "47/47 [==============================] - 23s 497ms/step - loss: 0.5207 - accuracy: 0.7819 - val_loss: 2.7459 - val_accuracy: 0.2280\n",
            "Epoch 6/100\n",
            "47/47 [==============================] - 23s 493ms/step - loss: 0.5231 - accuracy: 0.8008 - val_loss: 3.4185 - val_accuracy: 0.2280\n",
            "Epoch 7/100\n",
            "47/47 [==============================] - 23s 500ms/step - loss: 0.4791 - accuracy: 0.7999 - val_loss: 3.5034 - val_accuracy: 0.2280\n",
            "Epoch 8/100\n",
            "47/47 [==============================] - 24s 503ms/step - loss: 0.4637 - accuracy: 0.8111 - val_loss: 3.0018 - val_accuracy: 0.2333\n",
            "Epoch 9/100\n",
            "47/47 [==============================] - 23s 494ms/step - loss: 0.4570 - accuracy: 0.8136 - val_loss: 2.2253 - val_accuracy: 0.3467\n",
            "Epoch 10/100\n",
            "47/47 [==============================] - 23s 496ms/step - loss: 0.4173 - accuracy: 0.8243 - val_loss: 1.7640 - val_accuracy: 0.4053\n",
            "Epoch 11/100\n",
            "47/47 [==============================] - 23s 491ms/step - loss: 0.4126 - accuracy: 0.8290 - val_loss: 1.2003 - val_accuracy: 0.5120\n",
            "Epoch 12/100\n",
            "47/47 [==============================] - 23s 493ms/step - loss: 0.3868 - accuracy: 0.8419 - val_loss: 1.0875 - val_accuracy: 0.5360\n",
            "Epoch 13/100\n",
            "47/47 [==============================] - 23s 496ms/step - loss: 0.3633 - accuracy: 0.8526 - val_loss: 0.5872 - val_accuracy: 0.7347\n",
            "Epoch 14/100\n",
            "47/47 [==============================] - 23s 493ms/step - loss: 0.3590 - accuracy: 0.8557 - val_loss: 0.5090 - val_accuracy: 0.7920\n",
            "Epoch 15/100\n",
            "47/47 [==============================] - 23s 493ms/step - loss: 0.3580 - accuracy: 0.8483 - val_loss: 0.3978 - val_accuracy: 0.8400\n",
            "Epoch 16/100\n",
            "47/47 [==============================] - 23s 493ms/step - loss: 0.3343 - accuracy: 0.8603 - val_loss: 0.4539 - val_accuracy: 0.8267\n",
            "Epoch 17/100\n",
            "47/47 [==============================] - 23s 496ms/step - loss: 0.3482 - accuracy: 0.8663 - val_loss: 0.4053 - val_accuracy: 0.8413\n",
            "Epoch 18/100\n",
            "47/47 [==============================] - 23s 493ms/step - loss: 0.3282 - accuracy: 0.8728 - val_loss: 0.4020 - val_accuracy: 0.8413\n",
            "Epoch 19/100\n",
            "47/47 [==============================] - 23s 500ms/step - loss: 0.3083 - accuracy: 0.8796 - val_loss: 0.3927 - val_accuracy: 0.8440\n",
            "Epoch 20/100\n",
            "47/47 [==============================] - 23s 496ms/step - loss: 0.3172 - accuracy: 0.8616 - val_loss: 0.4173 - val_accuracy: 0.8413\n",
            "Epoch 21/100\n",
            "47/47 [==============================] - 23s 498ms/step - loss: 0.3050 - accuracy: 0.8796 - val_loss: 0.4881 - val_accuracy: 0.8027\n",
            "Epoch 22/100\n",
            "47/47 [==============================] - 23s 496ms/step - loss: 0.2945 - accuracy: 0.8839 - val_loss: 0.5607 - val_accuracy: 0.7920\n",
            "Epoch 23/100\n",
            "47/47 [==============================] - 23s 498ms/step - loss: 0.3007 - accuracy: 0.8766 - val_loss: 0.5113 - val_accuracy: 0.8067\n",
            "Epoch 24/100\n",
            "47/47 [==============================] - 23s 497ms/step - loss: 0.2793 - accuracy: 0.8959 - val_loss: 0.3584 - val_accuracy: 0.8573\n",
            "Epoch 25/100\n",
            "47/47 [==============================] - 23s 496ms/step - loss: 0.2667 - accuracy: 0.8912 - val_loss: 0.5459 - val_accuracy: 0.7867\n",
            "Epoch 26/100\n",
            "47/47 [==============================] - 24s 503ms/step - loss: 0.2794 - accuracy: 0.8895 - val_loss: 0.4501 - val_accuracy: 0.8267\n",
            "Epoch 27/100\n",
            "47/47 [==============================] - 23s 495ms/step - loss: 0.2597 - accuracy: 0.9070 - val_loss: 0.4328 - val_accuracy: 0.8333\n",
            "Epoch 28/100\n",
            "47/47 [==============================] - 23s 496ms/step - loss: 0.2679 - accuracy: 0.8976 - val_loss: 0.4575 - val_accuracy: 0.8213\n",
            "Epoch 29/100\n",
            "47/47 [==============================] - 23s 497ms/step - loss: 0.2494 - accuracy: 0.9010 - val_loss: 0.4512 - val_accuracy: 0.8347\n",
            "Epoch 30/100\n",
            "47/47 [==============================] - 23s 495ms/step - loss: 0.2572 - accuracy: 0.9010 - val_loss: 0.5166 - val_accuracy: 0.8147\n",
            "Epoch 31/100\n",
            "47/47 [==============================] - 23s 492ms/step - loss: 0.2362 - accuracy: 0.9102 - val_loss: 0.4367 - val_accuracy: 0.8547\n",
            "Epoch 32/100\n",
            "47/47 [==============================] - 23s 499ms/step - loss: 0.2586 - accuracy: 0.8955 - val_loss: 0.4708 - val_accuracy: 0.8267\n",
            "Epoch 33/100\n",
            "47/47 [==============================] - 23s 496ms/step - loss: 0.2305 - accuracy: 0.9070 - val_loss: 0.4086 - val_accuracy: 0.8493\n",
            "Epoch 34/100\n",
            "47/47 [==============================] - 23s 496ms/step - loss: 0.2464 - accuracy: 0.9083 - val_loss: 0.4148 - val_accuracy: 0.8427\n",
            "Epoch 35/100\n",
            "47/47 [==============================] - 23s 493ms/step - loss: 0.2394 - accuracy: 0.9062 - val_loss: 0.4488 - val_accuracy: 0.8267\n",
            "Epoch 36/100\n",
            "47/47 [==============================] - 24s 504ms/step - loss: 0.2289 - accuracy: 0.9143 - val_loss: 0.4070 - val_accuracy: 0.8573\n",
            "Epoch 37/100\n",
            "47/47 [==============================] - 23s 497ms/step - loss: 0.2259 - accuracy: 0.9165 - val_loss: 0.5092 - val_accuracy: 0.8240\n",
            "Epoch 38/100\n",
            "47/47 [==============================] - 24s 503ms/step - loss: 0.2316 - accuracy: 0.9040 - val_loss: 0.4675 - val_accuracy: 0.8373\n",
            "Epoch 39/100\n",
            "47/47 [==============================] - 23s 497ms/step - loss: 0.2202 - accuracy: 0.9147 - val_loss: 0.3972 - val_accuracy: 0.8600\n",
            "Epoch 40/100\n",
            "47/47 [==============================] - 23s 494ms/step - loss: 0.2184 - accuracy: 0.9147 - val_loss: 0.4230 - val_accuracy: 0.8547\n",
            "Epoch 41/100\n",
            "47/47 [==============================] - 23s 500ms/step - loss: 0.2052 - accuracy: 0.9165 - val_loss: 0.5447 - val_accuracy: 0.8080\n",
            "Epoch 42/100\n",
            "47/47 [==============================] - 24s 501ms/step - loss: 0.2091 - accuracy: 0.9220 - val_loss: 0.4683 - val_accuracy: 0.8333\n",
            "Epoch 43/100\n",
            "47/47 [==============================] - 23s 497ms/step - loss: 0.2101 - accuracy: 0.9203 - val_loss: 0.4943 - val_accuracy: 0.8253\n",
            "Epoch 44/100\n",
            "47/47 [==============================] - 24s 504ms/step - loss: 0.1913 - accuracy: 0.9246 - val_loss: 0.4170 - val_accuracy: 0.8533\n",
            "Epoch 45/100\n",
            "47/47 [==============================] - 24s 501ms/step - loss: 0.2021 - accuracy: 0.9207 - val_loss: 0.4424 - val_accuracy: 0.8547\n",
            "Epoch 46/100\n",
            "47/47 [==============================] - 24s 502ms/step - loss: 0.1895 - accuracy: 0.9284 - val_loss: 0.4952 - val_accuracy: 0.8440\n",
            "Epoch 47/100\n",
            "47/47 [==============================] - 23s 497ms/step - loss: 0.1887 - accuracy: 0.9267 - val_loss: 0.5033 - val_accuracy: 0.8320\n",
            "Epoch 48/100\n",
            "47/47 [==============================] - 23s 497ms/step - loss: 0.1808 - accuracy: 0.9319 - val_loss: 0.4534 - val_accuracy: 0.8413\n",
            "Epoch 49/100\n",
            "47/47 [==============================] - 23s 498ms/step - loss: 0.1929 - accuracy: 0.9293 - val_loss: 0.5841 - val_accuracy: 0.8133\n",
            "Epoch 50/100\n",
            "47/47 [==============================] - 23s 500ms/step - loss: 0.1839 - accuracy: 0.9284 - val_loss: 0.5250 - val_accuracy: 0.8240\n",
            "Epoch 51/100\n",
            "47/47 [==============================] - 24s 502ms/step - loss: 0.1797 - accuracy: 0.9310 - val_loss: 0.5114 - val_accuracy: 0.8400\n",
            "Epoch 52/100\n",
            "47/47 [==============================] - 23s 496ms/step - loss: 0.1758 - accuracy: 0.9319 - val_loss: 0.4324 - val_accuracy: 0.8507\n",
            "Epoch 53/100\n",
            "47/47 [==============================] - 24s 501ms/step - loss: 0.1671 - accuracy: 0.9276 - val_loss: 0.5737 - val_accuracy: 0.8187\n",
            "Epoch 54/100\n",
            "47/47 [==============================] - 23s 498ms/step - loss: 0.1647 - accuracy: 0.9392 - val_loss: 0.4475 - val_accuracy: 0.8600\n",
            "Epoch 55/100\n",
            "47/47 [==============================] - 23s 498ms/step - loss: 0.1771 - accuracy: 0.9349 - val_loss: 0.4603 - val_accuracy: 0.8493\n",
            "Epoch 56/100\n",
            "47/47 [==============================] - 24s 500ms/step - loss: 0.1601 - accuracy: 0.9417 - val_loss: 0.4264 - val_accuracy: 0.8533\n",
            "Epoch 57/100\n",
            "47/47 [==============================] - 23s 499ms/step - loss: 0.1676 - accuracy: 0.9306 - val_loss: 0.5500 - val_accuracy: 0.8360\n",
            "Epoch 58/100\n",
            "47/47 [==============================] - 23s 500ms/step - loss: 0.1660 - accuracy: 0.9366 - val_loss: 0.5267 - val_accuracy: 0.8360\n",
            "Epoch 59/100\n",
            "47/47 [==============================] - 24s 500ms/step - loss: 0.1862 - accuracy: 0.9280 - val_loss: 0.4567 - val_accuracy: 0.8453\n",
            "Epoch 60/100\n",
            "47/47 [==============================] - 24s 501ms/step - loss: 0.1728 - accuracy: 0.9327 - val_loss: 0.4972 - val_accuracy: 0.8307\n",
            "Epoch 61/100\n",
            "47/47 [==============================] - 23s 498ms/step - loss: 0.1736 - accuracy: 0.9306 - val_loss: 0.5638 - val_accuracy: 0.8227\n",
            "Epoch 62/100\n",
            "47/47 [==============================] - 23s 500ms/step - loss: 0.1718 - accuracy: 0.9280 - val_loss: 0.4780 - val_accuracy: 0.8413\n",
            "Epoch 63/100\n",
            "47/47 [==============================] - 24s 502ms/step - loss: 0.1349 - accuracy: 0.9507 - val_loss: 0.4464 - val_accuracy: 0.8453\n",
            "Epoch 64/100\n",
            "47/47 [==============================] - 23s 497ms/step - loss: 0.1565 - accuracy: 0.9392 - val_loss: 0.4946 - val_accuracy: 0.8467\n",
            "Epoch 65/100\n",
            "47/47 [==============================] - 24s 507ms/step - loss: 0.1547 - accuracy: 0.9422 - val_loss: 0.5177 - val_accuracy: 0.8387\n",
            "Epoch 66/100\n",
            "47/47 [==============================] - 24s 503ms/step - loss: 0.1565 - accuracy: 0.9370 - val_loss: 0.4437 - val_accuracy: 0.8560\n",
            "Epoch 67/100\n",
            "47/47 [==============================] - 24s 500ms/step - loss: 0.1547 - accuracy: 0.9430 - val_loss: 0.4904 - val_accuracy: 0.8507\n",
            "Epoch 68/100\n",
            "47/47 [==============================] - 23s 496ms/step - loss: 0.1591 - accuracy: 0.9404 - val_loss: 0.4898 - val_accuracy: 0.8547\n",
            "Epoch 69/100\n",
            "47/47 [==============================] - 24s 507ms/step - loss: 0.1534 - accuracy: 0.9340 - val_loss: 0.4699 - val_accuracy: 0.8520\n",
            "Epoch 70/100\n",
            "47/47 [==============================] - 23s 497ms/step - loss: 0.1629 - accuracy: 0.9357 - val_loss: 0.5018 - val_accuracy: 0.8373\n",
            "Epoch 71/100\n",
            "47/47 [==============================] - 24s 504ms/step - loss: 0.1627 - accuracy: 0.9332 - val_loss: 0.4861 - val_accuracy: 0.8507\n",
            "Epoch 72/100\n",
            "47/47 [==============================] - 23s 499ms/step - loss: 0.1490 - accuracy: 0.9344 - val_loss: 0.4841 - val_accuracy: 0.8480\n",
            "Epoch 73/100\n",
            "47/47 [==============================] - 24s 501ms/step - loss: 0.1471 - accuracy: 0.9460 - val_loss: 0.5298 - val_accuracy: 0.8467\n",
            "Epoch 74/100\n",
            "47/47 [==============================] - 24s 507ms/step - loss: 0.1366 - accuracy: 0.9490 - val_loss: 0.5331 - val_accuracy: 0.8427\n",
            "Epoch 75/100\n",
            "47/47 [==============================] - 23s 495ms/step - loss: 0.1461 - accuracy: 0.9370 - val_loss: 0.5008 - val_accuracy: 0.8387\n",
            "Epoch 76/100\n",
            "47/47 [==============================] - 23s 500ms/step - loss: 0.1373 - accuracy: 0.9529 - val_loss: 0.4727 - val_accuracy: 0.8440\n",
            "Epoch 77/100\n",
            "47/47 [==============================] - 24s 502ms/step - loss: 0.1357 - accuracy: 0.9439 - val_loss: 0.5111 - val_accuracy: 0.8400\n",
            "Epoch 78/100\n",
            "47/47 [==============================] - 23s 498ms/step - loss: 0.1314 - accuracy: 0.9507 - val_loss: 0.4932 - val_accuracy: 0.8480\n",
            "Epoch 79/100\n",
            "47/47 [==============================] - 24s 511ms/step - loss: 0.1442 - accuracy: 0.9413 - val_loss: 0.5549 - val_accuracy: 0.8227\n",
            "Epoch 80/100\n",
            "47/47 [==============================] - 24s 505ms/step - loss: 0.1348 - accuracy: 0.9482 - val_loss: 0.4695 - val_accuracy: 0.8480\n",
            "Epoch 81/100\n",
            "47/47 [==============================] - 23s 499ms/step - loss: 0.1233 - accuracy: 0.9516 - val_loss: 0.4833 - val_accuracy: 0.8507\n",
            "Epoch 82/100\n",
            "47/47 [==============================] - 23s 500ms/step - loss: 0.1452 - accuracy: 0.9409 - val_loss: 0.4869 - val_accuracy: 0.8533\n",
            "Epoch 83/100\n",
            "47/47 [==============================] - 23s 495ms/step - loss: 0.1286 - accuracy: 0.9516 - val_loss: 0.5014 - val_accuracy: 0.8467\n",
            "Epoch 84/100\n",
            "47/47 [==============================] - 23s 498ms/step - loss: 0.1316 - accuracy: 0.9507 - val_loss: 0.5156 - val_accuracy: 0.8427\n",
            "Epoch 85/100\n",
            "47/47 [==============================] - 24s 503ms/step - loss: 0.1375 - accuracy: 0.9477 - val_loss: 0.5444 - val_accuracy: 0.8347\n",
            "Epoch 86/100\n",
            "47/47 [==============================] - 24s 504ms/step - loss: 0.1264 - accuracy: 0.9533 - val_loss: 0.4959 - val_accuracy: 0.8493\n",
            "Epoch 87/100\n",
            "47/47 [==============================] - 23s 499ms/step - loss: 0.1325 - accuracy: 0.9464 - val_loss: 0.4743 - val_accuracy: 0.8480\n",
            "Epoch 88/100\n",
            "47/47 [==============================] - 24s 504ms/step - loss: 0.1229 - accuracy: 0.9512 - val_loss: 0.5023 - val_accuracy: 0.8547\n",
            "Epoch 89/100\n",
            "47/47 [==============================] - 23s 499ms/step - loss: 0.1250 - accuracy: 0.9563 - val_loss: 0.5515 - val_accuracy: 0.8400\n",
            "Epoch 90/100\n",
            "47/47 [==============================] - 24s 503ms/step - loss: 0.1259 - accuracy: 0.9537 - val_loss: 0.5489 - val_accuracy: 0.8467\n",
            "Epoch 91/100\n",
            "47/47 [==============================] - 24s 502ms/step - loss: 0.1110 - accuracy: 0.9546 - val_loss: 0.4967 - val_accuracy: 0.8533\n",
            "Epoch 92/100\n",
            "47/47 [==============================] - 23s 500ms/step - loss: 0.1175 - accuracy: 0.9542 - val_loss: 0.5273 - val_accuracy: 0.8467\n",
            "Epoch 93/100\n",
            "47/47 [==============================] - 23s 499ms/step - loss: 0.1376 - accuracy: 0.9452 - val_loss: 0.4979 - val_accuracy: 0.8480\n",
            "Epoch 94/100\n",
            "47/47 [==============================] - 24s 503ms/step - loss: 0.1240 - accuracy: 0.9533 - val_loss: 0.5279 - val_accuracy: 0.8467\n",
            "Epoch 95/100\n",
            "47/47 [==============================] - 24s 503ms/step - loss: 0.1207 - accuracy: 0.9554 - val_loss: 0.5041 - val_accuracy: 0.8547\n",
            "Epoch 96/100\n",
            "47/47 [==============================] - 24s 503ms/step - loss: 0.1326 - accuracy: 0.9460 - val_loss: 0.5213 - val_accuracy: 0.8440\n",
            "Epoch 97/100\n",
            "47/47 [==============================] - 24s 501ms/step - loss: 0.1230 - accuracy: 0.9584 - val_loss: 0.4964 - val_accuracy: 0.8533\n",
            "Epoch 98/100\n",
            "47/47 [==============================] - 23s 495ms/step - loss: 0.1314 - accuracy: 0.9494 - val_loss: 0.5202 - val_accuracy: 0.8440\n",
            "Epoch 99/100\n",
            "47/47 [==============================] - 23s 497ms/step - loss: 0.1091 - accuracy: 0.9636 - val_loss: 0.6023 - val_accuracy: 0.8320\n",
            "Epoch 100/100\n",
            "47/47 [==============================] - 24s 502ms/step - loss: 0.1076 - accuracy: 0.9524 - val_loss: 0.5590 - val_accuracy: 0.8413\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 432x288 with 1 Axes>",
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\r\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n<!-- Created with matplotlib (https://matplotlib.org/) -->\r\n<svg height=\"282.129625pt\" version=\"1.1\" viewBox=\"0 0 387.716875 282.129625\" width=\"387.716875pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n <metadata>\r\n  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\r\n   <cc:Work>\r\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\r\n    <dc:date>2020-11-30T21:10:03.741777</dc:date>\r\n    <dc:format>image/svg+xml</dc:format>\r\n    <dc:creator>\r\n     <cc:Agent>\r\n      <dc:title>Matplotlib v3.3.3, https://matplotlib.org/</dc:title>\r\n     </cc:Agent>\r\n    </dc:creator>\r\n   </cc:Work>\r\n  </rdf:RDF>\r\n </metadata>\r\n <defs>\r\n  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\r\n </defs>\r\n <g id=\"figure_1\">\r\n  <g id=\"patch_1\">\r\n   <path d=\"M 0 282.129625 \r\nL 387.716875 282.129625 \r\nL 387.716875 0 \r\nL 0 0 \r\nz\r\n\" style=\"fill:#ffffff;\"/>\r\n  </g>\r\n  <g id=\"axes_1\">\r\n   <g id=\"patch_2\">\r\n    <path d=\"M 45.716875 242.15775 \r\nL 380.516875 242.15775 \r\nL 380.516875 24.71775 \r\nL 45.716875 24.71775 \r\nz\r\n\" style=\"fill:#e5e5e5;\"/>\r\n   </g>\r\n   <g id=\"matplotlib.axis_1\">\r\n    <g id=\"xtick_1\">\r\n     <g id=\"line2d_1\">\r\n      <path clip-path=\"url(#pb7d45e7ef7)\" d=\"M 60.935057 242.15775 \r\nL 60.935057 24.71775 \r\n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:square;stroke-width:0.8;\"/>\r\n     </g>\r\n     <g id=\"line2d_2\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL 0 3.5 \r\n\" id=\"m51f239c874\" style=\"stroke:#555555;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"fill:#555555;stroke:#555555;stroke-width:0.8;\" x=\"60.935057\" xlink:href=\"#m51f239c874\" y=\"242.15775\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_1\">\r\n      <!-- 0 -->\r\n      <g style=\"fill:#555555;\" transform=\"translate(57.753807 256.756187)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 31.78125 66.40625 \r\nQ 24.171875 66.40625 20.328125 58.90625 \r\nQ 16.5 51.421875 16.5 36.375 \r\nQ 16.5 21.390625 20.328125 13.890625 \r\nQ 24.171875 6.390625 31.78125 6.390625 \r\nQ 39.453125 6.390625 43.28125 13.890625 \r\nQ 47.125 21.390625 47.125 36.375 \r\nQ 47.125 51.421875 43.28125 58.90625 \r\nQ 39.453125 66.40625 31.78125 66.40625 \r\nz\r\nM 31.78125 74.21875 \r\nQ 44.046875 74.21875 50.515625 64.515625 \r\nQ 56.984375 54.828125 56.984375 36.375 \r\nQ 56.984375 17.96875 50.515625 8.265625 \r\nQ 44.046875 -1.421875 31.78125 -1.421875 \r\nQ 19.53125 -1.421875 13.0625 8.265625 \r\nQ 6.59375 17.96875 6.59375 36.375 \r\nQ 6.59375 54.828125 13.0625 64.515625 \r\nQ 19.53125 74.21875 31.78125 74.21875 \r\nz\r\n\" id=\"DejaVuSans-48\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_2\">\r\n     <g id=\"line2d_3\">\r\n      <path clip-path=\"url(#pb7d45e7ef7)\" d=\"M 122.42266 242.15775 \r\nL 122.42266 24.71775 \r\n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:square;stroke-width:0.8;\"/>\r\n     </g>\r\n     <g id=\"line2d_4\">\r\n      <g>\r\n       <use style=\"fill:#555555;stroke:#555555;stroke-width:0.8;\" x=\"122.42266\" xlink:href=\"#m51f239c874\" y=\"242.15775\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_2\">\r\n      <!-- 20 -->\r\n      <g style=\"fill:#555555;\" transform=\"translate(116.06016 256.756187)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 19.1875 8.296875 \r\nL 53.609375 8.296875 \r\nL 53.609375 0 \r\nL 7.328125 0 \r\nL 7.328125 8.296875 \r\nQ 12.9375 14.109375 22.625 23.890625 \r\nQ 32.328125 33.6875 34.8125 36.53125 \r\nQ 39.546875 41.84375 41.421875 45.53125 \r\nQ 43.3125 49.21875 43.3125 52.78125 \r\nQ 43.3125 58.59375 39.234375 62.25 \r\nQ 35.15625 65.921875 28.609375 65.921875 \r\nQ 23.96875 65.921875 18.8125 64.3125 \r\nQ 13.671875 62.703125 7.8125 59.421875 \r\nL 7.8125 69.390625 \r\nQ 13.765625 71.78125 18.9375 73 \r\nQ 24.125 74.21875 28.421875 74.21875 \r\nQ 39.75 74.21875 46.484375 68.546875 \r\nQ 53.21875 62.890625 53.21875 53.421875 \r\nQ 53.21875 48.921875 51.53125 44.890625 \r\nQ 49.859375 40.875 45.40625 35.40625 \r\nQ 44.1875 33.984375 37.640625 27.21875 \r\nQ 31.109375 20.453125 19.1875 8.296875 \r\nz\r\n\" id=\"DejaVuSans-50\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_3\">\r\n     <g id=\"line2d_5\">\r\n      <path clip-path=\"url(#pb7d45e7ef7)\" d=\"M 183.910263 242.15775 \r\nL 183.910263 24.71775 \r\n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:square;stroke-width:0.8;\"/>\r\n     </g>\r\n     <g id=\"line2d_6\">\r\n      <g>\r\n       <use style=\"fill:#555555;stroke:#555555;stroke-width:0.8;\" x=\"183.910263\" xlink:href=\"#m51f239c874\" y=\"242.15775\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_3\">\r\n      <!-- 40 -->\r\n      <g style=\"fill:#555555;\" transform=\"translate(177.547763 256.756187)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 37.796875 64.3125 \r\nL 12.890625 25.390625 \r\nL 37.796875 25.390625 \r\nz\r\nM 35.203125 72.90625 \r\nL 47.609375 72.90625 \r\nL 47.609375 25.390625 \r\nL 58.015625 25.390625 \r\nL 58.015625 17.1875 \r\nL 47.609375 17.1875 \r\nL 47.609375 0 \r\nL 37.796875 0 \r\nL 37.796875 17.1875 \r\nL 4.890625 17.1875 \r\nL 4.890625 26.703125 \r\nz\r\n\" id=\"DejaVuSans-52\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-52\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_4\">\r\n     <g id=\"line2d_7\">\r\n      <path clip-path=\"url(#pb7d45e7ef7)\" d=\"M 245.397867 242.15775 \r\nL 245.397867 24.71775 \r\n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:square;stroke-width:0.8;\"/>\r\n     </g>\r\n     <g id=\"line2d_8\">\r\n      <g>\r\n       <use style=\"fill:#555555;stroke:#555555;stroke-width:0.8;\" x=\"245.397867\" xlink:href=\"#m51f239c874\" y=\"242.15775\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_4\">\r\n      <!-- 60 -->\r\n      <g style=\"fill:#555555;\" transform=\"translate(239.035367 256.756187)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 33.015625 40.375 \r\nQ 26.375 40.375 22.484375 35.828125 \r\nQ 18.609375 31.296875 18.609375 23.390625 \r\nQ 18.609375 15.53125 22.484375 10.953125 \r\nQ 26.375 6.390625 33.015625 6.390625 \r\nQ 39.65625 6.390625 43.53125 10.953125 \r\nQ 47.40625 15.53125 47.40625 23.390625 \r\nQ 47.40625 31.296875 43.53125 35.828125 \r\nQ 39.65625 40.375 33.015625 40.375 \r\nz\r\nM 52.59375 71.296875 \r\nL 52.59375 62.3125 \r\nQ 48.875 64.0625 45.09375 64.984375 \r\nQ 41.3125 65.921875 37.59375 65.921875 \r\nQ 27.828125 65.921875 22.671875 59.328125 \r\nQ 17.53125 52.734375 16.796875 39.40625 \r\nQ 19.671875 43.65625 24.015625 45.921875 \r\nQ 28.375 48.1875 33.59375 48.1875 \r\nQ 44.578125 48.1875 50.953125 41.515625 \r\nQ 57.328125 34.859375 57.328125 23.390625 \r\nQ 57.328125 12.15625 50.6875 5.359375 \r\nQ 44.046875 -1.421875 33.015625 -1.421875 \r\nQ 20.359375 -1.421875 13.671875 8.265625 \r\nQ 6.984375 17.96875 6.984375 36.375 \r\nQ 6.984375 53.65625 15.1875 63.9375 \r\nQ 23.390625 74.21875 37.203125 74.21875 \r\nQ 40.921875 74.21875 44.703125 73.484375 \r\nQ 48.484375 72.75 52.59375 71.296875 \r\nz\r\n\" id=\"DejaVuSans-54\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-54\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_5\">\r\n     <g id=\"line2d_9\">\r\n      <path clip-path=\"url(#pb7d45e7ef7)\" d=\"M 306.88547 242.15775 \r\nL 306.88547 24.71775 \r\n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:square;stroke-width:0.8;\"/>\r\n     </g>\r\n     <g id=\"line2d_10\">\r\n      <g>\r\n       <use style=\"fill:#555555;stroke:#555555;stroke-width:0.8;\" x=\"306.88547\" xlink:href=\"#m51f239c874\" y=\"242.15775\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_5\">\r\n      <!-- 80 -->\r\n      <g style=\"fill:#555555;\" transform=\"translate(300.52297 256.756187)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 31.78125 34.625 \r\nQ 24.75 34.625 20.71875 30.859375 \r\nQ 16.703125 27.09375 16.703125 20.515625 \r\nQ 16.703125 13.921875 20.71875 10.15625 \r\nQ 24.75 6.390625 31.78125 6.390625 \r\nQ 38.8125 6.390625 42.859375 10.171875 \r\nQ 46.921875 13.96875 46.921875 20.515625 \r\nQ 46.921875 27.09375 42.890625 30.859375 \r\nQ 38.875 34.625 31.78125 34.625 \r\nz\r\nM 21.921875 38.8125 \r\nQ 15.578125 40.375 12.03125 44.71875 \r\nQ 8.5 49.078125 8.5 55.328125 \r\nQ 8.5 64.0625 14.71875 69.140625 \r\nQ 20.953125 74.21875 31.78125 74.21875 \r\nQ 42.671875 74.21875 48.875 69.140625 \r\nQ 55.078125 64.0625 55.078125 55.328125 \r\nQ 55.078125 49.078125 51.53125 44.71875 \r\nQ 48 40.375 41.703125 38.8125 \r\nQ 48.828125 37.15625 52.796875 32.3125 \r\nQ 56.78125 27.484375 56.78125 20.515625 \r\nQ 56.78125 9.90625 50.3125 4.234375 \r\nQ 43.84375 -1.421875 31.78125 -1.421875 \r\nQ 19.734375 -1.421875 13.25 4.234375 \r\nQ 6.78125 9.90625 6.78125 20.515625 \r\nQ 6.78125 27.484375 10.78125 32.3125 \r\nQ 14.796875 37.15625 21.921875 38.8125 \r\nz\r\nM 18.3125 54.390625 \r\nQ 18.3125 48.734375 21.84375 45.5625 \r\nQ 25.390625 42.390625 31.78125 42.390625 \r\nQ 38.140625 42.390625 41.71875 45.5625 \r\nQ 45.3125 48.734375 45.3125 54.390625 \r\nQ 45.3125 60.0625 41.71875 63.234375 \r\nQ 38.140625 66.40625 31.78125 66.40625 \r\nQ 25.390625 66.40625 21.84375 63.234375 \r\nQ 18.3125 60.0625 18.3125 54.390625 \r\nz\r\n\" id=\"DejaVuSans-56\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-56\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_6\">\r\n     <g id=\"line2d_11\">\r\n      <path clip-path=\"url(#pb7d45e7ef7)\" d=\"M 368.373073 242.15775 \r\nL 368.373073 24.71775 \r\n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:square;stroke-width:0.8;\"/>\r\n     </g>\r\n     <g id=\"line2d_12\">\r\n      <g>\r\n       <use style=\"fill:#555555;stroke:#555555;stroke-width:0.8;\" x=\"368.373073\" xlink:href=\"#m51f239c874\" y=\"242.15775\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_6\">\r\n      <!-- 100 -->\r\n      <g style=\"fill:#555555;\" transform=\"translate(358.829323 256.756187)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 12.40625 8.296875 \r\nL 28.515625 8.296875 \r\nL 28.515625 63.921875 \r\nL 10.984375 60.40625 \r\nL 10.984375 69.390625 \r\nL 28.421875 72.90625 \r\nL 38.28125 72.90625 \r\nL 38.28125 8.296875 \r\nL 54.390625 8.296875 \r\nL 54.390625 0 \r\nL 12.40625 0 \r\nz\r\n\" id=\"DejaVuSans-49\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"text_7\">\r\n     <!-- Nmero de epoca -->\r\n     <g style=\"fill:#555555;\" transform=\"translate(159.82375 272.434)scale(0.12 -0.12)\">\r\n      <defs>\r\n       <path d=\"M 9.8125 72.90625 \r\nL 23.09375 72.90625 \r\nL 55.421875 11.921875 \r\nL 55.421875 72.90625 \r\nL 64.984375 72.90625 \r\nL 64.984375 0 \r\nL 51.703125 0 \r\nL 19.390625 60.984375 \r\nL 19.390625 0 \r\nL 9.8125 0 \r\nz\r\n\" id=\"DejaVuSans-78\"/>\r\n       <path d=\"M 8.5 21.578125 \r\nL 8.5 54.6875 \r\nL 17.484375 54.6875 \r\nL 17.484375 21.921875 \r\nQ 17.484375 14.15625 20.5 10.265625 \r\nQ 23.53125 6.390625 29.59375 6.390625 \r\nQ 36.859375 6.390625 41.078125 11.03125 \r\nQ 45.3125 15.671875 45.3125 23.6875 \r\nL 45.3125 54.6875 \r\nL 54.296875 54.6875 \r\nL 54.296875 0 \r\nL 45.3125 0 \r\nL 45.3125 8.40625 \r\nQ 42.046875 3.421875 37.71875 1 \r\nQ 33.40625 -1.421875 27.6875 -1.421875 \r\nQ 18.265625 -1.421875 13.375 4.4375 \r\nQ 8.5 10.296875 8.5 21.578125 \r\nz\r\nM 31.109375 56 \r\nz\r\nM 37.78125 79.984375 \r\nL 47.5 79.984375 \r\nL 31.59375 61.625 \r\nL 24.109375 61.625 \r\nz\r\n\" id=\"DejaVuSans-250\"/>\r\n       <path d=\"M 52 44.1875 \r\nQ 55.375 50.25 60.0625 53.125 \r\nQ 64.75 56 71.09375 56 \r\nQ 79.640625 56 84.28125 50.015625 \r\nQ 88.921875 44.046875 88.921875 33.015625 \r\nL 88.921875 0 \r\nL 79.890625 0 \r\nL 79.890625 32.71875 \r\nQ 79.890625 40.578125 77.09375 44.375 \r\nQ 74.3125 48.1875 68.609375 48.1875 \r\nQ 61.625 48.1875 57.5625 43.546875 \r\nQ 53.515625 38.921875 53.515625 30.90625 \r\nL 53.515625 0 \r\nL 44.484375 0 \r\nL 44.484375 32.71875 \r\nQ 44.484375 40.625 41.703125 44.40625 \r\nQ 38.921875 48.1875 33.109375 48.1875 \r\nQ 26.21875 48.1875 22.15625 43.53125 \r\nQ 18.109375 38.875 18.109375 30.90625 \r\nL 18.109375 0 \r\nL 9.078125 0 \r\nL 9.078125 54.6875 \r\nL 18.109375 54.6875 \r\nL 18.109375 46.1875 \r\nQ 21.1875 51.21875 25.484375 53.609375 \r\nQ 29.78125 56 35.6875 56 \r\nQ 41.65625 56 45.828125 52.96875 \r\nQ 50 49.953125 52 44.1875 \r\nz\r\n\" id=\"DejaVuSans-109\"/>\r\n       <path d=\"M 56.203125 29.59375 \r\nL 56.203125 25.203125 \r\nL 14.890625 25.203125 \r\nQ 15.484375 15.921875 20.484375 11.0625 \r\nQ 25.484375 6.203125 34.421875 6.203125 \r\nQ 39.59375 6.203125 44.453125 7.46875 \r\nQ 49.3125 8.734375 54.109375 11.28125 \r\nL 54.109375 2.78125 \r\nQ 49.265625 0.734375 44.1875 -0.34375 \r\nQ 39.109375 -1.421875 33.890625 -1.421875 \r\nQ 20.796875 -1.421875 13.15625 6.1875 \r\nQ 5.515625 13.8125 5.515625 26.8125 \r\nQ 5.515625 40.234375 12.765625 48.109375 \r\nQ 20.015625 56 32.328125 56 \r\nQ 43.359375 56 49.78125 48.890625 \r\nQ 56.203125 41.796875 56.203125 29.59375 \r\nz\r\nM 47.21875 32.234375 \r\nQ 47.125 39.59375 43.09375 43.984375 \r\nQ 39.0625 48.390625 32.421875 48.390625 \r\nQ 24.90625 48.390625 20.390625 44.140625 \r\nQ 15.875 39.890625 15.1875 32.171875 \r\nz\r\n\" id=\"DejaVuSans-101\"/>\r\n       <path d=\"M 41.109375 46.296875 \r\nQ 39.59375 47.171875 37.8125 47.578125 \r\nQ 36.03125 48 33.890625 48 \r\nQ 26.265625 48 22.1875 43.046875 \r\nQ 18.109375 38.09375 18.109375 28.8125 \r\nL 18.109375 0 \r\nL 9.078125 0 \r\nL 9.078125 54.6875 \r\nL 18.109375 54.6875 \r\nL 18.109375 46.1875 \r\nQ 20.953125 51.171875 25.484375 53.578125 \r\nQ 30.03125 56 36.53125 56 \r\nQ 37.453125 56 38.578125 55.875 \r\nQ 39.703125 55.765625 41.0625 55.515625 \r\nz\r\n\" id=\"DejaVuSans-114\"/>\r\n       <path d=\"M 30.609375 48.390625 \r\nQ 23.390625 48.390625 19.1875 42.75 \r\nQ 14.984375 37.109375 14.984375 27.296875 \r\nQ 14.984375 17.484375 19.15625 11.84375 \r\nQ 23.34375 6.203125 30.609375 6.203125 \r\nQ 37.796875 6.203125 41.984375 11.859375 \r\nQ 46.1875 17.53125 46.1875 27.296875 \r\nQ 46.1875 37.015625 41.984375 42.703125 \r\nQ 37.796875 48.390625 30.609375 48.390625 \r\nz\r\nM 30.609375 56 \r\nQ 42.328125 56 49.015625 48.375 \r\nQ 55.71875 40.765625 55.71875 27.296875 \r\nQ 55.71875 13.875 49.015625 6.21875 \r\nQ 42.328125 -1.421875 30.609375 -1.421875 \r\nQ 18.84375 -1.421875 12.171875 6.21875 \r\nQ 5.515625 13.875 5.515625 27.296875 \r\nQ 5.515625 40.765625 12.171875 48.375 \r\nQ 18.84375 56 30.609375 56 \r\nz\r\n\" id=\"DejaVuSans-111\"/>\r\n       <path id=\"DejaVuSans-32\"/>\r\n       <path d=\"M 45.40625 46.390625 \r\nL 45.40625 75.984375 \r\nL 54.390625 75.984375 \r\nL 54.390625 0 \r\nL 45.40625 0 \r\nL 45.40625 8.203125 \r\nQ 42.578125 3.328125 38.25 0.953125 \r\nQ 33.9375 -1.421875 27.875 -1.421875 \r\nQ 17.96875 -1.421875 11.734375 6.484375 \r\nQ 5.515625 14.40625 5.515625 27.296875 \r\nQ 5.515625 40.1875 11.734375 48.09375 \r\nQ 17.96875 56 27.875 56 \r\nQ 33.9375 56 38.25 53.625 \r\nQ 42.578125 51.265625 45.40625 46.390625 \r\nz\r\nM 14.796875 27.296875 \r\nQ 14.796875 17.390625 18.875 11.75 \r\nQ 22.953125 6.109375 30.078125 6.109375 \r\nQ 37.203125 6.109375 41.296875 11.75 \r\nQ 45.40625 17.390625 45.40625 27.296875 \r\nQ 45.40625 37.203125 41.296875 42.84375 \r\nQ 37.203125 48.484375 30.078125 48.484375 \r\nQ 22.953125 48.484375 18.875 42.84375 \r\nQ 14.796875 37.203125 14.796875 27.296875 \r\nz\r\n\" id=\"DejaVuSans-100\"/>\r\n       <path d=\"M 18.109375 8.203125 \r\nL 18.109375 -20.796875 \r\nL 9.078125 -20.796875 \r\nL 9.078125 54.6875 \r\nL 18.109375 54.6875 \r\nL 18.109375 46.390625 \r\nQ 20.953125 51.265625 25.265625 53.625 \r\nQ 29.59375 56 35.59375 56 \r\nQ 45.5625 56 51.78125 48.09375 \r\nQ 58.015625 40.1875 58.015625 27.296875 \r\nQ 58.015625 14.40625 51.78125 6.484375 \r\nQ 45.5625 -1.421875 35.59375 -1.421875 \r\nQ 29.59375 -1.421875 25.265625 0.953125 \r\nQ 20.953125 3.328125 18.109375 8.203125 \r\nz\r\nM 48.6875 27.296875 \r\nQ 48.6875 37.203125 44.609375 42.84375 \r\nQ 40.53125 48.484375 33.40625 48.484375 \r\nQ 26.265625 48.484375 22.1875 42.84375 \r\nQ 18.109375 37.203125 18.109375 27.296875 \r\nQ 18.109375 17.390625 22.1875 11.75 \r\nQ 26.265625 6.109375 33.40625 6.109375 \r\nQ 40.53125 6.109375 44.609375 11.75 \r\nQ 48.6875 17.390625 48.6875 27.296875 \r\nz\r\n\" id=\"DejaVuSans-112\"/>\r\n       <path d=\"M 48.78125 52.59375 \r\nL 48.78125 44.1875 \r\nQ 44.96875 46.296875 41.140625 47.34375 \r\nQ 37.3125 48.390625 33.40625 48.390625 \r\nQ 24.65625 48.390625 19.8125 42.84375 \r\nQ 14.984375 37.3125 14.984375 27.296875 \r\nQ 14.984375 17.28125 19.8125 11.734375 \r\nQ 24.65625 6.203125 33.40625 6.203125 \r\nQ 37.3125 6.203125 41.140625 7.25 \r\nQ 44.96875 8.296875 48.78125 10.40625 \r\nL 48.78125 2.09375 \r\nQ 45.015625 0.34375 40.984375 -0.53125 \r\nQ 36.96875 -1.421875 32.421875 -1.421875 \r\nQ 20.0625 -1.421875 12.78125 6.34375 \r\nQ 5.515625 14.109375 5.515625 27.296875 \r\nQ 5.515625 40.671875 12.859375 48.328125 \r\nQ 20.21875 56 33.015625 56 \r\nQ 37.15625 56 41.109375 55.140625 \r\nQ 45.0625 54.296875 48.78125 52.59375 \r\nz\r\n\" id=\"DejaVuSans-99\"/>\r\n       <path d=\"M 34.28125 27.484375 \r\nQ 23.390625 27.484375 19.1875 25 \r\nQ 14.984375 22.515625 14.984375 16.5 \r\nQ 14.984375 11.71875 18.140625 8.90625 \r\nQ 21.296875 6.109375 26.703125 6.109375 \r\nQ 34.1875 6.109375 38.703125 11.40625 \r\nQ 43.21875 16.703125 43.21875 25.484375 \r\nL 43.21875 27.484375 \r\nz\r\nM 52.203125 31.203125 \r\nL 52.203125 0 \r\nL 43.21875 0 \r\nL 43.21875 8.296875 \r\nQ 40.140625 3.328125 35.546875 0.953125 \r\nQ 30.953125 -1.421875 24.3125 -1.421875 \r\nQ 15.921875 -1.421875 10.953125 3.296875 \r\nQ 6 8.015625 6 15.921875 \r\nQ 6 25.140625 12.171875 29.828125 \r\nQ 18.359375 34.515625 30.609375 34.515625 \r\nL 43.21875 34.515625 \r\nL 43.21875 35.40625 \r\nQ 43.21875 41.609375 39.140625 45 \r\nQ 35.0625 48.390625 27.6875 48.390625 \r\nQ 23 48.390625 18.546875 47.265625 \r\nQ 14.109375 46.140625 10.015625 43.890625 \r\nL 10.015625 52.203125 \r\nQ 14.9375 54.109375 19.578125 55.046875 \r\nQ 24.21875 56 28.609375 56 \r\nQ 40.484375 56 46.34375 49.84375 \r\nQ 52.203125 43.703125 52.203125 31.203125 \r\nz\r\n\" id=\"DejaVuSans-97\"/>\r\n      </defs>\r\n      <use xlink:href=\"#DejaVuSans-78\"/>\r\n      <use x=\"74.804688\" xlink:href=\"#DejaVuSans-250\"/>\r\n      <use x=\"138.183594\" xlink:href=\"#DejaVuSans-109\"/>\r\n      <use x=\"235.595703\" xlink:href=\"#DejaVuSans-101\"/>\r\n      <use x=\"297.119141\" xlink:href=\"#DejaVuSans-114\"/>\r\n      <use x=\"335.982422\" xlink:href=\"#DejaVuSans-111\"/>\r\n      <use x=\"397.164062\" xlink:href=\"#DejaVuSans-32\"/>\r\n      <use x=\"428.951172\" xlink:href=\"#DejaVuSans-100\"/>\r\n      <use x=\"492.427734\" xlink:href=\"#DejaVuSans-101\"/>\r\n      <use x=\"553.951172\" xlink:href=\"#DejaVuSans-32\"/>\r\n      <use x=\"585.738281\" xlink:href=\"#DejaVuSans-101\"/>\r\n      <use x=\"647.261719\" xlink:href=\"#DejaVuSans-112\"/>\r\n      <use x=\"710.738281\" xlink:href=\"#DejaVuSans-111\"/>\r\n      <use x=\"771.919922\" xlink:href=\"#DejaVuSans-99\"/>\r\n      <use x=\"826.900391\" xlink:href=\"#DejaVuSans-97\"/>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"matplotlib.axis_2\">\r\n    <g id=\"ytick_1\">\r\n     <g id=\"line2d_13\">\r\n      <path clip-path=\"url(#pb7d45e7ef7)\" d=\"M 45.716875 215.492169 \r\nL 380.516875 215.492169 \r\n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:square;stroke-width:0.8;\"/>\r\n     </g>\r\n     <g id=\"line2d_14\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL -3.5 0 \r\n\" id=\"m28abdf4f76\" style=\"stroke:#555555;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"fill:#555555;stroke:#555555;stroke-width:0.8;\" x=\"45.716875\" xlink:href=\"#m28abdf4f76\" y=\"215.492169\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_8\">\r\n      <!-- 0.2 -->\r\n      <g style=\"fill:#555555;\" transform=\"translate(22.81375 219.291388)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 10.6875 12.40625 \r\nL 21 12.40625 \r\nL 21 0 \r\nL 10.6875 0 \r\nz\r\n\" id=\"DejaVuSans-46\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-50\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_2\">\r\n     <g id=\"line2d_15\">\r\n      <path clip-path=\"url(#pb7d45e7ef7)\" d=\"M 45.716875 179.173578 \r\nL 380.516875 179.173578 \r\n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:square;stroke-width:0.8;\"/>\r\n     </g>\r\n     <g id=\"line2d_16\">\r\n      <g>\r\n       <use style=\"fill:#555555;stroke:#555555;stroke-width:0.8;\" x=\"45.716875\" xlink:href=\"#m28abdf4f76\" y=\"179.173578\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_9\">\r\n      <!-- 0.4 -->\r\n      <g style=\"fill:#555555;\" transform=\"translate(22.81375 182.972797)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-52\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_3\">\r\n     <g id=\"line2d_17\">\r\n      <path clip-path=\"url(#pb7d45e7ef7)\" d=\"M 45.716875 142.854987 \r\nL 380.516875 142.854987 \r\n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:square;stroke-width:0.8;\"/>\r\n     </g>\r\n     <g id=\"line2d_18\">\r\n      <g>\r\n       <use style=\"fill:#555555;stroke:#555555;stroke-width:0.8;\" x=\"45.716875\" xlink:href=\"#m28abdf4f76\" y=\"142.854987\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_10\">\r\n      <!-- 0.6 -->\r\n      <g style=\"fill:#555555;\" transform=\"translate(22.81375 146.654205)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-54\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_4\">\r\n     <g id=\"line2d_19\">\r\n      <path clip-path=\"url(#pb7d45e7ef7)\" d=\"M 45.716875 106.536395 \r\nL 380.516875 106.536395 \r\n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:square;stroke-width:0.8;\"/>\r\n     </g>\r\n     <g id=\"line2d_20\">\r\n      <g>\r\n       <use style=\"fill:#555555;stroke:#555555;stroke-width:0.8;\" x=\"45.716875\" xlink:href=\"#m28abdf4f76\" y=\"106.536395\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_11\">\r\n      <!-- 0.8 -->\r\n      <g style=\"fill:#555555;\" transform=\"translate(22.81375 110.335614)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-56\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_5\">\r\n     <g id=\"line2d_21\">\r\n      <path clip-path=\"url(#pb7d45e7ef7)\" d=\"M 45.716875 70.217804 \r\nL 380.516875 70.217804 \r\n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:square;stroke-width:0.8;\"/>\r\n     </g>\r\n     <g id=\"line2d_22\">\r\n      <g>\r\n       <use style=\"fill:#555555;stroke:#555555;stroke-width:0.8;\" x=\"45.716875\" xlink:href=\"#m28abdf4f76\" y=\"70.217804\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_12\">\r\n      <!-- 1.0 -->\r\n      <g style=\"fill:#555555;\" transform=\"translate(22.81375 74.017023)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_6\">\r\n     <g id=\"line2d_23\">\r\n      <path clip-path=\"url(#pb7d45e7ef7)\" d=\"M 45.716875 33.899213 \r\nL 380.516875 33.899213 \r\n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:square;stroke-width:0.8;\"/>\r\n     </g>\r\n     <g id=\"line2d_24\">\r\n      <g>\r\n       <use style=\"fill:#555555;stroke:#555555;stroke-width:0.8;\" x=\"45.716875\" xlink:href=\"#m28abdf4f76\" y=\"33.899213\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_13\">\r\n      <!-- 1.2 -->\r\n      <g style=\"fill:#555555;\" transform=\"translate(22.81375 37.698432)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-50\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"text_14\">\r\n     <!-- Perdida/Precisin -->\r\n     <g style=\"fill:#555555;\" transform=\"translate(16.318125 184.643062)rotate(-90)scale(0.12 -0.12)\">\r\n      <defs>\r\n       <path d=\"M 19.671875 64.796875 \r\nL 19.671875 37.40625 \r\nL 32.078125 37.40625 \r\nQ 38.96875 37.40625 42.71875 40.96875 \r\nQ 46.484375 44.53125 46.484375 51.125 \r\nQ 46.484375 57.671875 42.71875 61.234375 \r\nQ 38.96875 64.796875 32.078125 64.796875 \r\nz\r\nM 9.8125 72.90625 \r\nL 32.078125 72.90625 \r\nQ 44.34375 72.90625 50.609375 67.359375 \r\nQ 56.890625 61.8125 56.890625 51.125 \r\nQ 56.890625 40.328125 50.609375 34.8125 \r\nQ 44.34375 29.296875 32.078125 29.296875 \r\nL 19.671875 29.296875 \r\nL 19.671875 0 \r\nL 9.8125 0 \r\nz\r\n\" id=\"DejaVuSans-80\"/>\r\n       <path d=\"M 9.421875 54.6875 \r\nL 18.40625 54.6875 \r\nL 18.40625 0 \r\nL 9.421875 0 \r\nz\r\nM 9.421875 75.984375 \r\nL 18.40625 75.984375 \r\nL 18.40625 64.59375 \r\nL 9.421875 64.59375 \r\nz\r\n\" id=\"DejaVuSans-105\"/>\r\n       <path d=\"M 25.390625 72.90625 \r\nL 33.6875 72.90625 \r\nL 8.296875 -9.28125 \r\nL 0 -9.28125 \r\nz\r\n\" id=\"DejaVuSans-47\"/>\r\n       <path d=\"M 44.28125 53.078125 \r\nL 44.28125 44.578125 \r\nQ 40.484375 46.53125 36.375 47.5 \r\nQ 32.28125 48.484375 27.875 48.484375 \r\nQ 21.1875 48.484375 17.84375 46.4375 \r\nQ 14.5 44.390625 14.5 40.28125 \r\nQ 14.5 37.15625 16.890625 35.375 \r\nQ 19.28125 33.59375 26.515625 31.984375 \r\nL 29.59375 31.296875 \r\nQ 39.15625 29.25 43.1875 25.515625 \r\nQ 47.21875 21.78125 47.21875 15.09375 \r\nQ 47.21875 7.46875 41.1875 3.015625 \r\nQ 35.15625 -1.421875 24.609375 -1.421875 \r\nQ 20.21875 -1.421875 15.453125 -0.5625 \r\nQ 10.6875 0.296875 5.421875 2 \r\nL 5.421875 11.28125 \r\nQ 10.40625 8.6875 15.234375 7.390625 \r\nQ 20.0625 6.109375 24.8125 6.109375 \r\nQ 31.15625 6.109375 34.5625 8.28125 \r\nQ 37.984375 10.453125 37.984375 14.40625 \r\nQ 37.984375 18.0625 35.515625 20.015625 \r\nQ 33.0625 21.96875 24.703125 23.78125 \r\nL 21.578125 24.515625 \r\nQ 13.234375 26.265625 9.515625 29.90625 \r\nQ 5.8125 33.546875 5.8125 39.890625 \r\nQ 5.8125 47.609375 11.28125 51.796875 \r\nQ 16.75 56 26.8125 56 \r\nQ 31.78125 56 36.171875 55.265625 \r\nQ 40.578125 54.546875 44.28125 53.078125 \r\nz\r\n\" id=\"DejaVuSans-115\"/>\r\n       <path d=\"M 30.609375 48.390625 \r\nQ 23.390625 48.390625 19.1875 42.75 \r\nQ 14.984375 37.109375 14.984375 27.296875 \r\nQ 14.984375 17.484375 19.15625 11.84375 \r\nQ 23.34375 6.203125 30.609375 6.203125 \r\nQ 37.796875 6.203125 41.984375 11.859375 \r\nQ 46.1875 17.53125 46.1875 27.296875 \r\nQ 46.1875 37.015625 41.984375 42.703125 \r\nQ 37.796875 48.390625 30.609375 48.390625 \r\nz\r\nM 30.609375 56 \r\nQ 42.328125 56 49.015625 48.375 \r\nQ 55.71875 40.765625 55.71875 27.296875 \r\nQ 55.71875 13.875 49.015625 6.21875 \r\nQ 42.328125 -1.421875 30.609375 -1.421875 \r\nQ 18.84375 -1.421875 12.171875 6.21875 \r\nQ 5.515625 13.875 5.515625 27.296875 \r\nQ 5.515625 40.765625 12.171875 48.375 \r\nQ 18.84375 56 30.609375 56 \r\nz\r\nM 37.40625 79.984375 \r\nL 47.125 79.984375 \r\nL 31.21875 61.625 \r\nL 23.734375 61.625 \r\nz\r\n\" id=\"DejaVuSans-243\"/>\r\n       <path d=\"M 54.890625 33.015625 \r\nL 54.890625 0 \r\nL 45.90625 0 \r\nL 45.90625 32.71875 \r\nQ 45.90625 40.484375 42.875 44.328125 \r\nQ 39.84375 48.1875 33.796875 48.1875 \r\nQ 26.515625 48.1875 22.3125 43.546875 \r\nQ 18.109375 38.921875 18.109375 30.90625 \r\nL 18.109375 0 \r\nL 9.078125 0 \r\nL 9.078125 54.6875 \r\nL 18.109375 54.6875 \r\nL 18.109375 46.1875 \r\nQ 21.34375 51.125 25.703125 53.5625 \r\nQ 30.078125 56 35.796875 56 \r\nQ 45.21875 56 50.046875 50.171875 \r\nQ 54.890625 44.34375 54.890625 33.015625 \r\nz\r\n\" id=\"DejaVuSans-110\"/>\r\n      </defs>\r\n      <use xlink:href=\"#DejaVuSans-80\"/>\r\n      <use x=\"56.677734\" xlink:href=\"#DejaVuSans-101\"/>\r\n      <use x=\"118.201172\" xlink:href=\"#DejaVuSans-114\"/>\r\n      <use x=\"157.564453\" xlink:href=\"#DejaVuSans-100\"/>\r\n      <use x=\"221.041016\" xlink:href=\"#DejaVuSans-105\"/>\r\n      <use x=\"248.824219\" xlink:href=\"#DejaVuSans-100\"/>\r\n      <use x=\"312.300781\" xlink:href=\"#DejaVuSans-97\"/>\r\n      <use x=\"373.580078\" xlink:href=\"#DejaVuSans-47\"/>\r\n      <use x=\"407.271484\" xlink:href=\"#DejaVuSans-80\"/>\r\n      <use x=\"465.824219\" xlink:href=\"#DejaVuSans-114\"/>\r\n      <use x=\"504.6875\" xlink:href=\"#DejaVuSans-101\"/>\r\n      <use x=\"566.210938\" xlink:href=\"#DejaVuSans-99\"/>\r\n      <use x=\"621.191406\" xlink:href=\"#DejaVuSans-105\"/>\r\n      <use x=\"648.974609\" xlink:href=\"#DejaVuSans-115\"/>\r\n      <use x=\"701.074219\" xlink:href=\"#DejaVuSans-105\"/>\r\n      <use x=\"728.857422\" xlink:href=\"#DejaVuSans-243\"/>\r\n      <use x=\"790.039062\" xlink:href=\"#DejaVuSans-110\"/>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"line2d_25\">\r\n    <path clip-path=\"url(#pb7d45e7ef7)\" d=\"M 60.935057 34.601386 \r\nL 64.009437 99.758756 \r\nL 67.083817 129.087638 \r\nL 70.158197 142.813451 \r\nL 73.232577 157.260075 \r\nL 76.306958 156.82682 \r\nL 79.381338 164.800545 \r\nL 82.455718 167.599938 \r\nL 85.530098 168.830115 \r\nL 88.604478 176.024002 \r\nL 91.678858 176.889163 \r\nL 94.753239 181.563084 \r\nL 97.827619 185.835843 \r\nL 100.901999 186.616795 \r\nL 103.976379 186.792519 \r\nL 107.050759 191.096894 \r\nL 110.125139 188.572507 \r\nL 113.19952 192.211988 \r\nL 116.2739 195.832679 \r\nL 119.34828 194.216764 \r\nL 122.42266 196.425016 \r\nL 125.49704 198.32729 \r\nL 128.57142 197.198234 \r\nL 131.645801 201.085694 \r\nL 134.720181 203.38282 \r\nL 137.794561 201.075346 \r\nL 140.868941 204.648061 \r\nL 143.943321 203.162437 \r\nL 147.017701 206.51272 \r\nL 150.092082 205.103883 \r\nL 153.166462 208.919772 \r\nL 156.240842 204.849767 \r\nL 159.315222 209.946746 \r\nL 162.389602 207.065144 \r\nL 165.463982 208.341612 \r\nL 168.538363 210.248854 \r\nL 171.612743 210.797212 \r\nL 174.687123 209.752765 \r\nL 177.761503 211.82273 \r\nL 180.835883 212.15515 \r\nL 183.910263 214.551428 \r\nL 186.984644 213.83781 \r\nL 190.059024 213.664505 \r\nL 193.133404 217.078711 \r\nL 196.207784 215.102104 \r\nL 199.282164 217.393317 \r\nL 202.356544 217.54139 \r\nL 205.430925 218.97632 \r\nL 208.505305 216.788925 \r\nL 211.579685 218.415085 \r\nL 214.654065 219.18644 \r\nL 217.728445 219.878696 \r\nL 220.802825 221.465731 \r\nL 223.877206 221.896634 \r\nL 226.951586 219.647644 \r\nL 230.025966 222.74064 \r\nL 233.100346 221.375653 \r\nL 236.174726 221.662843 \r\nL 239.249106 218.006682 \r\nL 242.323487 220.429787 \r\nL 245.397867 220.277512 \r\nL 248.472247 220.611464 \r\nL 251.546627 227.316216 \r\nL 254.621007 223.386917 \r\nL 257.695387 223.725645 \r\nL 260.769768 223.390646 \r\nL 263.844148 223.709315 \r\nL 266.918528 222.910454 \r\nL 269.992908 223.947882 \r\nL 273.067288 222.232466 \r\nL 276.141668 222.263492 \r\nL 279.216049 224.746888 \r\nL 282.290429 225.094304 \r\nL 285.364809 227.000527 \r\nL 288.439189 225.283204 \r\nL 291.513569 226.883097 \r\nL 294.587949 227.168203 \r\nL 297.66233 227.947297 \r\nL 300.73671 225.633461 \r\nL 303.81109 227.329995 \r\nL 306.88547 229.418323 \r\nL 309.95985 225.437231 \r\nL 313.03423 228.453133 \r\nL 316.108611 227.912891 \r\nL 319.182991 226.840762 \r\nL 322.257371 228.851727 \r\nL 325.331751 227.741813 \r\nL 328.406131 229.498086 \r\nL 331.480511 229.113688 \r\nL 334.554892 228.944232 \r\nL 337.629272 231.65893 \r\nL 340.703652 230.472802 \r\nL 343.778032 226.827758 \r\nL 346.852412 229.287519 \r\nL 349.926792 229.892927 \r\nL 353.001173 227.732675 \r\nL 356.075553 229.475565 \r\nL 359.149933 227.952706 \r\nL 362.224313 231.994894 \r\nL 365.298693 232.274114 \r\n\" style=\"fill:none;stroke:#e24a33;stroke-linecap:square;stroke-width:1.5;\"/>\r\n   </g>\r\n   <g id=\"line2d_26\">\r\n    <path clip-path=\"url(#pb7d45e7ef7)\" d=\"M 60.935057 164.28202 \r\nL 64.009437 135.728203 \r\nL 67.083817 121.334584 \r\nL 70.158197 115.343728 \r\nL 73.232577 109.819691 \r\nL 76.306958 106.396344 \r\nL 79.381338 106.551958 \r\nL 82.455718 104.529068 \r\nL 85.530098 104.062249 \r\nL 88.604478 102.117161 \r\nL 91.678858 101.261325 \r\nL 94.753239 98.92723 \r\nL 97.827619 96.982142 \r\nL 100.901999 96.413558 \r\nL 103.976379 97.760177 \r\nL 107.050759 95.581685 \r\nL 110.125139 94.492444 \r\nL 113.19952 93.325392 \r\nL 116.2739 92.080537 \r\nL 119.34828 95.348281 \r\nL 122.42266 92.080537 \r\nL 125.49704 91.302502 \r\nL 128.57142 92.625158 \r\nL 131.645801 89.12401 \r\nL 134.720181 89.979847 \r\nL 137.794561 90.291063 \r\nL 140.868941 87.101121 \r\nL 143.943321 88.812794 \r\nL 147.017701 88.190372 \r\nL 150.092082 88.190372 \r\nL 153.166462 86.522535 \r\nL 156.240842 89.201811 \r\nL 159.315222 87.101121 \r\nL 162.389602 86.867717 \r\nL 165.463982 87.256734 \r\nL 168.538363 85.778465 \r\nL 171.612743 85.389448 \r\nL 174.687123 87.645752 \r\nL 177.761503 85.700664 \r\nL 180.835883 85.700664 \r\nL 183.910263 85.389448 \r\nL 186.984644 84.378008 \r\nL 190.059024 84.689225 \r\nL 193.133404 83.911189 \r\nL 196.207784 84.611423 \r\nL 199.282164 83.210955 \r\nL 202.356544 83.522172 \r\nL 205.430925 82.588534 \r\nL 208.505305 83.055353 \r\nL 211.579685 83.210955 \r\nL 214.654065 82.744136 \r\nL 217.728445 82.588534 \r\nL 220.802825 83.366569 \r\nL 223.877206 81.265878 \r\nL 226.951586 82.043913 \r\nL 230.025966 80.799059 \r\nL 233.100346 82.821938 \r\nL 236.174726 81.732697 \r\nL 239.249106 83.288768 \r\nL 242.323487 82.432931 \r\nL 245.397867 82.821938 \r\nL 248.472247 83.288768 \r\nL 251.546627 79.165187 \r\nL 254.621007 81.265878 \r\nL 257.695387 80.721258 \r\nL 260.769768 81.654896 \r\nL 263.844148 80.565644 \r\nL 266.918528 81.032463 \r\nL 269.992908 82.199516 \r\nL 273.067288 81.8883 \r\nL 276.141668 82.355119 \r\nL 279.216049 82.121715 \r\nL 282.290429 80.021024 \r\nL 285.364809 79.476404 \r\nL 288.439189 81.654896 \r\nL 291.513569 78.77617 \r\nL 294.587949 80.410042 \r\nL 297.66233 79.165187 \r\nL 300.73671 80.876861 \r\nL 303.81109 79.632006 \r\nL 306.88547 79.009585 \r\nL 309.95985 80.958829 \r\nL 313.03423 79.009585 \r\nL 316.108611 79.165187 \r\nL 319.182991 79.722461 \r\nL 322.257371 78.698369 \r\nL 325.331751 79.943223 \r\nL 328.406131 79.087386 \r\nL 331.480511 78.153748 \r\nL 334.554892 78.620567 \r\nL 337.629272 78.464954 \r\nL 340.703652 78.542755 \r\nL 343.778032 80.176627 \r\nL 346.852412 78.698369 \r\nL 349.926792 78.309351 \r\nL 353.001173 80.021024 \r\nL 356.075553 77.764731 \r\nL 359.149933 79.398592 \r\nL 362.224313 76.831082 \r\nL 365.298693 78.853971 \r\n\" style=\"fill:none;stroke:#348abd;stroke-linecap:square;stroke-width:1.5;\"/>\r\n   </g>\r\n   <g id=\"patch_3\">\r\n    <path d=\"M 45.716875 242.15775 \r\nL 45.716875 24.71775 \r\n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:square;stroke-linejoin:miter;\"/>\r\n   </g>\r\n   <g id=\"patch_4\">\r\n    <path d=\"M 380.516875 242.15775 \r\nL 380.516875 24.71775 \r\n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:square;stroke-linejoin:miter;\"/>\r\n   </g>\r\n   <g id=\"patch_5\">\r\n    <path d=\"M 45.716875 242.15775 \r\nL 380.516875 242.15775 \r\n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:square;stroke-linejoin:miter;\"/>\r\n   </g>\r\n   <g id=\"patch_6\">\r\n    <path d=\"M 45.716875 24.71775 \r\nL 380.516875 24.71775 \r\n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:square;stroke-linejoin:miter;\"/>\r\n   </g>\r\n   <g id=\"text_15\">\r\n    <!-- Perdida en el entrenamiento y Precisin -->\r\n    <g transform=\"translate(69.715375 18.71775)scale(0.144 -0.144)\">\r\n     <defs>\r\n      <path d=\"M 9.421875 75.984375 \r\nL 18.40625 75.984375 \r\nL 18.40625 0 \r\nL 9.421875 0 \r\nz\r\n\" id=\"DejaVuSans-108\"/>\r\n      <path d=\"M 18.3125 70.21875 \r\nL 18.3125 54.6875 \r\nL 36.8125 54.6875 \r\nL 36.8125 47.703125 \r\nL 18.3125 47.703125 \r\nL 18.3125 18.015625 \r\nQ 18.3125 11.328125 20.140625 9.421875 \r\nQ 21.96875 7.515625 27.59375 7.515625 \r\nL 36.8125 7.515625 \r\nL 36.8125 0 \r\nL 27.59375 0 \r\nQ 17.1875 0 13.234375 3.875 \r\nQ 9.28125 7.765625 9.28125 18.015625 \r\nL 9.28125 47.703125 \r\nL 2.6875 47.703125 \r\nL 2.6875 54.6875 \r\nL 9.28125 54.6875 \r\nL 9.28125 70.21875 \r\nz\r\n\" id=\"DejaVuSans-116\"/>\r\n      <path d=\"M 32.171875 -5.078125 \r\nQ 28.375 -14.84375 24.75 -17.8125 \r\nQ 21.140625 -20.796875 15.09375 -20.796875 \r\nL 7.90625 -20.796875 \r\nL 7.90625 -13.28125 \r\nL 13.1875 -13.28125 \r\nQ 16.890625 -13.28125 18.9375 -11.515625 \r\nQ 21 -9.765625 23.484375 -3.21875 \r\nL 25.09375 0.875 \r\nL 2.984375 54.6875 \r\nL 12.5 54.6875 \r\nL 29.59375 11.921875 \r\nL 46.6875 54.6875 \r\nL 56.203125 54.6875 \r\nz\r\n\" id=\"DejaVuSans-121\"/>\r\n     </defs>\r\n     <use xlink:href=\"#DejaVuSans-80\"/>\r\n     <use x=\"56.677734\" xlink:href=\"#DejaVuSans-101\"/>\r\n     <use x=\"118.201172\" xlink:href=\"#DejaVuSans-114\"/>\r\n     <use x=\"157.564453\" xlink:href=\"#DejaVuSans-100\"/>\r\n     <use x=\"221.041016\" xlink:href=\"#DejaVuSans-105\"/>\r\n     <use x=\"248.824219\" xlink:href=\"#DejaVuSans-100\"/>\r\n     <use x=\"312.300781\" xlink:href=\"#DejaVuSans-97\"/>\r\n     <use x=\"373.580078\" xlink:href=\"#DejaVuSans-32\"/>\r\n     <use x=\"405.367188\" xlink:href=\"#DejaVuSans-101\"/>\r\n     <use x=\"466.890625\" xlink:href=\"#DejaVuSans-110\"/>\r\n     <use x=\"530.269531\" xlink:href=\"#DejaVuSans-32\"/>\r\n     <use x=\"562.056641\" xlink:href=\"#DejaVuSans-101\"/>\r\n     <use x=\"623.580078\" xlink:href=\"#DejaVuSans-108\"/>\r\n     <use x=\"651.363281\" xlink:href=\"#DejaVuSans-32\"/>\r\n     <use x=\"683.150391\" xlink:href=\"#DejaVuSans-101\"/>\r\n     <use x=\"744.673828\" xlink:href=\"#DejaVuSans-110\"/>\r\n     <use x=\"808.052734\" xlink:href=\"#DejaVuSans-116\"/>\r\n     <use x=\"847.261719\" xlink:href=\"#DejaVuSans-114\"/>\r\n     <use x=\"886.125\" xlink:href=\"#DejaVuSans-101\"/>\r\n     <use x=\"947.648438\" xlink:href=\"#DejaVuSans-110\"/>\r\n     <use x=\"1011.027344\" xlink:href=\"#DejaVuSans-97\"/>\r\n     <use x=\"1072.306641\" xlink:href=\"#DejaVuSans-109\"/>\r\n     <use x=\"1169.71875\" xlink:href=\"#DejaVuSans-105\"/>\r\n     <use x=\"1197.501953\" xlink:href=\"#DejaVuSans-101\"/>\r\n     <use x=\"1259.025391\" xlink:href=\"#DejaVuSans-110\"/>\r\n     <use x=\"1322.404297\" xlink:href=\"#DejaVuSans-116\"/>\r\n     <use x=\"1361.613281\" xlink:href=\"#DejaVuSans-111\"/>\r\n     <use x=\"1422.794922\" xlink:href=\"#DejaVuSans-32\"/>\r\n     <use x=\"1454.582031\" xlink:href=\"#DejaVuSans-121\"/>\r\n     <use x=\"1513.761719\" xlink:href=\"#DejaVuSans-32\"/>\r\n     <use x=\"1545.548828\" xlink:href=\"#DejaVuSans-80\"/>\r\n     <use x=\"1604.101562\" xlink:href=\"#DejaVuSans-114\"/>\r\n     <use x=\"1642.964844\" xlink:href=\"#DejaVuSans-101\"/>\r\n     <use x=\"1704.488281\" xlink:href=\"#DejaVuSans-99\"/>\r\n     <use x=\"1759.46875\" xlink:href=\"#DejaVuSans-105\"/>\r\n     <use x=\"1787.251953\" xlink:href=\"#DejaVuSans-115\"/>\r\n     <use x=\"1839.351562\" xlink:href=\"#DejaVuSans-105\"/>\r\n     <use x=\"1867.134766\" xlink:href=\"#DejaVuSans-243\"/>\r\n     <use x=\"1928.316406\" xlink:href=\"#DejaVuSans-110\"/>\r\n    </g>\r\n   </g>\r\n   <g id=\"legend_1\">\r\n    <g id=\"patch_7\">\r\n     <path d=\"M 293.92625 62.63025 \r\nL 373.516875 62.63025 \r\nQ 375.516875 62.63025 375.516875 60.63025 \r\nL 375.516875 31.71775 \r\nQ 375.516875 29.71775 373.516875 29.71775 \r\nL 293.92625 29.71775 \r\nQ 291.92625 29.71775 291.92625 31.71775 \r\nL 291.92625 60.63025 \r\nQ 291.92625 62.63025 293.92625 62.63025 \r\nz\r\n\" style=\"fill:#e5e5e5;opacity:0.8;stroke:#cccccc;stroke-linejoin:miter;stroke-width:0.5;\"/>\r\n    </g>\r\n    <g id=\"line2d_27\">\r\n     <path d=\"M 295.92625 37.816187 \r\nL 315.92625 37.816187 \r\n\" style=\"fill:none;stroke:#e24a33;stroke-linecap:square;stroke-width:1.5;\"/>\r\n    </g>\r\n    <g id=\"line2d_28\"/>\r\n    <g id=\"text_16\">\r\n     <!-- train_loss -->\r\n     <g transform=\"translate(323.92625 41.316187)scale(0.1 -0.1)\">\r\n      <defs>\r\n       <path d=\"M 50.984375 -16.609375 \r\nL 50.984375 -23.578125 \r\nL -0.984375 -23.578125 \r\nL -0.984375 -16.609375 \r\nz\r\n\" id=\"DejaVuSans-95\"/>\r\n      </defs>\r\n      <use xlink:href=\"#DejaVuSans-116\"/>\r\n      <use x=\"39.208984\" xlink:href=\"#DejaVuSans-114\"/>\r\n      <use x=\"80.322266\" xlink:href=\"#DejaVuSans-97\"/>\r\n      <use x=\"141.601562\" xlink:href=\"#DejaVuSans-105\"/>\r\n      <use x=\"169.384766\" xlink:href=\"#DejaVuSans-110\"/>\r\n      <use x=\"232.763672\" xlink:href=\"#DejaVuSans-95\"/>\r\n      <use x=\"282.763672\" xlink:href=\"#DejaVuSans-108\"/>\r\n      <use x=\"310.546875\" xlink:href=\"#DejaVuSans-111\"/>\r\n      <use x=\"371.728516\" xlink:href=\"#DejaVuSans-115\"/>\r\n      <use x=\"423.828125\" xlink:href=\"#DejaVuSans-115\"/>\r\n     </g>\r\n    </g>\r\n    <g id=\"line2d_29\">\r\n     <path d=\"M 295.92625 52.772437 \r\nL 315.92625 52.772437 \r\n\" style=\"fill:none;stroke:#348abd;stroke-linecap:square;stroke-width:1.5;\"/>\r\n    </g>\r\n    <g id=\"line2d_30\"/>\r\n    <g id=\"text_17\">\r\n     <!-- train_acc -->\r\n     <g transform=\"translate(323.92625 56.272437)scale(0.1 -0.1)\">\r\n      <use xlink:href=\"#DejaVuSans-116\"/>\r\n      <use x=\"39.208984\" xlink:href=\"#DejaVuSans-114\"/>\r\n      <use x=\"80.322266\" xlink:href=\"#DejaVuSans-97\"/>\r\n      <use x=\"141.601562\" xlink:href=\"#DejaVuSans-105\"/>\r\n      <use x=\"169.384766\" xlink:href=\"#DejaVuSans-110\"/>\r\n      <use x=\"232.763672\" xlink:href=\"#DejaVuSans-95\"/>\r\n      <use x=\"282.763672\" xlink:href=\"#DejaVuSans-97\"/>\r\n      <use x=\"344.042969\" xlink:href=\"#DejaVuSans-99\"/>\r\n      <use x=\"399.023438\" xlink:href=\"#DejaVuSans-99\"/>\r\n     </g>\r\n    </g>\r\n   </g>\r\n  </g>\r\n </g>\r\n <defs>\r\n  <clipPath id=\"pb7d45e7ef7\">\r\n   <rect height=\"217.44\" width=\"334.8\" x=\"45.716875\" y=\"24.71775\"/>\r\n  </clipPath>\r\n </defs>\r\n</svg>\r\n",
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "plt.style.use(\"ggplot\")\n",
        "plt.figure()\n",
        "plt.plot(np.arange(0,epochs),history.history['loss'],label=\"train_loss\")\n",
        "plt.plot(np.arange(0,epochs),history.history['accuracy'],label=\"train_acc\")\n",
        "plt.title(\"Perdida en el entrenamiento y Precisin\")\n",
        "plt.xlabel(\"Nmero de epoca\")\n",
        "plt.ylabel(\"Perdida/Precisin\")\n",
        "plt.legend(loc=\"upper right\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 432x288 with 1 Axes>",
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\r\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n<!-- Created with matplotlib (https://matplotlib.org/) -->\r\n<svg height=\"282.129625pt\" version=\"1.1\" viewBox=\"0 0 387.716875 282.129625\" width=\"387.716875pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n <metadata>\r\n  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\r\n   <cc:Work>\r\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\r\n    <dc:date>2020-11-30T21:10:04.056934</dc:date>\r\n    <dc:format>image/svg+xml</dc:format>\r\n    <dc:creator>\r\n     <cc:Agent>\r\n      <dc:title>Matplotlib v3.3.3, https://matplotlib.org/</dc:title>\r\n     </cc:Agent>\r\n    </dc:creator>\r\n   </cc:Work>\r\n  </rdf:RDF>\r\n </metadata>\r\n <defs>\r\n  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\r\n </defs>\r\n <g id=\"figure_1\">\r\n  <g id=\"patch_1\">\r\n   <path d=\"M 0 282.129625 \r\nL 387.716875 282.129625 \r\nL 387.716875 0 \r\nL 0 0 \r\nz\r\n\" style=\"fill:#ffffff;\"/>\r\n  </g>\r\n  <g id=\"axes_1\">\r\n   <g id=\"patch_2\">\r\n    <path d=\"M 45.716875 242.15775 \r\nL 380.516875 242.15775 \r\nL 380.516875 24.71775 \r\nL 45.716875 24.71775 \r\nz\r\n\" style=\"fill:#e5e5e5;\"/>\r\n   </g>\r\n   <g id=\"matplotlib.axis_1\">\r\n    <g id=\"xtick_1\">\r\n     <g id=\"line2d_1\">\r\n      <path clip-path=\"url(#p38b213bd6c)\" d=\"M 60.935057 242.15775 \r\nL 60.935057 24.71775 \r\n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:square;stroke-width:0.8;\"/>\r\n     </g>\r\n     <g id=\"line2d_2\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL 0 3.5 \r\n\" id=\"m25a6f2288d\" style=\"stroke:#555555;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"fill:#555555;stroke:#555555;stroke-width:0.8;\" x=\"60.935057\" xlink:href=\"#m25a6f2288d\" y=\"242.15775\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_1\">\r\n      <!-- 0 -->\r\n      <g style=\"fill:#555555;\" transform=\"translate(57.753807 256.756187)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 31.78125 66.40625 \r\nQ 24.171875 66.40625 20.328125 58.90625 \r\nQ 16.5 51.421875 16.5 36.375 \r\nQ 16.5 21.390625 20.328125 13.890625 \r\nQ 24.171875 6.390625 31.78125 6.390625 \r\nQ 39.453125 6.390625 43.28125 13.890625 \r\nQ 47.125 21.390625 47.125 36.375 \r\nQ 47.125 51.421875 43.28125 58.90625 \r\nQ 39.453125 66.40625 31.78125 66.40625 \r\nz\r\nM 31.78125 74.21875 \r\nQ 44.046875 74.21875 50.515625 64.515625 \r\nQ 56.984375 54.828125 56.984375 36.375 \r\nQ 56.984375 17.96875 50.515625 8.265625 \r\nQ 44.046875 -1.421875 31.78125 -1.421875 \r\nQ 19.53125 -1.421875 13.0625 8.265625 \r\nQ 6.59375 17.96875 6.59375 36.375 \r\nQ 6.59375 54.828125 13.0625 64.515625 \r\nQ 19.53125 74.21875 31.78125 74.21875 \r\nz\r\n\" id=\"DejaVuSans-48\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_2\">\r\n     <g id=\"line2d_3\">\r\n      <path clip-path=\"url(#p38b213bd6c)\" d=\"M 122.42266 242.15775 \r\nL 122.42266 24.71775 \r\n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:square;stroke-width:0.8;\"/>\r\n     </g>\r\n     <g id=\"line2d_4\">\r\n      <g>\r\n       <use style=\"fill:#555555;stroke:#555555;stroke-width:0.8;\" x=\"122.42266\" xlink:href=\"#m25a6f2288d\" y=\"242.15775\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_2\">\r\n      <!-- 20 -->\r\n      <g style=\"fill:#555555;\" transform=\"translate(116.06016 256.756187)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 19.1875 8.296875 \r\nL 53.609375 8.296875 \r\nL 53.609375 0 \r\nL 7.328125 0 \r\nL 7.328125 8.296875 \r\nQ 12.9375 14.109375 22.625 23.890625 \r\nQ 32.328125 33.6875 34.8125 36.53125 \r\nQ 39.546875 41.84375 41.421875 45.53125 \r\nQ 43.3125 49.21875 43.3125 52.78125 \r\nQ 43.3125 58.59375 39.234375 62.25 \r\nQ 35.15625 65.921875 28.609375 65.921875 \r\nQ 23.96875 65.921875 18.8125 64.3125 \r\nQ 13.671875 62.703125 7.8125 59.421875 \r\nL 7.8125 69.390625 \r\nQ 13.765625 71.78125 18.9375 73 \r\nQ 24.125 74.21875 28.421875 74.21875 \r\nQ 39.75 74.21875 46.484375 68.546875 \r\nQ 53.21875 62.890625 53.21875 53.421875 \r\nQ 53.21875 48.921875 51.53125 44.890625 \r\nQ 49.859375 40.875 45.40625 35.40625 \r\nQ 44.1875 33.984375 37.640625 27.21875 \r\nQ 31.109375 20.453125 19.1875 8.296875 \r\nz\r\n\" id=\"DejaVuSans-50\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_3\">\r\n     <g id=\"line2d_5\">\r\n      <path clip-path=\"url(#p38b213bd6c)\" d=\"M 183.910263 242.15775 \r\nL 183.910263 24.71775 \r\n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:square;stroke-width:0.8;\"/>\r\n     </g>\r\n     <g id=\"line2d_6\">\r\n      <g>\r\n       <use style=\"fill:#555555;stroke:#555555;stroke-width:0.8;\" x=\"183.910263\" xlink:href=\"#m25a6f2288d\" y=\"242.15775\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_3\">\r\n      <!-- 40 -->\r\n      <g style=\"fill:#555555;\" transform=\"translate(177.547763 256.756187)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 37.796875 64.3125 \r\nL 12.890625 25.390625 \r\nL 37.796875 25.390625 \r\nz\r\nM 35.203125 72.90625 \r\nL 47.609375 72.90625 \r\nL 47.609375 25.390625 \r\nL 58.015625 25.390625 \r\nL 58.015625 17.1875 \r\nL 47.609375 17.1875 \r\nL 47.609375 0 \r\nL 37.796875 0 \r\nL 37.796875 17.1875 \r\nL 4.890625 17.1875 \r\nL 4.890625 26.703125 \r\nz\r\n\" id=\"DejaVuSans-52\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-52\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_4\">\r\n     <g id=\"line2d_7\">\r\n      <path clip-path=\"url(#p38b213bd6c)\" d=\"M 245.397867 242.15775 \r\nL 245.397867 24.71775 \r\n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:square;stroke-width:0.8;\"/>\r\n     </g>\r\n     <g id=\"line2d_8\">\r\n      <g>\r\n       <use style=\"fill:#555555;stroke:#555555;stroke-width:0.8;\" x=\"245.397867\" xlink:href=\"#m25a6f2288d\" y=\"242.15775\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_4\">\r\n      <!-- 60 -->\r\n      <g style=\"fill:#555555;\" transform=\"translate(239.035367 256.756187)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 33.015625 40.375 \r\nQ 26.375 40.375 22.484375 35.828125 \r\nQ 18.609375 31.296875 18.609375 23.390625 \r\nQ 18.609375 15.53125 22.484375 10.953125 \r\nQ 26.375 6.390625 33.015625 6.390625 \r\nQ 39.65625 6.390625 43.53125 10.953125 \r\nQ 47.40625 15.53125 47.40625 23.390625 \r\nQ 47.40625 31.296875 43.53125 35.828125 \r\nQ 39.65625 40.375 33.015625 40.375 \r\nz\r\nM 52.59375 71.296875 \r\nL 52.59375 62.3125 \r\nQ 48.875 64.0625 45.09375 64.984375 \r\nQ 41.3125 65.921875 37.59375 65.921875 \r\nQ 27.828125 65.921875 22.671875 59.328125 \r\nQ 17.53125 52.734375 16.796875 39.40625 \r\nQ 19.671875 43.65625 24.015625 45.921875 \r\nQ 28.375 48.1875 33.59375 48.1875 \r\nQ 44.578125 48.1875 50.953125 41.515625 \r\nQ 57.328125 34.859375 57.328125 23.390625 \r\nQ 57.328125 12.15625 50.6875 5.359375 \r\nQ 44.046875 -1.421875 33.015625 -1.421875 \r\nQ 20.359375 -1.421875 13.671875 8.265625 \r\nQ 6.984375 17.96875 6.984375 36.375 \r\nQ 6.984375 53.65625 15.1875 63.9375 \r\nQ 23.390625 74.21875 37.203125 74.21875 \r\nQ 40.921875 74.21875 44.703125 73.484375 \r\nQ 48.484375 72.75 52.59375 71.296875 \r\nz\r\n\" id=\"DejaVuSans-54\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-54\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_5\">\r\n     <g id=\"line2d_9\">\r\n      <path clip-path=\"url(#p38b213bd6c)\" d=\"M 306.88547 242.15775 \r\nL 306.88547 24.71775 \r\n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:square;stroke-width:0.8;\"/>\r\n     </g>\r\n     <g id=\"line2d_10\">\r\n      <g>\r\n       <use style=\"fill:#555555;stroke:#555555;stroke-width:0.8;\" x=\"306.88547\" xlink:href=\"#m25a6f2288d\" y=\"242.15775\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_5\">\r\n      <!-- 80 -->\r\n      <g style=\"fill:#555555;\" transform=\"translate(300.52297 256.756187)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 31.78125 34.625 \r\nQ 24.75 34.625 20.71875 30.859375 \r\nQ 16.703125 27.09375 16.703125 20.515625 \r\nQ 16.703125 13.921875 20.71875 10.15625 \r\nQ 24.75 6.390625 31.78125 6.390625 \r\nQ 38.8125 6.390625 42.859375 10.171875 \r\nQ 46.921875 13.96875 46.921875 20.515625 \r\nQ 46.921875 27.09375 42.890625 30.859375 \r\nQ 38.875 34.625 31.78125 34.625 \r\nz\r\nM 21.921875 38.8125 \r\nQ 15.578125 40.375 12.03125 44.71875 \r\nQ 8.5 49.078125 8.5 55.328125 \r\nQ 8.5 64.0625 14.71875 69.140625 \r\nQ 20.953125 74.21875 31.78125 74.21875 \r\nQ 42.671875 74.21875 48.875 69.140625 \r\nQ 55.078125 64.0625 55.078125 55.328125 \r\nQ 55.078125 49.078125 51.53125 44.71875 \r\nQ 48 40.375 41.703125 38.8125 \r\nQ 48.828125 37.15625 52.796875 32.3125 \r\nQ 56.78125 27.484375 56.78125 20.515625 \r\nQ 56.78125 9.90625 50.3125 4.234375 \r\nQ 43.84375 -1.421875 31.78125 -1.421875 \r\nQ 19.734375 -1.421875 13.25 4.234375 \r\nQ 6.78125 9.90625 6.78125 20.515625 \r\nQ 6.78125 27.484375 10.78125 32.3125 \r\nQ 14.796875 37.15625 21.921875 38.8125 \r\nz\r\nM 18.3125 54.390625 \r\nQ 18.3125 48.734375 21.84375 45.5625 \r\nQ 25.390625 42.390625 31.78125 42.390625 \r\nQ 38.140625 42.390625 41.71875 45.5625 \r\nQ 45.3125 48.734375 45.3125 54.390625 \r\nQ 45.3125 60.0625 41.71875 63.234375 \r\nQ 38.140625 66.40625 31.78125 66.40625 \r\nQ 25.390625 66.40625 21.84375 63.234375 \r\nQ 18.3125 60.0625 18.3125 54.390625 \r\nz\r\n\" id=\"DejaVuSans-56\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-56\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_6\">\r\n     <g id=\"line2d_11\">\r\n      <path clip-path=\"url(#p38b213bd6c)\" d=\"M 368.373073 242.15775 \r\nL 368.373073 24.71775 \r\n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:square;stroke-width:0.8;\"/>\r\n     </g>\r\n     <g id=\"line2d_12\">\r\n      <g>\r\n       <use style=\"fill:#555555;stroke:#555555;stroke-width:0.8;\" x=\"368.373073\" xlink:href=\"#m25a6f2288d\" y=\"242.15775\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_6\">\r\n      <!-- 100 -->\r\n      <g style=\"fill:#555555;\" transform=\"translate(358.829323 256.756187)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 12.40625 8.296875 \r\nL 28.515625 8.296875 \r\nL 28.515625 63.921875 \r\nL 10.984375 60.40625 \r\nL 10.984375 69.390625 \r\nL 28.421875 72.90625 \r\nL 38.28125 72.90625 \r\nL 38.28125 8.296875 \r\nL 54.390625 8.296875 \r\nL 54.390625 0 \r\nL 12.40625 0 \r\nz\r\n\" id=\"DejaVuSans-49\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"text_7\">\r\n     <!-- Nmero de epoca -->\r\n     <g style=\"fill:#555555;\" transform=\"translate(159.82375 272.434)scale(0.12 -0.12)\">\r\n      <defs>\r\n       <path d=\"M 9.8125 72.90625 \r\nL 23.09375 72.90625 \r\nL 55.421875 11.921875 \r\nL 55.421875 72.90625 \r\nL 64.984375 72.90625 \r\nL 64.984375 0 \r\nL 51.703125 0 \r\nL 19.390625 60.984375 \r\nL 19.390625 0 \r\nL 9.8125 0 \r\nz\r\n\" id=\"DejaVuSans-78\"/>\r\n       <path d=\"M 8.5 21.578125 \r\nL 8.5 54.6875 \r\nL 17.484375 54.6875 \r\nL 17.484375 21.921875 \r\nQ 17.484375 14.15625 20.5 10.265625 \r\nQ 23.53125 6.390625 29.59375 6.390625 \r\nQ 36.859375 6.390625 41.078125 11.03125 \r\nQ 45.3125 15.671875 45.3125 23.6875 \r\nL 45.3125 54.6875 \r\nL 54.296875 54.6875 \r\nL 54.296875 0 \r\nL 45.3125 0 \r\nL 45.3125 8.40625 \r\nQ 42.046875 3.421875 37.71875 1 \r\nQ 33.40625 -1.421875 27.6875 -1.421875 \r\nQ 18.265625 -1.421875 13.375 4.4375 \r\nQ 8.5 10.296875 8.5 21.578125 \r\nz\r\nM 31.109375 56 \r\nz\r\nM 37.78125 79.984375 \r\nL 47.5 79.984375 \r\nL 31.59375 61.625 \r\nL 24.109375 61.625 \r\nz\r\n\" id=\"DejaVuSans-250\"/>\r\n       <path d=\"M 52 44.1875 \r\nQ 55.375 50.25 60.0625 53.125 \r\nQ 64.75 56 71.09375 56 \r\nQ 79.640625 56 84.28125 50.015625 \r\nQ 88.921875 44.046875 88.921875 33.015625 \r\nL 88.921875 0 \r\nL 79.890625 0 \r\nL 79.890625 32.71875 \r\nQ 79.890625 40.578125 77.09375 44.375 \r\nQ 74.3125 48.1875 68.609375 48.1875 \r\nQ 61.625 48.1875 57.5625 43.546875 \r\nQ 53.515625 38.921875 53.515625 30.90625 \r\nL 53.515625 0 \r\nL 44.484375 0 \r\nL 44.484375 32.71875 \r\nQ 44.484375 40.625 41.703125 44.40625 \r\nQ 38.921875 48.1875 33.109375 48.1875 \r\nQ 26.21875 48.1875 22.15625 43.53125 \r\nQ 18.109375 38.875 18.109375 30.90625 \r\nL 18.109375 0 \r\nL 9.078125 0 \r\nL 9.078125 54.6875 \r\nL 18.109375 54.6875 \r\nL 18.109375 46.1875 \r\nQ 21.1875 51.21875 25.484375 53.609375 \r\nQ 29.78125 56 35.6875 56 \r\nQ 41.65625 56 45.828125 52.96875 \r\nQ 50 49.953125 52 44.1875 \r\nz\r\n\" id=\"DejaVuSans-109\"/>\r\n       <path d=\"M 56.203125 29.59375 \r\nL 56.203125 25.203125 \r\nL 14.890625 25.203125 \r\nQ 15.484375 15.921875 20.484375 11.0625 \r\nQ 25.484375 6.203125 34.421875 6.203125 \r\nQ 39.59375 6.203125 44.453125 7.46875 \r\nQ 49.3125 8.734375 54.109375 11.28125 \r\nL 54.109375 2.78125 \r\nQ 49.265625 0.734375 44.1875 -0.34375 \r\nQ 39.109375 -1.421875 33.890625 -1.421875 \r\nQ 20.796875 -1.421875 13.15625 6.1875 \r\nQ 5.515625 13.8125 5.515625 26.8125 \r\nQ 5.515625 40.234375 12.765625 48.109375 \r\nQ 20.015625 56 32.328125 56 \r\nQ 43.359375 56 49.78125 48.890625 \r\nQ 56.203125 41.796875 56.203125 29.59375 \r\nz\r\nM 47.21875 32.234375 \r\nQ 47.125 39.59375 43.09375 43.984375 \r\nQ 39.0625 48.390625 32.421875 48.390625 \r\nQ 24.90625 48.390625 20.390625 44.140625 \r\nQ 15.875 39.890625 15.1875 32.171875 \r\nz\r\n\" id=\"DejaVuSans-101\"/>\r\n       <path d=\"M 41.109375 46.296875 \r\nQ 39.59375 47.171875 37.8125 47.578125 \r\nQ 36.03125 48 33.890625 48 \r\nQ 26.265625 48 22.1875 43.046875 \r\nQ 18.109375 38.09375 18.109375 28.8125 \r\nL 18.109375 0 \r\nL 9.078125 0 \r\nL 9.078125 54.6875 \r\nL 18.109375 54.6875 \r\nL 18.109375 46.1875 \r\nQ 20.953125 51.171875 25.484375 53.578125 \r\nQ 30.03125 56 36.53125 56 \r\nQ 37.453125 56 38.578125 55.875 \r\nQ 39.703125 55.765625 41.0625 55.515625 \r\nz\r\n\" id=\"DejaVuSans-114\"/>\r\n       <path d=\"M 30.609375 48.390625 \r\nQ 23.390625 48.390625 19.1875 42.75 \r\nQ 14.984375 37.109375 14.984375 27.296875 \r\nQ 14.984375 17.484375 19.15625 11.84375 \r\nQ 23.34375 6.203125 30.609375 6.203125 \r\nQ 37.796875 6.203125 41.984375 11.859375 \r\nQ 46.1875 17.53125 46.1875 27.296875 \r\nQ 46.1875 37.015625 41.984375 42.703125 \r\nQ 37.796875 48.390625 30.609375 48.390625 \r\nz\r\nM 30.609375 56 \r\nQ 42.328125 56 49.015625 48.375 \r\nQ 55.71875 40.765625 55.71875 27.296875 \r\nQ 55.71875 13.875 49.015625 6.21875 \r\nQ 42.328125 -1.421875 30.609375 -1.421875 \r\nQ 18.84375 -1.421875 12.171875 6.21875 \r\nQ 5.515625 13.875 5.515625 27.296875 \r\nQ 5.515625 40.765625 12.171875 48.375 \r\nQ 18.84375 56 30.609375 56 \r\nz\r\n\" id=\"DejaVuSans-111\"/>\r\n       <path id=\"DejaVuSans-32\"/>\r\n       <path d=\"M 45.40625 46.390625 \r\nL 45.40625 75.984375 \r\nL 54.390625 75.984375 \r\nL 54.390625 0 \r\nL 45.40625 0 \r\nL 45.40625 8.203125 \r\nQ 42.578125 3.328125 38.25 0.953125 \r\nQ 33.9375 -1.421875 27.875 -1.421875 \r\nQ 17.96875 -1.421875 11.734375 6.484375 \r\nQ 5.515625 14.40625 5.515625 27.296875 \r\nQ 5.515625 40.1875 11.734375 48.09375 \r\nQ 17.96875 56 27.875 56 \r\nQ 33.9375 56 38.25 53.625 \r\nQ 42.578125 51.265625 45.40625 46.390625 \r\nz\r\nM 14.796875 27.296875 \r\nQ 14.796875 17.390625 18.875 11.75 \r\nQ 22.953125 6.109375 30.078125 6.109375 \r\nQ 37.203125 6.109375 41.296875 11.75 \r\nQ 45.40625 17.390625 45.40625 27.296875 \r\nQ 45.40625 37.203125 41.296875 42.84375 \r\nQ 37.203125 48.484375 30.078125 48.484375 \r\nQ 22.953125 48.484375 18.875 42.84375 \r\nQ 14.796875 37.203125 14.796875 27.296875 \r\nz\r\n\" id=\"DejaVuSans-100\"/>\r\n       <path d=\"M 18.109375 8.203125 \r\nL 18.109375 -20.796875 \r\nL 9.078125 -20.796875 \r\nL 9.078125 54.6875 \r\nL 18.109375 54.6875 \r\nL 18.109375 46.390625 \r\nQ 20.953125 51.265625 25.265625 53.625 \r\nQ 29.59375 56 35.59375 56 \r\nQ 45.5625 56 51.78125 48.09375 \r\nQ 58.015625 40.1875 58.015625 27.296875 \r\nQ 58.015625 14.40625 51.78125 6.484375 \r\nQ 45.5625 -1.421875 35.59375 -1.421875 \r\nQ 29.59375 -1.421875 25.265625 0.953125 \r\nQ 20.953125 3.328125 18.109375 8.203125 \r\nz\r\nM 48.6875 27.296875 \r\nQ 48.6875 37.203125 44.609375 42.84375 \r\nQ 40.53125 48.484375 33.40625 48.484375 \r\nQ 26.265625 48.484375 22.1875 42.84375 \r\nQ 18.109375 37.203125 18.109375 27.296875 \r\nQ 18.109375 17.390625 22.1875 11.75 \r\nQ 26.265625 6.109375 33.40625 6.109375 \r\nQ 40.53125 6.109375 44.609375 11.75 \r\nQ 48.6875 17.390625 48.6875 27.296875 \r\nz\r\n\" id=\"DejaVuSans-112\"/>\r\n       <path d=\"M 48.78125 52.59375 \r\nL 48.78125 44.1875 \r\nQ 44.96875 46.296875 41.140625 47.34375 \r\nQ 37.3125 48.390625 33.40625 48.390625 \r\nQ 24.65625 48.390625 19.8125 42.84375 \r\nQ 14.984375 37.3125 14.984375 27.296875 \r\nQ 14.984375 17.28125 19.8125 11.734375 \r\nQ 24.65625 6.203125 33.40625 6.203125 \r\nQ 37.3125 6.203125 41.140625 7.25 \r\nQ 44.96875 8.296875 48.78125 10.40625 \r\nL 48.78125 2.09375 \r\nQ 45.015625 0.34375 40.984375 -0.53125 \r\nQ 36.96875 -1.421875 32.421875 -1.421875 \r\nQ 20.0625 -1.421875 12.78125 6.34375 \r\nQ 5.515625 14.109375 5.515625 27.296875 \r\nQ 5.515625 40.671875 12.859375 48.328125 \r\nQ 20.21875 56 33.015625 56 \r\nQ 37.15625 56 41.109375 55.140625 \r\nQ 45.0625 54.296875 48.78125 52.59375 \r\nz\r\n\" id=\"DejaVuSans-99\"/>\r\n       <path d=\"M 34.28125 27.484375 \r\nQ 23.390625 27.484375 19.1875 25 \r\nQ 14.984375 22.515625 14.984375 16.5 \r\nQ 14.984375 11.71875 18.140625 8.90625 \r\nQ 21.296875 6.109375 26.703125 6.109375 \r\nQ 34.1875 6.109375 38.703125 11.40625 \r\nQ 43.21875 16.703125 43.21875 25.484375 \r\nL 43.21875 27.484375 \r\nz\r\nM 52.203125 31.203125 \r\nL 52.203125 0 \r\nL 43.21875 0 \r\nL 43.21875 8.296875 \r\nQ 40.140625 3.328125 35.546875 0.953125 \r\nQ 30.953125 -1.421875 24.3125 -1.421875 \r\nQ 15.921875 -1.421875 10.953125 3.296875 \r\nQ 6 8.015625 6 15.921875 \r\nQ 6 25.140625 12.171875 29.828125 \r\nQ 18.359375 34.515625 30.609375 34.515625 \r\nL 43.21875 34.515625 \r\nL 43.21875 35.40625 \r\nQ 43.21875 41.609375 39.140625 45 \r\nQ 35.0625 48.390625 27.6875 48.390625 \r\nQ 23 48.390625 18.546875 47.265625 \r\nQ 14.109375 46.140625 10.015625 43.890625 \r\nL 10.015625 52.203125 \r\nQ 14.9375 54.109375 19.578125 55.046875 \r\nQ 24.21875 56 28.609375 56 \r\nQ 40.484375 56 46.34375 49.84375 \r\nQ 52.203125 43.703125 52.203125 31.203125 \r\nz\r\n\" id=\"DejaVuSans-97\"/>\r\n      </defs>\r\n      <use xlink:href=\"#DejaVuSans-78\"/>\r\n      <use x=\"74.804688\" xlink:href=\"#DejaVuSans-250\"/>\r\n      <use x=\"138.183594\" xlink:href=\"#DejaVuSans-109\"/>\r\n      <use x=\"235.595703\" xlink:href=\"#DejaVuSans-101\"/>\r\n      <use x=\"297.119141\" xlink:href=\"#DejaVuSans-114\"/>\r\n      <use x=\"335.982422\" xlink:href=\"#DejaVuSans-111\"/>\r\n      <use x=\"397.164062\" xlink:href=\"#DejaVuSans-32\"/>\r\n      <use x=\"428.951172\" xlink:href=\"#DejaVuSans-100\"/>\r\n      <use x=\"492.427734\" xlink:href=\"#DejaVuSans-101\"/>\r\n      <use x=\"553.951172\" xlink:href=\"#DejaVuSans-32\"/>\r\n      <use x=\"585.738281\" xlink:href=\"#DejaVuSans-101\"/>\r\n      <use x=\"647.261719\" xlink:href=\"#DejaVuSans-112\"/>\r\n      <use x=\"710.738281\" xlink:href=\"#DejaVuSans-111\"/>\r\n      <use x=\"771.919922\" xlink:href=\"#DejaVuSans-99\"/>\r\n      <use x=\"826.900391\" xlink:href=\"#DejaVuSans-97\"/>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"matplotlib.axis_2\">\r\n    <g id=\"ytick_1\">\r\n     <g id=\"line2d_13\">\r\n      <path clip-path=\"url(#p38b213bd6c)\" d=\"M 45.716875 215.637753 \r\nL 380.516875 215.637753 \r\n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:square;stroke-width:0.8;\"/>\r\n     </g>\r\n     <g id=\"line2d_14\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL -3.5 0 \r\n\" id=\"m9901f0bdc7\" style=\"stroke:#555555;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"fill:#555555;stroke:#555555;stroke-width:0.8;\" x=\"45.716875\" xlink:href=\"#m9901f0bdc7\" y=\"215.637753\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_8\">\r\n      <!-- 0.5 -->\r\n      <g style=\"fill:#555555;\" transform=\"translate(22.81375 219.436972)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 10.6875 12.40625 \r\nL 21 12.40625 \r\nL 21 0 \r\nL 10.6875 0 \r\nz\r\n\" id=\"DejaVuSans-46\"/>\r\n        <path d=\"M 10.796875 72.90625 \r\nL 49.515625 72.90625 \r\nL 49.515625 64.59375 \r\nL 19.828125 64.59375 \r\nL 19.828125 46.734375 \r\nQ 21.96875 47.46875 24.109375 47.828125 \r\nQ 26.265625 48.1875 28.421875 48.1875 \r\nQ 40.625 48.1875 47.75 41.5 \r\nQ 54.890625 34.8125 54.890625 23.390625 \r\nQ 54.890625 11.625 47.5625 5.09375 \r\nQ 40.234375 -1.421875 26.90625 -1.421875 \r\nQ 22.3125 -1.421875 17.546875 -0.640625 \r\nQ 12.796875 0.140625 7.71875 1.703125 \r\nL 7.71875 11.625 \r\nQ 12.109375 9.234375 16.796875 8.0625 \r\nQ 21.484375 6.890625 26.703125 6.890625 \r\nQ 35.15625 6.890625 40.078125 11.328125 \r\nQ 45.015625 15.765625 45.015625 23.390625 \r\nQ 45.015625 31 40.078125 35.4375 \r\nQ 35.15625 39.890625 26.703125 39.890625 \r\nQ 22.75 39.890625 18.8125 39.015625 \r\nQ 14.890625 38.140625 10.796875 36.28125 \r\nz\r\n\" id=\"DejaVuSans-53\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_2\">\r\n     <g id=\"line2d_15\">\r\n      <path clip-path=\"url(#p38b213bd6c)\" d=\"M 45.716875 185.499418 \r\nL 380.516875 185.499418 \r\n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:square;stroke-width:0.8;\"/>\r\n     </g>\r\n     <g id=\"line2d_16\">\r\n      <g>\r\n       <use style=\"fill:#555555;stroke:#555555;stroke-width:0.8;\" x=\"45.716875\" xlink:href=\"#m9901f0bdc7\" y=\"185.499418\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_9\">\r\n      <!-- 1.0 -->\r\n      <g style=\"fill:#555555;\" transform=\"translate(22.81375 189.298636)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_3\">\r\n     <g id=\"line2d_17\">\r\n      <path clip-path=\"url(#p38b213bd6c)\" d=\"M 45.716875 155.361082 \r\nL 380.516875 155.361082 \r\n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:square;stroke-width:0.8;\"/>\r\n     </g>\r\n     <g id=\"line2d_18\">\r\n      <g>\r\n       <use style=\"fill:#555555;stroke:#555555;stroke-width:0.8;\" x=\"45.716875\" xlink:href=\"#m9901f0bdc7\" y=\"155.361082\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_10\">\r\n      <!-- 1.5 -->\r\n      <g style=\"fill:#555555;\" transform=\"translate(22.81375 159.160301)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_4\">\r\n     <g id=\"line2d_19\">\r\n      <path clip-path=\"url(#p38b213bd6c)\" d=\"M 45.716875 125.222747 \r\nL 380.516875 125.222747 \r\n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:square;stroke-width:0.8;\"/>\r\n     </g>\r\n     <g id=\"line2d_20\">\r\n      <g>\r\n       <use style=\"fill:#555555;stroke:#555555;stroke-width:0.8;\" x=\"45.716875\" xlink:href=\"#m9901f0bdc7\" y=\"125.222747\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_11\">\r\n      <!-- 2.0 -->\r\n      <g style=\"fill:#555555;\" transform=\"translate(22.81375 129.021966)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_5\">\r\n     <g id=\"line2d_21\">\r\n      <path clip-path=\"url(#p38b213bd6c)\" d=\"M 45.716875 95.084411 \r\nL 380.516875 95.084411 \r\n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:square;stroke-width:0.8;\"/>\r\n     </g>\r\n     <g id=\"line2d_22\">\r\n      <g>\r\n       <use style=\"fill:#555555;stroke:#555555;stroke-width:0.8;\" x=\"45.716875\" xlink:href=\"#m9901f0bdc7\" y=\"95.084411\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_12\">\r\n      <!-- 2.5 -->\r\n      <g style=\"fill:#555555;\" transform=\"translate(22.81375 98.88363)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_6\">\r\n     <g id=\"line2d_23\">\r\n      <path clip-path=\"url(#p38b213bd6c)\" d=\"M 45.716875 64.946076 \r\nL 380.516875 64.946076 \r\n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:square;stroke-width:0.8;\"/>\r\n     </g>\r\n     <g id=\"line2d_24\">\r\n      <g>\r\n       <use style=\"fill:#555555;stroke:#555555;stroke-width:0.8;\" x=\"45.716875\" xlink:href=\"#m9901f0bdc7\" y=\"64.946076\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_13\">\r\n      <!-- 3.0 -->\r\n      <g style=\"fill:#555555;\" transform=\"translate(22.81375 68.745295)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 40.578125 39.3125 \r\nQ 47.65625 37.796875 51.625 33 \r\nQ 55.609375 28.21875 55.609375 21.1875 \r\nQ 55.609375 10.40625 48.1875 4.484375 \r\nQ 40.765625 -1.421875 27.09375 -1.421875 \r\nQ 22.515625 -1.421875 17.65625 -0.515625 \r\nQ 12.796875 0.390625 7.625 2.203125 \r\nL 7.625 11.71875 \r\nQ 11.71875 9.328125 16.59375 8.109375 \r\nQ 21.484375 6.890625 26.8125 6.890625 \r\nQ 36.078125 6.890625 40.9375 10.546875 \r\nQ 45.796875 14.203125 45.796875 21.1875 \r\nQ 45.796875 27.640625 41.28125 31.265625 \r\nQ 36.765625 34.90625 28.71875 34.90625 \r\nL 20.21875 34.90625 \r\nL 20.21875 43.015625 \r\nL 29.109375 43.015625 \r\nQ 36.375 43.015625 40.234375 45.921875 \r\nQ 44.09375 48.828125 44.09375 54.296875 \r\nQ 44.09375 59.90625 40.109375 62.90625 \r\nQ 36.140625 65.921875 28.71875 65.921875 \r\nQ 24.65625 65.921875 20.015625 65.03125 \r\nQ 15.375 64.15625 9.8125 62.3125 \r\nL 9.8125 71.09375 \r\nQ 15.4375 72.65625 20.34375 73.4375 \r\nQ 25.25 74.21875 29.59375 74.21875 \r\nQ 40.828125 74.21875 47.359375 69.109375 \r\nQ 53.90625 64.015625 53.90625 55.328125 \r\nQ 53.90625 49.265625 50.4375 45.09375 \r\nQ 46.96875 40.921875 40.578125 39.3125 \r\nz\r\n\" id=\"DejaVuSans-51\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-51\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_7\">\r\n     <g id=\"line2d_25\">\r\n      <path clip-path=\"url(#p38b213bd6c)\" d=\"M 45.716875 34.807741 \r\nL 380.516875 34.807741 \r\n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:square;stroke-width:0.8;\"/>\r\n     </g>\r\n     <g id=\"line2d_26\">\r\n      <g>\r\n       <use style=\"fill:#555555;stroke:#555555;stroke-width:0.8;\" x=\"45.716875\" xlink:href=\"#m9901f0bdc7\" y=\"34.807741\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_14\">\r\n      <!-- 3.5 -->\r\n      <g style=\"fill:#555555;\" transform=\"translate(22.81375 38.606959)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-51\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"text_15\">\r\n     <!-- Perdida/Precisin -->\r\n     <g style=\"fill:#555555;\" transform=\"translate(16.318125 184.643062)rotate(-90)scale(0.12 -0.12)\">\r\n      <defs>\r\n       <path d=\"M 19.671875 64.796875 \r\nL 19.671875 37.40625 \r\nL 32.078125 37.40625 \r\nQ 38.96875 37.40625 42.71875 40.96875 \r\nQ 46.484375 44.53125 46.484375 51.125 \r\nQ 46.484375 57.671875 42.71875 61.234375 \r\nQ 38.96875 64.796875 32.078125 64.796875 \r\nz\r\nM 9.8125 72.90625 \r\nL 32.078125 72.90625 \r\nQ 44.34375 72.90625 50.609375 67.359375 \r\nQ 56.890625 61.8125 56.890625 51.125 \r\nQ 56.890625 40.328125 50.609375 34.8125 \r\nQ 44.34375 29.296875 32.078125 29.296875 \r\nL 19.671875 29.296875 \r\nL 19.671875 0 \r\nL 9.8125 0 \r\nz\r\n\" id=\"DejaVuSans-80\"/>\r\n       <path d=\"M 9.421875 54.6875 \r\nL 18.40625 54.6875 \r\nL 18.40625 0 \r\nL 9.421875 0 \r\nz\r\nM 9.421875 75.984375 \r\nL 18.40625 75.984375 \r\nL 18.40625 64.59375 \r\nL 9.421875 64.59375 \r\nz\r\n\" id=\"DejaVuSans-105\"/>\r\n       <path d=\"M 25.390625 72.90625 \r\nL 33.6875 72.90625 \r\nL 8.296875 -9.28125 \r\nL 0 -9.28125 \r\nz\r\n\" id=\"DejaVuSans-47\"/>\r\n       <path d=\"M 44.28125 53.078125 \r\nL 44.28125 44.578125 \r\nQ 40.484375 46.53125 36.375 47.5 \r\nQ 32.28125 48.484375 27.875 48.484375 \r\nQ 21.1875 48.484375 17.84375 46.4375 \r\nQ 14.5 44.390625 14.5 40.28125 \r\nQ 14.5 37.15625 16.890625 35.375 \r\nQ 19.28125 33.59375 26.515625 31.984375 \r\nL 29.59375 31.296875 \r\nQ 39.15625 29.25 43.1875 25.515625 \r\nQ 47.21875 21.78125 47.21875 15.09375 \r\nQ 47.21875 7.46875 41.1875 3.015625 \r\nQ 35.15625 -1.421875 24.609375 -1.421875 \r\nQ 20.21875 -1.421875 15.453125 -0.5625 \r\nQ 10.6875 0.296875 5.421875 2 \r\nL 5.421875 11.28125 \r\nQ 10.40625 8.6875 15.234375 7.390625 \r\nQ 20.0625 6.109375 24.8125 6.109375 \r\nQ 31.15625 6.109375 34.5625 8.28125 \r\nQ 37.984375 10.453125 37.984375 14.40625 \r\nQ 37.984375 18.0625 35.515625 20.015625 \r\nQ 33.0625 21.96875 24.703125 23.78125 \r\nL 21.578125 24.515625 \r\nQ 13.234375 26.265625 9.515625 29.90625 \r\nQ 5.8125 33.546875 5.8125 39.890625 \r\nQ 5.8125 47.609375 11.28125 51.796875 \r\nQ 16.75 56 26.8125 56 \r\nQ 31.78125 56 36.171875 55.265625 \r\nQ 40.578125 54.546875 44.28125 53.078125 \r\nz\r\n\" id=\"DejaVuSans-115\"/>\r\n       <path d=\"M 30.609375 48.390625 \r\nQ 23.390625 48.390625 19.1875 42.75 \r\nQ 14.984375 37.109375 14.984375 27.296875 \r\nQ 14.984375 17.484375 19.15625 11.84375 \r\nQ 23.34375 6.203125 30.609375 6.203125 \r\nQ 37.796875 6.203125 41.984375 11.859375 \r\nQ 46.1875 17.53125 46.1875 27.296875 \r\nQ 46.1875 37.015625 41.984375 42.703125 \r\nQ 37.796875 48.390625 30.609375 48.390625 \r\nz\r\nM 30.609375 56 \r\nQ 42.328125 56 49.015625 48.375 \r\nQ 55.71875 40.765625 55.71875 27.296875 \r\nQ 55.71875 13.875 49.015625 6.21875 \r\nQ 42.328125 -1.421875 30.609375 -1.421875 \r\nQ 18.84375 -1.421875 12.171875 6.21875 \r\nQ 5.515625 13.875 5.515625 27.296875 \r\nQ 5.515625 40.765625 12.171875 48.375 \r\nQ 18.84375 56 30.609375 56 \r\nz\r\nM 37.40625 79.984375 \r\nL 47.125 79.984375 \r\nL 31.21875 61.625 \r\nL 23.734375 61.625 \r\nz\r\n\" id=\"DejaVuSans-243\"/>\r\n       <path d=\"M 54.890625 33.015625 \r\nL 54.890625 0 \r\nL 45.90625 0 \r\nL 45.90625 32.71875 \r\nQ 45.90625 40.484375 42.875 44.328125 \r\nQ 39.84375 48.1875 33.796875 48.1875 \r\nQ 26.515625 48.1875 22.3125 43.546875 \r\nQ 18.109375 38.921875 18.109375 30.90625 \r\nL 18.109375 0 \r\nL 9.078125 0 \r\nL 9.078125 54.6875 \r\nL 18.109375 54.6875 \r\nL 18.109375 46.1875 \r\nQ 21.34375 51.125 25.703125 53.5625 \r\nQ 30.078125 56 35.796875 56 \r\nQ 45.21875 56 50.046875 50.171875 \r\nQ 54.890625 44.34375 54.890625 33.015625 \r\nz\r\n\" id=\"DejaVuSans-110\"/>\r\n      </defs>\r\n      <use xlink:href=\"#DejaVuSans-80\"/>\r\n      <use x=\"56.677734\" xlink:href=\"#DejaVuSans-101\"/>\r\n      <use x=\"118.201172\" xlink:href=\"#DejaVuSans-114\"/>\r\n      <use x=\"157.564453\" xlink:href=\"#DejaVuSans-100\"/>\r\n      <use x=\"221.041016\" xlink:href=\"#DejaVuSans-105\"/>\r\n      <use x=\"248.824219\" xlink:href=\"#DejaVuSans-100\"/>\r\n      <use x=\"312.300781\" xlink:href=\"#DejaVuSans-97\"/>\r\n      <use x=\"373.580078\" xlink:href=\"#DejaVuSans-47\"/>\r\n      <use x=\"407.271484\" xlink:href=\"#DejaVuSans-80\"/>\r\n      <use x=\"465.824219\" xlink:href=\"#DejaVuSans-114\"/>\r\n      <use x=\"504.6875\" xlink:href=\"#DejaVuSans-101\"/>\r\n      <use x=\"566.210938\" xlink:href=\"#DejaVuSans-99\"/>\r\n      <use x=\"621.191406\" xlink:href=\"#DejaVuSans-105\"/>\r\n      <use x=\"648.974609\" xlink:href=\"#DejaVuSans-115\"/>\r\n      <use x=\"701.074219\" xlink:href=\"#DejaVuSans-105\"/>\r\n      <use x=\"728.857422\" xlink:href=\"#DejaVuSans-243\"/>\r\n      <use x=\"790.039062\" xlink:href=\"#DejaVuSans-110\"/>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"line2d_27\">\r\n    <path clip-path=\"url(#p38b213bd6c)\" d=\"M 60.935057 156.350057 \r\nL 64.009437 132.096513 \r\nL 67.083817 99.180902 \r\nL 70.158197 93.388279 \r\nL 73.232577 80.263317 \r\nL 76.306958 39.722506 \r\nL 79.381338 34.601386 \r\nL 82.455718 64.836037 \r\nL 85.530098 111.640023 \r\nL 88.604478 139.450933 \r\nL 91.678858 173.425657 \r\nL 94.753239 180.225167 \r\nL 97.827619 210.379034 \r\nL 100.901999 215.097594 \r\nL 103.976379 221.799232 \r\nL 107.050759 218.419223 \r\nL 110.125139 221.343326 \r\nL 113.19952 221.544004 \r\nL 116.2739 222.104379 \r\nL 119.34828 220.619931 \r\nL 122.42266 216.356043 \r\nL 125.49704 211.981187 \r\nL 128.57142 214.954545 \r\nL 131.645801 224.175916 \r\nL 134.720181 212.872991 \r\nL 137.794561 218.644522 \r\nL 140.868941 219.690322 \r\nL 143.943321 218.200975 \r\nL 147.017701 218.577431 \r\nL 150.092082 214.635313 \r\nL 153.166462 219.450765 \r\nL 156.240842 217.397405 \r\nL 159.315222 221.148451 \r\nL 162.389602 220.776222 \r\nL 165.463982 218.721213 \r\nL 168.538363 221.246109 \r\nL 171.612743 215.085939 \r\nL 174.687123 217.596254 \r\nL 177.761503 221.835667 \r\nL 180.835883 220.276485 \r\nL 183.910263 212.945421 \r\nL 186.984644 217.548952 \r\nL 190.059024 215.983537 \r\nL 193.133404 220.639274 \r\nL 196.207784 219.10888 \r\nL 199.282164 215.929956 \r\nL 202.356544 215.436159 \r\nL 205.430925 218.446889 \r\nL 208.505305 210.569638 \r\nL 211.579685 214.131208 \r\nL 214.654065 214.950276 \r\nL 217.728445 219.714813 \r\nL 220.802825 211.192854 \r\nL 223.877206 218.801591 \r\nL 226.951586 218.027933 \r\nL 230.025966 220.076963 \r\nL 233.100346 212.626186 \r\nL 236.174726 214.025857 \r\nL 239.249106 218.246563 \r\nL 242.323487 215.805578 \r\nL 245.397867 211.792929 \r\nL 248.472247 216.961541 \r\nL 251.546627 218.870746 \r\nL 254.621007 215.961258 \r\nL 257.695387 214.572899 \r\nL 260.769768 219.030763 \r\nL 263.844148 216.213688 \r\nL 266.918528 216.253712 \r\nL 269.992908 217.449657 \r\nL 273.067288 215.530652 \r\nL 276.141668 216.473402 \r\nL 279.216049 216.59461 \r\nL 282.290429 213.844206 \r\nL 285.364809 213.644574 \r\nL 288.439189 215.588762 \r\nL 291.513569 217.284849 \r\nL 294.587949 214.968905 \r\nL 297.66233 216.047929 \r\nL 300.73671 212.327892 \r\nL 303.81109 217.47609 \r\nL 306.88547 216.642334 \r\nL 309.95985 216.429078 \r\nL 313.03423 215.554613 \r\nL 316.108611 214.696893 \r\nL 319.182991 212.962214 \r\nL 322.257371 215.884212 \r\nL 325.331751 217.185592 \r\nL 328.406131 215.49798 \r\nL 331.480511 212.534006 \r\nL 334.554892 212.691071 \r\nL 337.629272 215.834249 \r\nL 340.703652 213.992218 \r\nL 343.778032 215.766739 \r\nL 346.852412 213.957853 \r\nL 349.926792 215.389259 \r\nL 353.001173 214.354128 \r\nL 356.075553 215.85463 \r\nL 359.149933 214.419887 \r\nL 362.224313 209.472884 \r\nL 365.298693 212.08376 \r\n\" style=\"fill:none;stroke:#e24a33;stroke-linecap:square;stroke-width:1.5;\"/>\r\n   </g>\r\n   <g id=\"line2d_28\">\r\n    <path clip-path=\"url(#p38b213bd6c)\" d=\"M 60.935057 230.42563 \r\nL 64.009437 231.87227 \r\nL 67.083817 232.033007 \r\nL 70.158197 232.274114 \r\nL 73.232577 232.033007 \r\nL 76.306958 232.033007 \r\nL 79.381338 232.033007 \r\nL 82.455718 231.711532 \r\nL 85.530098 224.880176 \r\nL 88.604478 221.343944 \r\nL 91.678858 214.914431 \r\nL 94.753239 213.467792 \r\nL 97.827619 201.492829 \r\nL 100.901999 198.036965 \r\nL 103.976379 195.143686 \r\nL 107.050759 195.947375 \r\nL 110.125139 195.063316 \r\nL 113.19952 195.063316 \r\nL 116.2739 194.902579 \r\nL 119.34828 195.063316 \r\nL 122.42266 197.394014 \r\nL 125.49704 198.036965 \r\nL 128.57142 197.152907 \r\nL 131.645801 194.098888 \r\nL 134.720181 198.358439 \r\nL 137.794561 195.947375 \r\nL 140.868941 195.545531 \r\nL 143.943321 196.268848 \r\nL 147.017701 195.46516 \r\nL 150.092082 196.670693 \r\nL 153.166462 194.259628 \r\nL 156.240842 195.947375 \r\nL 159.315222 194.581102 \r\nL 162.389602 194.982946 \r\nL 165.463982 195.947375 \r\nL 168.538363 194.098888 \r\nL 171.612743 196.108112 \r\nL 174.687123 195.304423 \r\nL 177.761503 193.938151 \r\nL 180.835883 194.259628 \r\nL 183.910263 197.072537 \r\nL 186.984644 195.545531 \r\nL 190.059024 196.027741 \r\nL 193.133404 194.339995 \r\nL 196.207784 194.259628 \r\nL 199.282164 194.902579 \r\nL 202.356544 195.625897 \r\nL 205.430925 195.063316 \r\nL 208.505305 196.751063 \r\nL 211.579685 196.108112 \r\nL 214.654065 195.143686 \r\nL 217.728445 194.500735 \r\nL 220.802825 196.429589 \r\nL 223.877206 193.938151 \r\nL 226.951586 194.581102 \r\nL 230.025966 194.339995 \r\nL 233.100346 195.38479 \r\nL 236.174726 195.38479 \r\nL 239.249106 194.822209 \r\nL 242.323487 195.706267 \r\nL 245.397867 196.188482 \r\nL 248.472247 195.063316 \r\nL 251.546627 194.822209 \r\nL 254.621007 194.741839 \r\nL 257.695387 195.224053 \r\nL 260.769768 194.179258 \r\nL 263.844148 194.500735 \r\nL 266.918528 194.259628 \r\nL 269.992908 194.420365 \r\nL 273.067288 195.304423 \r\nL 276.141668 194.500735 \r\nL 279.216049 194.661472 \r\nL 282.290429 194.741839 \r\nL 285.364809 194.982946 \r\nL 288.439189 195.224053 \r\nL 291.513569 194.902579 \r\nL 294.587949 195.143686 \r\nL 297.66233 194.661472 \r\nL 300.73671 196.188482 \r\nL 303.81109 194.661472 \r\nL 306.88547 194.500735 \r\nL 309.95985 194.339995 \r\nL 313.03423 194.741839 \r\nL 316.108611 194.982946 \r\nL 319.182991 195.46516 \r\nL 322.257371 194.581102 \r\nL 325.331751 194.661472 \r\nL 328.406131 194.259628 \r\nL 331.480511 195.143686 \r\nL 334.554892 194.741839 \r\nL 337.629272 194.339995 \r\nL 340.703652 194.741839 \r\nL 343.778032 194.661472 \r\nL 346.852412 194.741839 \r\nL 349.926792 194.259628 \r\nL 353.001173 194.902579 \r\nL 356.075553 194.339995 \r\nL 359.149933 194.902579 \r\nL 362.224313 195.625897 \r\nL 365.298693 195.063316 \r\n\" style=\"fill:none;stroke:#348abd;stroke-linecap:square;stroke-width:1.5;\"/>\r\n   </g>\r\n   <g id=\"patch_3\">\r\n    <path d=\"M 45.716875 242.15775 \r\nL 45.716875 24.71775 \r\n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:square;stroke-linejoin:miter;\"/>\r\n   </g>\r\n   <g id=\"patch_4\">\r\n    <path d=\"M 380.516875 242.15775 \r\nL 380.516875 24.71775 \r\n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:square;stroke-linejoin:miter;\"/>\r\n   </g>\r\n   <g id=\"patch_5\">\r\n    <path d=\"M 45.716875 242.15775 \r\nL 380.516875 242.15775 \r\n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:square;stroke-linejoin:miter;\"/>\r\n   </g>\r\n   <g id=\"patch_6\">\r\n    <path d=\"M 45.716875 24.71775 \r\nL 380.516875 24.71775 \r\n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:square;stroke-linejoin:miter;\"/>\r\n   </g>\r\n   <g id=\"text_16\">\r\n    <!-- Perdida en el entrenamiento y Precisin -->\r\n    <g transform=\"translate(69.715375 18.71775)scale(0.144 -0.144)\">\r\n     <defs>\r\n      <path d=\"M 9.421875 75.984375 \r\nL 18.40625 75.984375 \r\nL 18.40625 0 \r\nL 9.421875 0 \r\nz\r\n\" id=\"DejaVuSans-108\"/>\r\n      <path d=\"M 18.3125 70.21875 \r\nL 18.3125 54.6875 \r\nL 36.8125 54.6875 \r\nL 36.8125 47.703125 \r\nL 18.3125 47.703125 \r\nL 18.3125 18.015625 \r\nQ 18.3125 11.328125 20.140625 9.421875 \r\nQ 21.96875 7.515625 27.59375 7.515625 \r\nL 36.8125 7.515625 \r\nL 36.8125 0 \r\nL 27.59375 0 \r\nQ 17.1875 0 13.234375 3.875 \r\nQ 9.28125 7.765625 9.28125 18.015625 \r\nL 9.28125 47.703125 \r\nL 2.6875 47.703125 \r\nL 2.6875 54.6875 \r\nL 9.28125 54.6875 \r\nL 9.28125 70.21875 \r\nz\r\n\" id=\"DejaVuSans-116\"/>\r\n      <path d=\"M 32.171875 -5.078125 \r\nQ 28.375 -14.84375 24.75 -17.8125 \r\nQ 21.140625 -20.796875 15.09375 -20.796875 \r\nL 7.90625 -20.796875 \r\nL 7.90625 -13.28125 \r\nL 13.1875 -13.28125 \r\nQ 16.890625 -13.28125 18.9375 -11.515625 \r\nQ 21 -9.765625 23.484375 -3.21875 \r\nL 25.09375 0.875 \r\nL 2.984375 54.6875 \r\nL 12.5 54.6875 \r\nL 29.59375 11.921875 \r\nL 46.6875 54.6875 \r\nL 56.203125 54.6875 \r\nz\r\n\" id=\"DejaVuSans-121\"/>\r\n     </defs>\r\n     <use xlink:href=\"#DejaVuSans-80\"/>\r\n     <use x=\"56.677734\" xlink:href=\"#DejaVuSans-101\"/>\r\n     <use x=\"118.201172\" xlink:href=\"#DejaVuSans-114\"/>\r\n     <use x=\"157.564453\" xlink:href=\"#DejaVuSans-100\"/>\r\n     <use x=\"221.041016\" xlink:href=\"#DejaVuSans-105\"/>\r\n     <use x=\"248.824219\" xlink:href=\"#DejaVuSans-100\"/>\r\n     <use x=\"312.300781\" xlink:href=\"#DejaVuSans-97\"/>\r\n     <use x=\"373.580078\" xlink:href=\"#DejaVuSans-32\"/>\r\n     <use x=\"405.367188\" xlink:href=\"#DejaVuSans-101\"/>\r\n     <use x=\"466.890625\" xlink:href=\"#DejaVuSans-110\"/>\r\n     <use x=\"530.269531\" xlink:href=\"#DejaVuSans-32\"/>\r\n     <use x=\"562.056641\" xlink:href=\"#DejaVuSans-101\"/>\r\n     <use x=\"623.580078\" xlink:href=\"#DejaVuSans-108\"/>\r\n     <use x=\"651.363281\" xlink:href=\"#DejaVuSans-32\"/>\r\n     <use x=\"683.150391\" xlink:href=\"#DejaVuSans-101\"/>\r\n     <use x=\"744.673828\" xlink:href=\"#DejaVuSans-110\"/>\r\n     <use x=\"808.052734\" xlink:href=\"#DejaVuSans-116\"/>\r\n     <use x=\"847.261719\" xlink:href=\"#DejaVuSans-114\"/>\r\n     <use x=\"886.125\" xlink:href=\"#DejaVuSans-101\"/>\r\n     <use x=\"947.648438\" xlink:href=\"#DejaVuSans-110\"/>\r\n     <use x=\"1011.027344\" xlink:href=\"#DejaVuSans-97\"/>\r\n     <use x=\"1072.306641\" xlink:href=\"#DejaVuSans-109\"/>\r\n     <use x=\"1169.71875\" xlink:href=\"#DejaVuSans-105\"/>\r\n     <use x=\"1197.501953\" xlink:href=\"#DejaVuSans-101\"/>\r\n     <use x=\"1259.025391\" xlink:href=\"#DejaVuSans-110\"/>\r\n     <use x=\"1322.404297\" xlink:href=\"#DejaVuSans-116\"/>\r\n     <use x=\"1361.613281\" xlink:href=\"#DejaVuSans-111\"/>\r\n     <use x=\"1422.794922\" xlink:href=\"#DejaVuSans-32\"/>\r\n     <use x=\"1454.582031\" xlink:href=\"#DejaVuSans-121\"/>\r\n     <use x=\"1513.761719\" xlink:href=\"#DejaVuSans-32\"/>\r\n     <use x=\"1545.548828\" xlink:href=\"#DejaVuSans-80\"/>\r\n     <use x=\"1604.101562\" xlink:href=\"#DejaVuSans-114\"/>\r\n     <use x=\"1642.964844\" xlink:href=\"#DejaVuSans-101\"/>\r\n     <use x=\"1704.488281\" xlink:href=\"#DejaVuSans-99\"/>\r\n     <use x=\"1759.46875\" xlink:href=\"#DejaVuSans-105\"/>\r\n     <use x=\"1787.251953\" xlink:href=\"#DejaVuSans-115\"/>\r\n     <use x=\"1839.351562\" xlink:href=\"#DejaVuSans-105\"/>\r\n     <use x=\"1867.134766\" xlink:href=\"#DejaVuSans-243\"/>\r\n     <use x=\"1928.316406\" xlink:href=\"#DejaVuSans-110\"/>\r\n    </g>\r\n   </g>\r\n   <g id=\"legend_1\">\r\n    <g id=\"patch_7\">\r\n     <path d=\"M 302.37625 62.63025 \r\nL 373.516875 62.63025 \r\nQ 375.516875 62.63025 375.516875 60.63025 \r\nL 375.516875 31.71775 \r\nQ 375.516875 29.71775 373.516875 29.71775 \r\nL 302.37625 29.71775 \r\nQ 300.37625 29.71775 300.37625 31.71775 \r\nL 300.37625 60.63025 \r\nQ 300.37625 62.63025 302.37625 62.63025 \r\nz\r\n\" style=\"fill:#e5e5e5;opacity:0.8;stroke:#cccccc;stroke-linejoin:miter;stroke-width:0.5;\"/>\r\n    </g>\r\n    <g id=\"line2d_29\">\r\n     <path d=\"M 304.37625 37.816187 \r\nL 324.37625 37.816187 \r\n\" style=\"fill:none;stroke:#e24a33;stroke-linecap:square;stroke-width:1.5;\"/>\r\n    </g>\r\n    <g id=\"line2d_30\"/>\r\n    <g id=\"text_17\">\r\n     <!-- val_loss -->\r\n     <g transform=\"translate(332.37625 41.316187)scale(0.1 -0.1)\">\r\n      <defs>\r\n       <path d=\"M 2.984375 54.6875 \r\nL 12.5 54.6875 \r\nL 29.59375 8.796875 \r\nL 46.6875 54.6875 \r\nL 56.203125 54.6875 \r\nL 35.6875 0 \r\nL 23.484375 0 \r\nz\r\n\" id=\"DejaVuSans-118\"/>\r\n       <path d=\"M 50.984375 -16.609375 \r\nL 50.984375 -23.578125 \r\nL -0.984375 -23.578125 \r\nL -0.984375 -16.609375 \r\nz\r\n\" id=\"DejaVuSans-95\"/>\r\n      </defs>\r\n      <use xlink:href=\"#DejaVuSans-118\"/>\r\n      <use x=\"59.179688\" xlink:href=\"#DejaVuSans-97\"/>\r\n      <use x=\"120.458984\" xlink:href=\"#DejaVuSans-108\"/>\r\n      <use x=\"148.242188\" xlink:href=\"#DejaVuSans-95\"/>\r\n      <use x=\"198.242188\" xlink:href=\"#DejaVuSans-108\"/>\r\n      <use x=\"226.025391\" xlink:href=\"#DejaVuSans-111\"/>\r\n      <use x=\"287.207031\" xlink:href=\"#DejaVuSans-115\"/>\r\n      <use x=\"339.306641\" xlink:href=\"#DejaVuSans-115\"/>\r\n     </g>\r\n    </g>\r\n    <g id=\"line2d_31\">\r\n     <path d=\"M 304.37625 52.772437 \r\nL 324.37625 52.772437 \r\n\" style=\"fill:none;stroke:#348abd;stroke-linecap:square;stroke-width:1.5;\"/>\r\n    </g>\r\n    <g id=\"line2d_32\"/>\r\n    <g id=\"text_18\">\r\n     <!-- val_acc -->\r\n     <g transform=\"translate(332.37625 56.272437)scale(0.1 -0.1)\">\r\n      <use xlink:href=\"#DejaVuSans-118\"/>\r\n      <use x=\"59.179688\" xlink:href=\"#DejaVuSans-97\"/>\r\n      <use x=\"120.458984\" xlink:href=\"#DejaVuSans-108\"/>\r\n      <use x=\"148.242188\" xlink:href=\"#DejaVuSans-95\"/>\r\n      <use x=\"198.242188\" xlink:href=\"#DejaVuSans-97\"/>\r\n      <use x=\"259.521484\" xlink:href=\"#DejaVuSans-99\"/>\r\n      <use x=\"314.501953\" xlink:href=\"#DejaVuSans-99\"/>\r\n     </g>\r\n    </g>\r\n   </g>\r\n  </g>\r\n </g>\r\n <defs>\r\n  <clipPath id=\"p38b213bd6c\">\r\n   <rect height=\"217.44\" width=\"334.8\" x=\"45.716875\" y=\"24.71775\"/>\r\n  </clipPath>\r\n </defs>\r\n</svg>\r\n",
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "plt.plot(np.arange(0,epochs),history.history['val_loss'],label=\"val_loss\")\n",
        "plt.plot(np.arange(0,epochs),history.history['val_accuracy'],label=\"val_acc\")\n",
        "plt.title(\"Perdida en el entrenamiento y Precisin\")\n",
        "plt.xlabel(\"Nmero de epoca\")\n",
        "plt.ylabel(\"Perdida/Precisin\")\n",
        "plt.legend(loc=\"upper right\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 0 images belonging to 0 classes.\n"
          ]
        }
      ],
      "source": [
        "test_datagen=ImageDataGenerator(preprocessing_function=preprocess_input)\n",
        "path_test=path_root+\"test_junto\"\n",
        "test_gen=test_datagen.flow_from_directory(\n",
        "    path_test,\n",
        "    target_size=(img_width,img_height),\n",
        "    color_mode='rgb',\n",
        "    batch_size=1,\n",
        "    class_mode=None,\n",
        "    shuffle=False,\n",
        "    seed=42\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 2, 0, 0, 0, 0,\n",
              "       2, 0, 3, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 3, 0, 0, 3, 1,\n",
              "       1, 2, 0, 1, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 2, 1, 1,\n",
              "       0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 2, 2, 0,\n",
              "       1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 3, 1, 1, 1, 0, 0, 1,\n",
              "       1, 3, 2, 1, 0, 0, 3, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 2, 0,\n",
              "       0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 2, 0, 0, 0, 2, 1, 0, 1, 0, 0, 3,\n",
              "       0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 3, 0, 1, 0, 0,\n",
              "       1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 2, 0, 3, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 3, 0, 3, 0, 0, 3, 1, 2, 1, 1, 0, 2,\n",
              "       1, 2, 0, 2, 0, 0, 2, 0, 0, 0, 0, 1, 0, 3, 0, 0, 0, 2, 0, 0, 0, 2,\n",
              "       2, 2, 0, 2, 2, 2, 1, 3, 2, 0, 1, 2, 2, 1, 0, 2, 2, 3, 3, 3, 0, 3,\n",
              "       2, 1, 2, 0, 0, 2, 1, 2, 2, 0, 0, 2, 0, 0, 2, 0, 2, 2, 1, 2, 0, 0,\n",
              "       1, 2, 2, 2, 3, 0, 0, 2, 2, 0, 2, 2, 2, 2, 2, 0, 0, 3, 0, 2, 0, 3,\n",
              "       2, 2, 0, 0, 2, 2, 2, 2, 1, 0, 0, 0, 3, 0, 2, 0, 1, 0, 2, 2, 0, 0,\n",
              "       2, 0, 0, 2, 0, 1, 0, 2, 0, 1, 2, 2, 0, 0, 2, 3, 2, 2, 2, 1, 0, 0,\n",
              "       0, 2, 1, 0, 2, 0, 2, 0, 0, 0, 3, 2, 0, 0, 2, 2, 2, 0, 0, 2, 0, 2,\n",
              "       2, 0, 2, 2, 0, 2, 2, 2, 2, 0, 2, 2, 0, 2, 2, 2, 1, 0, 2, 0, 1, 2,\n",
              "       2, 0, 2, 2, 0, 0, 0, 0, 2, 1, 1, 2, 2, 2, 3, 1, 3, 1, 1, 0, 0, 0,\n",
              "       2, 0, 2, 2, 0, 2, 0, 3, 2, 0, 2, 1, 0, 1, 0, 2, 2, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 3, 3, 3, 2, 3, 0, 0, 0, 0, 0,\n",
              "       0, 0, 2, 3, 0, 2, 0, 0, 0, 2, 0, 0, 0, 3, 0, 2, 2, 0, 0, 0, 3, 0,\n",
              "       0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 3, 0, 2, 0, 2, 2, 0, 0, 3, 1, 3, 0,\n",
              "       0, 0, 0, 0, 0, 2, 2, 2, 1, 3, 3, 3, 0, 3, 0, 2, 3, 3, 3, 0, 2, 0,\n",
              "       3, 0, 0, 0, 3, 0, 3, 3, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 1, 3,\n",
              "       0, 0, 2, 1, 0, 0, 0, 0, 0, 2, 0, 0, 0, 3, 3, 0, 0, 0, 0, 0, 0, 3,\n",
              "       3, 3, 0, 0, 3, 3, 2, 0, 0, 0, 0, 3, 1, 0, 2, 1, 2, 0, 3, 0, 3, 2,\n",
              "       3, 3, 1, 0, 0, 2, 0, 3, 0, 0, 0, 0, 0, 3, 2, 3, 0, 1, 0, 0, 0, 0,\n",
              "       3, 2, 0, 0, 0, 2, 3, 3, 0, 2, 1, 3, 2, 2, 3, 0, 3, 3, 0, 1, 0, 3,\n",
              "       3, 1, 0, 2, 0, 2, 3, 0, 0, 2, 0, 3, 0, 3, 0, 2, 0, 3, 0, 0, 0, 0,\n",
              "       0, 3, 0, 0, 3, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 2, 0, 1, 1, 0, 1, 0], dtype=int64)"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "steps_size_test+test_gen.n//test_gen.batch_size\n",
        "pred=model.predict_generator(test_gen,steps=steps_size_test,verbose=1)\n",
        "predicted_class_index=np.argmax(pred,axis=1)\n",
        "print(predicted_class_index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "in user code:\n\n    c:\\Users\\Integradora\\Documents\\MI-Fase2_Banano\\entornos virtuales\\entrenamiento_CNN386\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1224 test_function  *\n        return step_function(self, iterator)\n    c:\\Users\\Integradora\\Documents\\MI-Fase2_Banano\\entornos virtuales\\entrenamiento_CNN386\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1215 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    c:\\Users\\Integradora\\Documents\\MI-Fase2_Banano\\entornos virtuales\\entrenamiento_CNN386\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1211 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    c:\\Users\\Integradora\\Documents\\MI-Fase2_Banano\\entornos virtuales\\entrenamiento_CNN386\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2585 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    c:\\Users\\Integradora\\Documents\\MI-Fase2_Banano\\entornos virtuales\\entrenamiento_CNN386\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2945 _call_for_each_replica\n        return fn(*args, **kwargs)\n    c:\\Users\\Integradora\\Documents\\MI-Fase2_Banano\\entornos virtuales\\entrenamiento_CNN386\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1208 run_step  **\n        outputs = model.test_step(data)\n    c:\\Users\\Integradora\\Documents\\MI-Fase2_Banano\\entornos virtuales\\entrenamiento_CNN386\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1176 test_step\n        self.compiled_loss(\n    c:\\Users\\Integradora\\Documents\\MI-Fase2_Banano\\entornos virtuales\\entrenamiento_CNN386\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\compile_utils.py:204 __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    c:\\Users\\Integradora\\Documents\\MI-Fase2_Banano\\entornos virtuales\\entrenamiento_CNN386\\lib\\site-packages\\tensorflow\\python\\keras\\losses.py:149 __call__\n        losses = ag_call(y_true, y_pred)\n    c:\\Users\\Integradora\\Documents\\MI-Fase2_Banano\\entornos virtuales\\entrenamiento_CNN386\\lib\\site-packages\\tensorflow\\python\\keras\\losses.py:253 call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    c:\\Users\\Integradora\\Documents\\MI-Fase2_Banano\\entornos virtuales\\entrenamiento_CNN386\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    c:\\Users\\Integradora\\Documents\\MI-Fase2_Banano\\entornos virtuales\\entrenamiento_CNN386\\lib\\site-packages\\tensorflow\\python\\keras\\losses.py:1535 categorical_crossentropy\n        return K.categorical_crossentropy(y_true, y_pred, from_logits=from_logits)\n    c:\\Users\\Integradora\\Documents\\MI-Fase2_Banano\\entornos virtuales\\entrenamiento_CNN386\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    c:\\Users\\Integradora\\Documents\\MI-Fase2_Banano\\entornos virtuales\\entrenamiento_CNN386\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py:4687 categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n    c:\\Users\\Integradora\\Documents\\MI-Fase2_Banano\\entornos virtuales\\entrenamiento_CNN386\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_shape.py:1134 assert_is_compatible_with\n        raise ValueError(\"Shapes %s and %s are incompatible\" % (self, other))\n\n    ValueError: Shapes (32, 1) and (32, 4) are incompatible\n",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-35-952e67317452>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0macc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_one_hot_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'> %.3f'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0macc\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m100.0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\Integradora\\Documents\\MI-Fase2_Banano\\entornos virtuales\\entrenamiento_CNN386\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\Integradora\\Documents\\MI-Fase2_Banano\\entornos virtuales\\entrenamiento_CNN386\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict)\u001b[0m\n\u001b[0;32m   1377\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'TraceContext'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgraph_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'test'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1378\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1379\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1380\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1381\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\Integradora\\Documents\\MI-Fase2_Banano\\entornos virtuales\\entrenamiento_CNN386\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\Integradora\\Documents\\MI-Fase2_Banano\\entornos virtuales\\entrenamiento_CNN386\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    812\u001b[0m       \u001b[1;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    813\u001b[0m       \u001b[1;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 814\u001b[1;33m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    815\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    816\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
            "\u001b[1;32mc:\\Users\\Integradora\\Documents\\MI-Fase2_Banano\\entornos virtuales\\entrenamiento_CNN386\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2826\u001b[0m     \u001b[1;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2828\u001b[1;33m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2829\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\Integradora\\Documents\\MI-Fase2_Banano\\entornos virtuales\\entrenamiento_CNN386\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3208\u001b[0m           \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_signature\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3209\u001b[0m           and call_context_key in self._function_cache.missed):\n\u001b[1;32m-> 3210\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_define_function_with_shape_relaxation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3211\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3212\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\Integradora\\Documents\\MI-Fase2_Banano\\entornos virtuales\\entrenamiento_CNN386\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_define_function_with_shape_relaxation\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3139\u001b[0m           expand_composites=True)\n\u001b[0;32m   3140\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3141\u001b[1;33m     graph_function = self._create_graph_function(\n\u001b[0m\u001b[0;32m   3142\u001b[0m         args, kwargs, override_flat_arg_shapes=relaxed_arg_shapes)\n\u001b[0;32m   3143\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marg_relaxed\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrank_only_cache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\Integradora\\Documents\\MI-Fase2_Banano\\entornos virtuales\\entrenamiento_CNN386\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   3063\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3064\u001b[0m     graph_function = ConcreteFunction(\n\u001b[1;32m-> 3065\u001b[1;33m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[0;32m   3066\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3067\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\Integradora\\Documents\\MI-Fase2_Banano\\entornos virtuales\\entrenamiento_CNN386\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m    984\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    985\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 986\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    987\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    988\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\Integradora\\Documents\\MI-Fase2_Banano\\entornos virtuales\\entrenamiento_CNN386\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    598\u001b[0m         \u001b[1;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    599\u001b[0m         \u001b[1;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 600\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    601\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mref\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    602\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\Integradora\\Documents\\MI-Fase2_Banano\\entornos virtuales\\entrenamiento_CNN386\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    971\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    972\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 973\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    974\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    975\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    c:\\Users\\Integradora\\Documents\\MI-Fase2_Banano\\entornos virtuales\\entrenamiento_CNN386\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1224 test_function  *\n        return step_function(self, iterator)\n    c:\\Users\\Integradora\\Documents\\MI-Fase2_Banano\\entornos virtuales\\entrenamiento_CNN386\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1215 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    c:\\Users\\Integradora\\Documents\\MI-Fase2_Banano\\entornos virtuales\\entrenamiento_CNN386\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1211 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    c:\\Users\\Integradora\\Documents\\MI-Fase2_Banano\\entornos virtuales\\entrenamiento_CNN386\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2585 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    c:\\Users\\Integradora\\Documents\\MI-Fase2_Banano\\entornos virtuales\\entrenamiento_CNN386\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2945 _call_for_each_replica\n        return fn(*args, **kwargs)\n    c:\\Users\\Integradora\\Documents\\MI-Fase2_Banano\\entornos virtuales\\entrenamiento_CNN386\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1208 run_step  **\n        outputs = model.test_step(data)\n    c:\\Users\\Integradora\\Documents\\MI-Fase2_Banano\\entornos virtuales\\entrenamiento_CNN386\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1176 test_step\n        self.compiled_loss(\n    c:\\Users\\Integradora\\Documents\\MI-Fase2_Banano\\entornos virtuales\\entrenamiento_CNN386\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\compile_utils.py:204 __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    c:\\Users\\Integradora\\Documents\\MI-Fase2_Banano\\entornos virtuales\\entrenamiento_CNN386\\lib\\site-packages\\tensorflow\\python\\keras\\losses.py:149 __call__\n        losses = ag_call(y_true, y_pred)\n    c:\\Users\\Integradora\\Documents\\MI-Fase2_Banano\\entornos virtuales\\entrenamiento_CNN386\\lib\\site-packages\\tensorflow\\python\\keras\\losses.py:253 call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    c:\\Users\\Integradora\\Documents\\MI-Fase2_Banano\\entornos virtuales\\entrenamiento_CNN386\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    c:\\Users\\Integradora\\Documents\\MI-Fase2_Banano\\entornos virtuales\\entrenamiento_CNN386\\lib\\site-packages\\tensorflow\\python\\keras\\losses.py:1535 categorical_crossentropy\n        return K.categorical_crossentropy(y_true, y_pred, from_logits=from_logits)\n    c:\\Users\\Integradora\\Documents\\MI-Fase2_Banano\\entornos virtuales\\entrenamiento_CNN386\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    c:\\Users\\Integradora\\Documents\\MI-Fase2_Banano\\entornos virtuales\\entrenamiento_CNN386\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py:4687 categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n    c:\\Users\\Integradora\\Documents\\MI-Fase2_Banano\\entornos virtuales\\entrenamiento_CNN386\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_shape.py:1134 assert_is_compatible_with\n        raise ValueError(\"Shapes %s and %s are incompatible\" % (self, other))\n\n    ValueError: Shapes (32, 1) and (32, 4) are incompatible\n"
          ]
        }
      ],
      "source": [
        "#_, acc = model.evaluate(X_test, y_one_hot_test, verbose=0)\n",
        "#print('> %.3f' % (acc * 100.0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "path_modelo='./modelos/ipception_resnetV2.h5'\n",
        "model.save(path_modelo)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LqEUkU3ZfTZv"
      },
      "source": [
        "\n",
        "# entry point, run the example\n",
        "run_example(path_test+\"/780_tipoA.png\",path_modelo)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "unhashable type: 'numpy.ndarray'",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-13-5408095b783d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# entry point, run the example\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mrun_example\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_test\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\"/780_tipoA.png\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpath_modelo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;32mc:\\Users\\Integradora\\Documents\\MI-Fase2_Banano\\Mi_Fase2_Bananos\\funciones.py\u001b[0m in \u001b[0;36mrun_example\u001b[1;34m(filename, path_modelo)\u001b[0m\n\u001b[0;32m    165\u001b[0m         \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'Clase C'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    166\u001b[0m         3 :'Clase D'}\n\u001b[1;32m--> 167\u001b[1;33m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdic\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    168\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    169\u001b[0m '''\n",
            "\u001b[1;31mTypeError\u001b[0m: unhashable type: 'numpy.ndarray'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ]
}